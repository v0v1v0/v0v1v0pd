<div class="container">

<table style="width: 100%;"><tr>
<td>jeffreyspar</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
Jeffreys measure between Gaussian densities given their parameters
</h2>

<h3>Description</h3>

<p>Jeffreys measure (or symmetrised Kullback-Leibler divergence) between two multivariate (<code class="reqn">p &gt; 1</code>) or univariate (<code class="reqn">p = 1</code>) Gaussian densities, given their parameters (mean vectors and covariance matrices if they are multivariate, means and variances if univariate) (see Details).
</p>


<h3>Usage</h3>

<pre><code class="language-R">jeffreyspar(mean1, var1, mean2, var2, check = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>mean1</code></td>
<td>

<p><code class="reqn">p</code>-length numeric vector: the mean of the first Gaussian density.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>var1</code></td>
<td>

<p><code class="reqn">p</code> x <code class="reqn">p</code> symmetric numeric matrix (<code class="reqn">p</code> &gt; 1) or numeric (<code class="reqn">p</code> = 1): the covariance matrix (<code class="reqn">p</code> &gt; 1) or the variance (<code class="reqn">p</code> = 1) of the first Gaussian density.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>mean2</code></td>
<td>

<p><code class="reqn">p</code>-length numeric vector: the mean of the second Gaussian density.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>var2</code></td>
<td>

<p><code class="reqn">p</code> x <code class="reqn">p</code> symmetric numeric matrix (<code class="reqn">p</code> &gt; 1) or numeric (<code class="reqn">p</code> = 1): the covariance matrix (<code class="reqn">p</code> &gt; 1) or the variance (<code class="reqn">p</code> = 1) of the second Gaussian density.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>check</code></td>
<td>

<p>logical. When <code>TRUE</code> (the default is <code>FALSE</code>) the function checks if the covariance matrices are not degenerate (multivariate case) or if the variances are not zero (univariate case).
</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Let <code class="reqn">m1</code> and <code class="reqn">m2</code> the mean vectors, <code class="reqn">v1</code> and <code class="reqn">v2</code> the covariance matrices, Jeffreys measure of the two Gaussian densities is equal to:
</p>
<p style="text-align: center;"><code class="reqn">(1/2) t(m1 - m2) (v1^{-1} + v2^{-1}) (m1 - m2) - (1/2) tr( (v1 - v2) (v1^{-1} - v2^{-1}) )</code>
</p>
<p>.
</p>
<p>If <code class="reqn">p = 1</code> the means and variances are numbers, the formula is the same ignoring the following operators: t (transpose of a matrix or vector) and tr (trace of a square matrix).
</p>


<h3>Value</h3>

<p>Jeffreys measure between two Gaussian densities.
</p>
<p>Be careful! If <code>check = FALSE</code> and one covariance matrix is degenerated (multivariate case) or one variance is zero (univariate case), the result returned must not be considered.
</p>


<h3>Author(s)</h3>

<p>Rachid Boumaza,  Pierre Santagostini, Smail Yousfi, Gilles Hunault, Sabine Demotes-Mainard
</p>


<h3>References</h3>

<p>McLachlan, G.J. (1992). Discriminant analysis and statistical pattern recognition. John Wiley &amp; Sons, New York .
</p>
<p>Thabane, L., Safiul Haq, M. (1999). On Bayesian selection of the best population using the Kullback-Leibler divergence measure. Statistica     Neerlandica, 53(3): 342-360.
</p>


<h3>See Also</h3>

<p>jeffreys: Jeffreys measure of two parametrically estimated Gaussian densities, given samples.
</p>


<h3>Examples</h3>

<pre><code class="language-R">m1 &lt;- c(1,1)
v1 &lt;- matrix(c(4,1,1,9),ncol = 2)
m2 &lt;- c(0,1)
v2 &lt;- matrix(c(1,0,0,1),ncol = 2)
jeffreyspar(m1,v1,m2,v2)
</code></pre>


</div>