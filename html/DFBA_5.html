<div class="container">

<table style="width: 100%;"><tr>
<td>dfba_beta_contrast</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Bayesian Contrasts</h2>

<h3>Description</h3>

<p>This function implements a Bayesian analysis of a linear contrast of
conditions when there are 2 or more independent conditions and where
the variate for each condition is a binomial.
</p>


<h3>Usage</h3>

<pre><code class="language-R">dfba_beta_contrast(
  n1_vec,
  n2_vec,
  contrast_vec,
  a0_vec = rep(1, length(n1_vec)),
  b0_vec = rep(1, length(n1_vec)),
  prob_interval = 0.95,
  samples = 10000
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>n1_vec</code></td>
<td>
<p>A vector of length K that consists of the observed number of successes for the categorical variable in each of the K separate conditions</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>n2_vec</code></td>
<td>
<p>A vector of length K that consists of the observed number of failures for the  categorical variable in each of the K separate conditions</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>contrast_vec</code></td>
<td>
<p>A vector of coefficients of a linear comparison among the conditions where the sum of all the coefficients must be 0 and the sum of the positive coefficients must be 1 and the sum of the negative coefficients must be -1</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>a0_vec</code></td>
<td>
<p>A vector of length K that consists of the prior <code>a0</code> shape parameters for the separate betas (the default values are 1)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>b0_vec</code></td>
<td>
<p>A vector of length K that consists of the prior <code>b0</code> shape parameters for the separate betas (the default values are 1)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>prob_interval</code></td>
<td>
<p>Desired probability for equal-tail interval estimate on the contrast (default is 0.95)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>samples</code></td>
<td>
<p>The desired number of Monte Carlo samples taken from each posterior beta variate (default is 10000)</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Since the Bayesian analysis for each separate condition has a posterior beta
distribution with known shape parameters, the program approximates, <em>via</em>
Monte Carlo sampling, a linear contrast among the set of independent beta
distributions because the contrast of beta distributions is not a known
probability model.
</p>
<p>Given a binomial categorical variate for each of <code class="reqn">K</code> independent
conditions with <code class="reqn">K \ge 2</code>, the standard frequentist nonparametric
analysis is to do a <code class="reqn">\chi^2</code> test with <code class="reqn">K - 1</code> degrees of freedom
(Siegel &amp; Castellan, 1988). Hypothesis testing for the frequentist <code class="reqn">\chi^2</code>
test assesses the sharp-null hypothesis that the binomial success rate is
exactly equal in all the conditions. But this point-null hypothesis is not an
interesting question about the population success rate from a Bayesian
viewpoint because the probability of any single point hypothesis has a
probability measure value of zero (Chechile, 2020). Although it is possible
that the frequentist null hypothesis can be retained for small-<code class="reqn">n</code> studies,
the hypothesis itself is about the population in the case of unlimited sample
size, and surely for this limiting case it is almost certain that the
hypothesis is not exactly true. Thus, from the Bayesian framework, the point-
null hypothesis is not a good use of scientific effort and resources, and it
is more scientifically meaningful to assess a linear comparison of the
conditions, such as to assess if the population success rate in one condition
is greater than the success rate in another condition. An interval hypothesis
such as this has a meaningful probability value, as does the complimentary
hypothesis. If <code class="reqn">\phi_1</code> and <code class="reqn">\phi_2</code> are, respectively, the population
success rates for the binomials in conditions 1 and 2, then a meaningful
comparison might be to assess the probability distribution for <code class="reqn">\Delta = </code>
<code class="reqn">\phi_2 - \phi_1</code>. This example is a simple linear contrast with contrast
coefficient weights of -1 and 1, which are the multipliers for the two
population success rates. If the posterior interval estimate for the contrast
contains 0, then the hypothesis of <code class="reqn">\Delta = 0</code> has some credibility in light
of the given sample size. Thus, by estimating the distribution of <code class="reqn">\Delta</code>,
the user learns important information about condition differences. As another
example of a contrast, suppose there are three conditions where the first
condition is a standard control and the other two conditions are different
alternative conditions. In this case, a user might want to compare the
mean of the control data against the average of the two experimental-
condition means, <em>i.e.</em>, the contrast of
</p>
<p style="text-align: center;"><code class="reqn">\Delta = -1\phi_1 +.5\phi_2 + .5\phi_3.</code>
</p>

<p>In this second example, the coefficients of the contrast are <code class="reqn">[-1, +.5, +.5]</code>.
As a third example, the user might also be interested in a comparison where
the two experimental conditions are compared, <em>i.e.</em>, the contrast of
</p>
<p style="text-align: center;"><code class="reqn">\Delta = 0\phi_1 + 1\phi_2 - 1\phi_3.</code>
</p>

<p>For the <code>dfba_beta_contrast()</code> function, the user is required to
stipulate the coefficients of a contrast such that the sum of all the
coefficients is 0, the sum of the positive coefficients is 1, and the sum of
the negative coefficients is -1. This constraint on the coefficients forces
<code class="reqn">\Delta</code> to be on the <code class="reqn">[-1, +1]</code> interval.
</p>
<p>There is a standard Bayesian posterior for each condition, which is a beta
distribution (see Chechile (2020) for a detailed discussion of this
literature). In short, it is well known that the beta distribution is a
natural Bayesian conjugate function for Bernoulli random processes. Thus, a
prior beta distribution with shape parameters <code class="reqn">a_0</code> and <code class="reqn">b_0</code> results
(<em>via</em> Bayes's theorem) in a posterior beta with shape parameters <code class="reqn">a</code>
and <code class="reqn">b</code> where <code class="reqn">a = a_0 + n_1</code> and <code class="reqn">b = b_0 + n_2</code>, where <code class="reqn">n_1</code>
and <code class="reqn">n_2</code> are the respective successes and failures of the categorical
variable. While the Bayesian analysis of each beta distribution for the
separate conditions are known, a comparison among 2 or more separate beta
distributions is not distributed as a beta. The posterior mean of a linear
contrast of separate beta variates has a known mean regardless of the
correlations among the variates, but the distributional form of the contrast
of independent betas is not known in closed form. The distributional form is
important for ascertaining issues such as determining the probability that
the contrast is positive or specifying a probability interval for the
contrast. But, with the <code>dfba_beta_contrast()</code> function, these important
aspects of the Bayesian analysis are approximated via Monte Carlo simulation.
</p>
<p>The <code>samples</code> argument stipulates the number of random values to be
drawn from each of the <code class="reqn">K</code> posterior conditions. The default value for
<code>samples</code> is 10000. The default value of 10000 is also the minimum value
that can be selected (increased values of <code>samples</code> provide increased
precision). Posterior interval estimation and the Bayes factor for the
contrast are provided on the basis of the Monte Carlo sampling. If <code>samples</code>
is equal to <code class="reqn">N</code> and if <code class="reqn">\phi_1, \ldots, \phi_K</code> are the parameters
for the population success rates, then there are <code class="reqn">N</code> random values drawn
from each of <code class="reqn">\phi_i</code> parameters for <code class="reqn">i = 1, \ldots , K</code>. Given the
contrast coefficients stipulated in the arguments, there are <code class="reqn">N</code> delta random
posterior values where <code class="reqn">\Delta_j = \Psi_1\phi_{1j}+ \ldots +\Psi_i\phi_{Kj}</code> for
<code class="reqn">j = 1, \ldots, N</code>, where <code class="reqn">\Psi_i</code> are the contrast coefficients specified
in the <code>contrast_vec</code> argument. The Monte Carlo sampling from each posterior
beta with known shape parameters uses the <code>rbeta()</code> function. Thus, unlike
Bayesian procedures that employ Markov chain Monte Carlo algorithms, the
Monte Carlo sampling in the <code>dfba_beta_contrast()</code> function does not depend
on a burn-in process or a starting estimate. Thus, all the <code class="reqn">N</code> sampled
values are valid random samples. Repeated use of the <code>dfba_beta_contrast()</code>
function for the same input will naturally exhibit some random variation in
the interval estimate and in the Bayes factor for a contrast greater than 0.
However, the point estimate for the contrast does not depend on the Monte
Carlo sampling, and it is constant given the vectors for <code>n1_vec</code> and
<code>n2_vec</code> and given the same prior.
</p>


<h3>Value</h3>

<p>A list containing the following components:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>mean</code></td>
<td>
<p>Exact posterior mean estimate for the contrast</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>eti_lower</code></td>
<td>
<p>The lower equal-tail limit for the contrast for the probability interval value specified by <code>prob_interval</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>eti_upper</code></td>
<td>
<p>The upper equal-tail limit for the contrast for the probability interval value specified by <code>prob_interval</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>prob_positive_delta</code></td>
<td>
<p>Posterior probability that the contrast is positive</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>prior_positive_delta</code></td>
<td>
<p>Prior probability that the contrast is positive</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>bayes_factor</code></td>
<td>
<p>The Bayes factor for the posterior-to-prior odds for a positive contrast to a non-positive contrast</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>delta_quantiles</code></td>
<td>
<p>Quantile values (<code>probs = seq(0, 1, 0.01)</code>) for the posterior contrast from the Monte Carlo sampling</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>a_vec</code></td>
<td>
<p>A vector of length K that consists of the posterior <code>a</code> shape parameters for the separate posterior beta distributions</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>b_vec</code></td>
<td>
<p>A vector of length K that consists of the posterior <code>b</code> shape parameters for the separate posterior beta distributions</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>a0_vec</code></td>
<td>
<p>A vector of length K that consists of the prior <code>a0</code> shape parameters for the separate prior beta distributions</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>b0_vec</code></td>
<td>
<p>A vector of length K that consists of the prior <code>b0</code> shape parameters for the separate prior beta distributions</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>contrast_vec</code></td>
<td>
<p>A vector for the contrast coefficients for a linear comparison of posterior beta variates</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>prob_interval</code></td>
<td>
<p>The probability for the equal-tail estimate for the contrast (default is 0.95)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>samples</code></td>
<td>
<p>The number of Monte Carlo samples from the K separate posterior beta distributions</p>
</td>
</tr>
</table>
<h3>References</h3>

<p>Chechile, R. A. (2020). Bayesian Statistics for Experimental Scientists: A
General Introduction Using Distribution-Free Methods. Cambridge: MIT Press.
</p>
<p>Siegel, S. &amp; Castellan, N. J. (1988). Nonparametric Statistics for the
Behavioral Sciences. New York: McGraw Hill.
</p>


<h3>Examples</h3>

<pre><code class="language-R">## Suppose there are four conditions from a factorial design
# where the conditions labels are A1B1, A2B1, A1B2, and A2B2
# where the frequencies for success for the binomial variate are:
n1_vec &lt;- c(22, 15, 13, 21)
# and the frequencies for failures per condition are:
n2_vec &lt;- c(18, 25, 27, 19)
# Let us test the following three orthogonal contrasts
contrast.B1vsB2 &lt;- c(.5, .5, -.5, -.5)
contrast.A1vsA2 &lt;- c(.5, -.5, .5, -.5)
contrast.ABinter &lt;- c(.5, -.5, -.5, .5)

dfba_beta_contrast(n1_vec = n1_vec,
                   n2_vec = n2_vec,
                   contrast_vec = contrast.B1vsB2)

dfba_beta_contrast(n1_vec,
                   n2_vec,
                   contrast_vec = contrast.A1vsA2)

dfba_beta_contrast(n1_vec,
                   n2_vec,
                   contrast_vec = contrast.ABinter)

# Plot the cumulative distribution for AB interaction
testABinteraction&lt;-dfba_beta_contrast(n1_vec,
                                      n2_vec,
                                      contrast_vec = contrast.ABinter)
plot(testABinteraction)
</code></pre>


</div>