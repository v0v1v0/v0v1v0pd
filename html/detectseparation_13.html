<div class="container">

<table style="width: 100%;"><tr>
<td>detect_separation</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Detect Separation</h2>

<h3>Description</h3>

<p>Method for <code>glm</code> that tests for data separation and
finds which parameters have infinite maximum likelihood estimates
in generalized linear models with binomial responses
</p>
<p><code>detect_separation()</code> is a method for <code>glm</code>
that tests for the occurrence of complete or quasi-complete
separation in datasets for binomial response generalized linear
models, and finds which of the parameters will have infinite
maximum likelihood estimates. <code>detect_separation()</code>
relies on the linear programming methods developed in Konis (2007).
</p>


<h3>Usage</h3>

<pre><code class="language-R">detect_separation(
  x,
  y,
  weights = NULL,
  start = NULL,
  etastart = NULL,
  mustart = NULL,
  offset = NULL,
  family = gaussian(),
  control = list(),
  intercept = TRUE,
  singular.ok = TRUE
)

detectSeparation(
  x,
  y,
  weights = NULL,
  start = NULL,
  etastart = NULL,
  mustart = NULL,
  offset = NULL,
  family = gaussian(),
  control = list(),
  intercept = TRUE,
  singular.ok = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p><code>x</code> is a design matrix of dimension <code>n * p</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>
<p><code>y</code> is a vector of observations of length <code>n</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>weights</code></td>
<td>
<p>an optional vector of ‘prior weights’ to be used
in the fitting process.  Should be <code>NULL</code> or a numeric vector.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>start</code></td>
<td>
<p>currently not used.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>etastart</code></td>
<td>
<p>currently not used.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>mustart</code></td>
<td>
<p>currently not used.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>offset</code></td>
<td>
<p>this can be used to specify an <em>a priori</em> known
component to be included in the linear predictor during fitting.
This should be <code>NULL</code> or a numeric vector of length equal to
the number of cases.  One or more <code>offset</code> terms can be
included in the formula instead or as well, and if more than one is
specified their sum is used.  See <code>model.offset</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>family</code></td>
<td>
<p>a description of the error distribution and link
function to be used in the model.  For <code>glm</code> this can be a
character string naming a family function, a family function or the
result of a call to a family function.  For <code>glm.fit</code> only the
third option is supported.  (See <code>family</code> for details of
family functions.)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>control</code></td>
<td>
<p>a list of parameters controlling separation
detection. See <code>detect_separation_control()</code> for
details.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>intercept</code></td>
<td>
<p>logical. Should an intercept be included in the
<em>null</em> model?</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>singular.ok</code></td>
<td>
<p>logical. If <code>FALSE</code>, a singular model is an
error.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Following the definitions in Albert and Anderson (1984), the data
for a binomial-response generalized linear model with logistic link
exhibit quasi-complete separation if there exists a non-zero
parameter vector <code class="reqn">\beta</code> such that <code class="reqn">X^0 \beta \le 0</code> and
<code class="reqn">X^1 \beta \ge 0</code>, where <code class="reqn">X^0</code> and <code class="reqn">X^1</code> are the
matrices formed by the rows of the model matrix $X$ corresponding
to zero and non-zero responses, respectively. The data exhibits
complete separation if there exists a parameter vector <code class="reqn">\beta</code> such
that the aforementioned conditions are satisfied with strict
inequalities. If there are no vectors <code class="reqn">\beta</code> that can satisfy the
conditions, then the data points are said to overlap.
</p>
<p>If the inverse link function <code class="reqn">G(t)</code> of a generalized linear
model with binomial responses is such that <code class="reqn">\log G(t)</code> and
<code class="reqn">\log (1 - G(t))</code> are concave and the model has an intercept
parameter, then overlap is a necessary and sufficient condition for
the maximum likelihood estimates to be finite (see Silvapulle, 1981
for a proof). Such link functions are, for example, the logit,
probit and complementary log-log.
</p>
<p><code>detect_separation()</code> determines whether or not the
data exhibits (quasi-)complete separation. Then, if separation is
detected and the link function <code class="reqn">G(t)</code> is such that <code class="reqn">\log
G(t)</code> and <code class="reqn">\log (1 - G(t))</code> are concave, the maximum likelihood
estimates has infinite components.
</p>
<p><code>detect_separation()</code> is a wrapper to the
<code>detect_infinite_estimates()</code> method. Separation
detection, as separation is defined above, takes place using the
linear programming methods in Konis (2007) regardless of the link
function. The output of those methods is also used to determine
which estimates are infinite, unless the link is "log". In the
latter case the linear programming methods in Schwendinger et
al. (2021) are called to establish if and which estimates are
infinite. If the link function is not one of '"logit"', '"log"',
'"probit"', '"cauchit"', '"cloglog"' then a warning is issued.
</p>
<p>The <code>coefficients</code> method extracts a vector of values
for each of the model parameters under the following convention:
<code>0</code> if the maximum likelihood estimate of the parameter is
finite, and <code>Inf</code> or <code>-Inf</code> if the maximum likelihood
estimate of the parameter if plus or minus infinity. This
convention makes it easy to adjust the maximum likelihood estimates
to their actual values by element-wise addition.
</p>
<p><code>detect_separation()</code> can be passed directly as
a method to the <code>glm</code> function. See, examples.
</p>
<p><code>detectSeparation</code>() is an alias for <code>detect_separation</code>().
</p>


<h3>Value</h3>

<p>A list that inherits from class <code>detect_separation</code>,
<code>glm</code> and <code>lm</code>. A <code>print</code> method is provided for
<code>detect_separation</code> objects.
</p>


<h3>Note</h3>

<p>For the definition of complete and quasi-complete separation, see
Albert and Anderson (1984). Kosmidis and Firth (2021) prove that
the reduced-bias estimator that results by the penalization of the
logistic regression log-likelihood by Jeffreys prior takes always
finite values, even when some of the maximum likelihood estimates
are infinite. The reduced-bias estimates can be computed using the
<span class="pkg">brglm2</span> R package.
</p>
<p><code>detect_separation</code> was designed in 2017 by Ioannis
Kosmidis for the **brglm2** R package, after correspondence with
Kjell Konis, and a port of the <code>separator</code> function had been
included in **brglm2** under the permission of Kjell Konis. In
2020, <code>detect_separation</code> and
<code>check_infinite_estimates</code> were moved outside
**brglm2** into the dedicated **detectseparation** package. Dirk
Schumacher authored the <code>separator_ROI</code> function, which
depends on the **ROI** R package and is now the default
implementation used for detecting separation. In 2022, Florian
Schwendinger authored the <code>dielb_ROI</code> function for detecting
infinite estimates in log-binomial regression, and, with Ioannis
Kosmidis, they refactored the codebase to properly accommodate for
the support of log-binomial regression.
</p>


<h3>Author(s)</h3>

<p>Ioannis Kosmidis [aut, cre] <a href="mailto:ioannis.kosmidis@warwick.ac.uk">ioannis.kosmidis@warwick.ac.uk</a>, Dirk Schumacher [aut] <a href="mailto:mail@dirk-schumacher.net">mail@dirk-schumacher.net</a>, Florian Schwendinger [aut] <a href="mailto:FlorianSchwendinger@gmx.at">FlorianSchwendinger@gmx.at</a>, Kjell Konis [ctb] <a href="mailto:kjell.konis@me.com">kjell.konis@me.com</a>
</p>


<h3>References</h3>

<p>Konis K. (2007). *Linear Programming Algorithms for Detecting
Separated Data in Binary Logistic Regression
Models*. DPhil. University of Oxford.
<a href="https://ora.ox.ac.uk/objects/uuid:8f9ee0d0-d78e-4101-9ab4-f9cbceed2a2a">https://ora.ox.ac.uk/objects/uuid:8f9ee0d0-d78e-4101-9ab4-f9cbceed2a2a</a>
</p>
<p>Konis K. (2013). safeBinaryRegression: Safe Binary Regression. R
package version 0.1-3.
<a href="https://CRAN.R-project.org/package=safeBinaryRegression">https://CRAN.R-project.org/package=safeBinaryRegression</a>
</p>
<p>Kosmidis I. and Firth D. (2021). Jeffreys-prior penalty, finiteness
and shrinkage in binomial-response generalized linear
models. *Biometrika*, **108**, 71–82. <a href="https://doi.org/10.1093/biomet/asaa052">doi:10.1093/biomet/asaa052</a>
</p>
<p>Silvapulle, M. J. (1981).  On the Existence of Maximum Likelihood
Estimators for the Binomial Response Models.  *Journal of the Royal
Statistical Society. Series B (Methodological)*, **43**, 310–313.
<a href="https://www.jstor.org/stable/2984941">https://www.jstor.org/stable/2984941</a>
</p>
<p>Schwendinger, F., Grün, B. &amp; Hornik, K. (2021). A comparison of
optimization solvers for log binomial regression including conic
programming.  *Computational Statistics*, **36**,
1721–1754. <a href="https://doi.org/10.1007/s00180-021-01084-5">doi:10.1007/s00180-021-01084-5</a>
</p>


<h3>See Also</h3>

<p><code>glm.fit</code> and <code>glm</code>, <code>detect_infinite_estimates</code>, <code>check_infinite_estimates</code>, <code>brglm_fit</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">
# endometrial data from Heinze \&amp; Schemper (2002) (see ?endometrial)
data("endometrial", package = "detectseparation")
endometrial_sep &lt;- glm(HG ~ NV + PI + EH, data = endometrial,
                       family = binomial("logit"),
                       method = "detect_separation")
endometrial_sep
# The maximum likelihood estimate for NV is infinite
summary(update(endometrial_sep, method = "glm.fit"))


# Example inspired by unpublished microeconometrics lecture notes by
# Achim Zeileis https://eeecon.uibk.ac.at/~zeileis/
# The maximum likelihood estimate of sourhernyes is infinite
if (requireNamespace("AER", quietly = TRUE)) {
    data("MurderRates", package = "AER")
    murder_sep &lt;- glm(I(executions &gt; 0) ~ time + income +
                      noncauc + lfp + southern, data = MurderRates,
                      family = binomial(), method = "detect_separation")
    murder_sep
    # which is also evident by the large estimated standard error for NV
    murder_glm &lt;- update(murder_sep, method = "glm.fit")
    summary(murder_glm)
    # and is also revealed by the divergence of the NV column of the
    # result from the more computationally intensive check
    plot(check_infinite_estimates(murder_glm))
    # Mean bias reduction via adjusted scores results in finite estimates
    if (requireNamespace("brglm2", quietly = TRUE))
        update(murder_glm, method = brglm2::brglm_fit)
}

</code></pre>


</div>