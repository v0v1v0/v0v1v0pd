<div class="container">

<table style="width: 100%;"><tr>
<td>MLP_net</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>MLP_net function</h2>

<h3>Description</h3>

<p>A function to define a multilayer perceptron and compute quantities for backpropagation, if needed.
</p>


<h3>Usage</h3>

<pre><code class="language-R">MLP_net(input, weights, bias, dims, nlayers, activ, back = TRUE, regulariser)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>input</code></td>
<td>
<p>input data, a list of vectors (i.e. ragged array)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>weights</code></td>
<td>
<p>a list object containing weights for the forward pass, see ?weights2list</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>bias</code></td>
<td>
<p>a list object containing biases for the forward pass, see ?bias2list</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>dims</code></td>
<td>
<p>the dimensions of the network as stored from a call to the function network, see ?network</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nlayers</code></td>
<td>
<p>number of layers as stored from a call to the function network, see ?network</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>activ</code></td>
<td>
<p>list of activation functions as stored from a call to the function network, see ?network</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>back</code></td>
<td>
<p>logical, whether to compute quantities for backpropagation (set to FALSE for feed-forward use only)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>regulariser</code></td>
<td>
<p>type of regularisation strategy to, see ?train, ?no_regularisation ?L1_regularisation, ?L2_regularisation</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>a list object containing the evaluated forward pass and also, if selected, quantities for backpropagation.
</p>


<h3>References</h3>


<ol>
<li>
<p> Ian Goodfellow, Yoshua Bengio, Aaron Courville, Francis Bach. Deep Learning. (2016)
</p>
</li>
<li>
<p> Terrence J. Sejnowski. The Deep Learning Revolution (The MIT Press). (2018)
</p>
</li>
<li>
<p> Neural Networks YouTube playlist by 3brown1blue: <a href="https://www.youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi">https://www.youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi</a>
</p>
</li>
<li>
<p>http://neuralnetworksanddeeplearning.com/
</p>
</li>
</ol>
<h3>See Also</h3>

<p>network, train, backprop_evaluate, MLP_net, backpropagation_MLP,
logistic, ReLU, smoothReLU, ident, softmax, Qloss, multinomial,
NNgrad_test, weights2list, bias2list, biasInit, memInit, gradInit,
addGrad, nnetpar, nbiaspar, addList, no_regularisation, L1_regularisation,
L2_regularisation
</p>


</div>