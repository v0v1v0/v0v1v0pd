<div class="container">

<table style="width: 100%;"><tr>
<td>distcov.test</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Performs a distance covariance test.</h2>

<h3>Description</h3>

<p>Performs a distance covariance test.
</p>


<h3>Usage</h3>

<pre><code class="language-R">distcov.test(
  X,
  Y,
  method = "permutation",
  b = 499L,
  ln = 20,
  affine = FALSE,
  standardize = FALSE,
  bias.corr = FALSE,
  type.X = "sample",
  type.Y = "sample",
  metr.X = "euclidean",
  metr.Y = "euclidean",
  use = "all",
  return.data = FALSE,
  algorithm = "auto"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>X</code></td>
<td>
<p>contains either the first sample or its corresponding distance matrix.
</p>
<p>In the first case, X can be provided either as a vector (if one-dimensional), a matrix or a data.frame (if two-dimensional or higher). 
</p>
<p>In the second case, the input must be a distance matrix corresponding to the sample of interest.
</p>
<p>If X is a sample, type.X must be specified as "sample". If X is a distance matrix, type.X must be specified as "distance".</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Y</code></td>
<td>
<p>see X.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>method</code></td>
<td>
<p>specifies the type of test that is performed.
</p>
<p>"permutation" performs a Monte Carlo Permutation test. 
</p>
<p>"gamma" performs a test based on a gamma approximation of the test statistic under the null (Huang and Huo 2017). This test tends to be anti-conservative, if the “real” p-value is small
</p>
<p>"conservative" performs a conservative two-moment approximation (Berschneider and Bottcher 2018).
</p>
<p>"bb3" performs a  three-moment approximation  (Berschneider and Bottcher 2018). This is the most precise parametric option, but only available with the standard algorithm.
</p>
<p>"wildbs1" and "wilbs2" perform wild bootstrap tests (Chwialkowski et al. 2014); experimental at the moment.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>b</code></td>
<td>
<p>integer; specifies the number of random permutations/bootstrap samples used for the permutation or wild bootstraps tests. Ignored for other tests.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ln</code></td>
<td>
<p>numeric; block size parameter for wild bootstrap tests. Ignored for other tests.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>affine</code></td>
<td>
<p>logical; specifies if the affinely invariant distance covariance (Dueck et al. 2014) should be calculated or not.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>standardize</code></td>
<td>
<p>logical; specifies if X and Y should be standardized dividing each component by its standard deviations. No effect when affine = TRUE.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>bias.corr</code></td>
<td>
<p>logical; specifies if the bias corrected version of the sample distance covariance (Huo and Szekely 2016) should be calculated.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>type.X</code></td>
<td>
<p>For "distance", X is interpreted as a distance matrix. For "sample", X is interpreted as a sample.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>type.Y</code></td>
<td>
<p>see type.X.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>metr.X</code></td>
<td>
<p>specifies the metric which should be used to compute the distance matrix for X (ignored when type.X = "distance").
</p>
<p>Options are "euclidean", "discrete", "alpha", "minkowski", "gaussian", "gaussauto", "boundsq" or user-specified metrics (see examples).
</p>
<p>For "alpha", "minkowski", "gauss", "gaussauto" and "boundsq", the corresponding parameters are specified via "c(metric, parameter)", c("gaussian", 3) for example uses a Gaussian metric with bandwidth parameter 3; the default parameter is 2 for "minkowski" and "1" for all other metrics.
</p>
<p>See Lyons (2013); Sejdinovic et al. (2013); Bottcher et al. (2018) for details.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>metr.Y</code></td>
<td>
<p>see metr.X.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>use</code></td>
<td>
<p>specifies how to treat missing values. "complete.obs" excludes NAs, "all" uses all observations.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>return.data</code></td>
<td>
<p>logical; specifies if the test object should contain the original data.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>algorithm</code></td>
<td>
<p>specifies the algorithm used for calculating the distance covariance. 
</p>
<p>"fast" uses an O(n log n) algorithm if the observations are one-dimensional and metr.X and metr.Y are either "euclidean" or "discrete", see also Huo and Szekely (2016). 
</p>
<p>"memsave" uses a memory saving version of the standard algorithm with computational complexity O(n^2) but requiring only O(n) memory. 
</p>
<p>"standard" uses the classical algorithm. User-specified metrics always use the classical algorithm.
</p>
<p>"auto" chooses the best algorithm for the specific setting using a rule of thumb.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>distcov.test object
</p>


<h3>References</h3>

<p>Berschneider G, Bottcher B (2018).
“On complex Gaussian random fields, Gaussian quadratic forms and sample distance multivariance.”
<em>arXiv preprint arXiv:1808.07280</em>.
</p>
<p>Bottcher B, Keller-Ressel M, Schilling RL (2018).
“Detecting independence of random vectors: generalized distance covariance and Gaussian covariance.”
<em>Modern Stochastics: Theory and Applications</em>, <b>3</b>, 353–383.
</p>
<p>Chwialkowski KP, Sejdinovic D, Gretton A (2014).
“A wild bootstrap for degenerate kernel tests.”
In <em>Advances in neural information processing systems</em>, 3608–3616.
</p>
<p>Dueck J, Edelmann D, Gneiting T, Richards D (2014).
“The affinely invariant distance correlation.”
<em>Bernoulli</em>, <b>20</b>, 2305–2330.
</p>
<p>Huang C, Huo X (2017).
“A statistically and numerically efficient independence test based on random projections and distance covariance.”
<em>arXiv preprint arXiv:1701.06054</em>.
</p>
<p>Huo X, Szekely GJ (2016).
“Fast computing for distance covariance.”
<em>Technometrics</em>, <b>58</b>(4), 435–447.
</p>
<p>Lyons R (2013).
“Distance covariance in metric spaces.”
<em>The Annals of Probability</em>, <b>41</b>, 3284–3305.
</p>
<p>Sejdinovic D, Sriperumbudur B, Gretton A, Fukumizu K (2013).
“Equivalence of distance-based and RKHS-based statistics in hypothesis testing.”
<em>The Annals of Statistics</em>, <b>41</b>, 2263–2291.
</p>
<p>Szekely GJ, Rizzo ML, Bakirov NK (2007).
“Measuring and testing dependence by correlation of distances.”
<em>The Annals of Statistics</em>, <b>35</b>, 2769–2794.
</p>
<p>Szekely GJ, Rizzo ML (2009).
“Brownian distance covariance.”
<em>The Annals of Applied Statistics</em>, <b>3</b>, 1236–1265.
</p>


</div>