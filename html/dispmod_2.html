<div class="container">

<table style="width: 100%;"><tr>
<td>glm.poisson.disp</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Overdispersed Poisson log-linear models</h2>

<h3>Description</h3>

<p>This function estimates overdispersed Poisson log-linear models using the approach discussed by Breslow N.E. (1984).</p>


<h3>Usage</h3>

<pre><code class="language-R">glm.poisson.disp(object, maxit = 30, verbose = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>object</code></td>
<td>
<p>an object of class <code>"glm"</code> providing a fitted Poisson log-linear regression model; see <code>glm</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>maxit</code></td>
<td>
<p>integer giving the maximal number of iterations for the model fitting procedure.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>verbose</code></td>
<td>
<p>logical, if <code>TRUE</code> information are printed during each step of the algorithm.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Breslow (1984) proposed an iterative algorithm for fitting overdispersed Poisson log-linear models. The method is similar to that proposed by Williams (1982) for handling overdispersion in logistic regression models (see <code>glm.binomial.disp</code>). 
</p>
<p>Suppose we observe <code class="reqn">n</code> independent responses such that
</p>
<p style="text-align: center;"><code class="reqn">y_i \mid \lambda_i \sim \mathrm{Poisson}(\lambda_in_i)</code>
</p>

<p>for <code class="reqn">i = 1, \ldots, n</code>.
The response variable <code class="reqn">y_i</code> may be an event counts variable observed over a period of time (or in the space) of length <code class="reqn">n_i</code>, whereas <code class="reqn">\lambda_i</code> is the rate parameter. 
Then,
</p>
<p style="text-align: center;"><code class="reqn">E(y_i \mid \lambda_i) = \mu_i = \lambda_i n_i = \exp(\log(n_i) + \log(\lambda_i))</code>
</p>

<p>where <code class="reqn">\log(n_i)</code> is an offset and <code class="reqn">\log(\lambda_i) = \beta'x_i</code> expresses the dependence of the Poisson rate parameter on a set of, say <code class="reqn">p</code>, predictors. If the periods of time are all of the same length, we can set <code class="reqn">n_i = 1</code> for all <code class="reqn">i</code> so the offset is zero.
</p>
<p>The Poisson distribution has <code class="reqn">E(y_i \mid \lambda_i) = V(y_i \mid \lambda_i)</code>, but it may happen that the actual variance exceeds the nominal variance under the assumed probability model.
</p>
<p>Suppose that <code class="reqn">\theta_i = \lambda_i n_i</code> is a random variable distributed according to
</p>
<p style="text-align: center;"><code class="reqn">\theta_i \sim \mathrm{Gamma} (\mu_i, 1/\phi)</code>
</p>

<p>where <code class="reqn">E(\theta_i) = \mu_i</code> and <code class="reqn">V(\theta_i) = \mu_i^2 \phi</code>. Thus, it can be shown that the unconditional mean and variance of <code class="reqn">y_i</code> are given by
</p>
<p style="text-align: center;"><code class="reqn">E(y_i) = \mu_i</code>
</p>

<p>and
</p>
<p style="text-align: center;"><code class="reqn">V(y_i) = \mu_i + \mu_i^2 \phi = \mu_i (1 + \mu_i\phi)</code>
</p>

<p>Hence, for <code class="reqn">\phi &gt; 0</code> we have overdispersion. It is interesting to note that the same mean and variance arise also if we assume a negative binomial distribution for the response variable.
</p>
<p>The method proposed by Breslow uses an iterative algorithm for estimating the dispersion parameter <code class="reqn">\phi</code> and hence the necessary weights <code class="reqn">1/(1 + \mu_i \hat{\phi})</code> (for details see Breslow, 1984).
</p>


<h3>Value</h3>

<p>The function returns an object of class <code>"glm"</code> with the usual information and the added components:   
</p>
<table>
<tr style="vertical-align: top;">
<td><code>dispersion</code></td>
<td>
<p>the estimated dispersion parameter.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>disp.weights</code></td>
<td>
<p>the final weights used to fit the model.</p>
</td>
</tr>
</table>
<h3>Note</h3>

<p>Based on a similar procedure available in Arc (Cook and Weisberg, <a href="http://www.stat.umn.edu/arc">http://www.stat.umn.edu/arc</a>)</p>


<h3>References</h3>

<p>Breslow, N.E. (1984), Extra-Poisson variation in log-linear models, 
<em>Applied Statistics</em>, 33, 38â€“44.
</p>


<h3>See Also</h3>

<p><code>lm</code>, <code>glm</code>, <code>lm.disp</code>, <code>glm.binomial.disp</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">## Salmonella TA98 data
data(salmonellaTA98)
salmonellaTA98 &lt;- within(salmonellaTA98, logx10 &lt;- log(x+10))
mod &lt;- glm(y ~ logx10 + x, data = salmonellaTA98, family = poisson(log)) 
summary(mod)

mod.disp &lt;- glm.poisson.disp(mod)
summary(mod.disp)
mod.disp$dispersion

# compute predictions on a grid of x-values...
x0 &lt;- with(salmonellaTA98, seq(min(x), max(x), length=50))
eta0 &lt;- predict(mod, newdata = data.frame(logx10 = log(x0+10), x = x0), se=TRUE)
eta0.disp &lt;- predict(mod.disp, newdata = data.frame(logx10 = log(x0+10), x = x0), se=TRUE)
# ... and plot the mean functions with variability bands
plot(y ~ x, data = salmonellaTA98)
lines(x0, exp(eta0$fit))
lines(x0, exp(eta0$fit+2*eta0$se), lty=2)
lines(x0, exp(eta0$fit-2*eta0$se), lty=2)
lines(x0, exp(eta0.disp$fit), col=3)
lines(x0, exp(eta0.disp$fit+2*eta0.disp$se), lty=2, col=3)
lines(x0, exp(eta0.disp$fit-2*eta0.disp$se), lty=2, col=3)

## Holford's data
data(holford)

mod &lt;- glm(incid ~ offset(log(pop)) + Age + Cohort, data = holford, 
           family = poisson(log)) 
summary(mod)

mod.disp &lt;- glm.poisson.disp(mod)
summary(mod.disp)
mod.disp$dispersion
</code></pre>


</div>