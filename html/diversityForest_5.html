<div class="container">

<table style="width: 100%;"><tr>
<td>hars</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Data on human activity recognition using smartphones</h2>

<h3>Description</h3>

<p>This data set contains sensor data from 30 volunteers aged 19-48 years, performing 
six activities while wearing Samsung Galaxy S II smartphones on their waists. 
The sensors recorded 3-axial linear acceleration and angular velocity at 50Hz. 
The experiments were video-recorded to label the data manually. The outcome 
<code>Activity</code> is categorical with six classes that differentiate the six 
activities.<br>
This is an updated version of the Human Activity Recognition Using Smartphones 
data set published in the UC Irvine Machine Learning Repository. This updated 
version published on OpenML includes both raw sensor signals and updated 
activity labels, with aggregated measurements for each individual and activity.
</p>


<h3>Format</h3>

<p>A data frame with 180 observations (activities), 66 covariates and one 
6-class outcome variable
</p>


<h3>Details</h3>

<p>The classes of the outcome <code>Activity</code> are as follows: <code>LAYING</code>, 
<code>SITTING</code>, <code>STANDING</code>, <code>WALKING</code>, <code>WALKING_DOWNSTAIRS</code>, 
<code>WALKING_UPSTAIRS</code>.<br>
The OpenML data set contained one additional variable <code>Person</code> 
that was removed because it has too many factors to use it as a covariate 
in prediction.
</p>


<h3>Source</h3>


<ul>
<li>
<p> Updated version: OpenML: data.name: Smartphone-Based_Recognition_of_Human_Activities, data.id: 4153, link: <a href="https://www.openml.org/d/4153/">https://www.openml.org/d/4153/</a> (Accessed: 29/08/2024)
</p>
</li>
<li>
<p> Original version: UC Irvine Machine Learning Repository, link: <a href="https://archive.ics.uci.edu/dataset/240/human+activity+recognition+using+smartphones/">https://archive.ics.uci.edu/dataset/240/human+activity+recognition+using+smartphones/</a> (Accessed: 29/08/2024)
</p>
</li>
</ul>
<h3>References</h3>


<ul>
<li>
<p> Reyes-Ortiz, J.-L., Oneto, L., Sam√†, A., Parra, X., Anguita, D. (2016). Transition-aware human activity recognition using smartphones. Neurocomputing, 171:754-767, &lt;<a href="https://doi.org/10.1016/j.neucom.2015.07.085">doi:10.1016/j.neucom.2015.07.085</a>&gt;.
</p>
</li>
<li>
<p> Vanschoren, J., van Rijn, J. N., Bischl, B., Torgo, L. (2013). OpenML: networked science in machine learning. SIGKDD Explorations 15(2):49-60, &lt;<a href="https://doi.org/10.1145/2641190.2641198">doi:10.1145/2641190.2641198</a>&gt;.
</p>
</li>
<li>
<p> Dua, D., Graff, C. (2019). UCI Machine Learning Repository. Irvine, CA: University of California, School of Information and Computer Science. <a href="https://archive.ics.uci.edu/ml/">https://archive.ics.uci.edu/ml/</a>.
</p>
</li>
</ul>
<h3>Examples</h3>

<pre><code class="language-R">
# Load data:
data(hars)

# Numbers of observations per outcome class:
table(hars$Activity)

# Dimension of data:
dim(hars)

# First rows of (subset) data:
head(hars[,1:5])

</code></pre>


</div>