<div class="container">

<table style="width: 100%;"><tr>
<td>binningDepth2D</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>2d Binning</h2>

<h3>Description</h3>

<p>A robust method of decreasing a sample size and therefore a complexity of a statistical procedure. The method may be used within a kernel density or a predictive distribution estimation.
</p>


<h3>Usage</h3>

<pre><code class="language-R">binningDepth2D(
  x,
  binmethod = "LocDepth",
  nbins = 8,
  k = 1,
  remove_borders = FALSE,
  depth_params = list(method = "LP")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>bivariate matrix containing data. Each row is viewed as one two-dimensional observation.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>binmethod</code></td>
<td>
<p>A method for calculation center and dispersion measures. "LocDepth" uses location-scale depth, MAD uses median and MAD in each dimension.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nbins</code></td>
<td>
<p>number of bins in each dimension</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>k</code></td>
<td>
<p>responsible for tightness of bins.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>remove_borders</code></td>
<td>
<p>Logical, include or not marginal bins</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>depth_params</code></td>
<td>
<p>other arguments passed to depthMedian</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Let us recall, that binning is a popular method of decreasing a sample size. To bin a window of <code class="reqn"> n </code> points <code class="reqn"> {W}_{i, n} = \left\{ {X}_{i - n + 1}, ..., {X}_{i} \right\} </code> to a grid <code class="reqn"> {{{X}'}_{1}}, ..., {{{X}'}_{m}} </code> we simply assign each sample point <code class="reqn"> {{X}_{i}} </code> to the nearest grid point <code class="reqn"> {{{X}'}_{j}} </code>. When binning is completed, each grid point <code class="reqn"> {{X}'}_{j} </code> has an associated number <code class="reqn"> {c}_{i} </code>, which is the sum of all the points that have been assigned to <code class="reqn"> {{X}'}_{j} </code>. This procedure replaces the data <code class="reqn"> {W}_{i, n} = \left\{ {X}_{i - n + 1}, ..., {X}_{i} \right\} </code> with the smaller set <code class="reqn"> {{W}'}_{j, m} = \left\{ {{X}'}_{j - m + 1}, ..., {{X}'}_{j} \right\} </code>. Although simple binning can speed up the computation, it is criticized for a lack of precise approximate control over the accuracy of the approximation. Robust binning however stresses properties of the majority of the data and decreases the computational complexity of the DSA at the same time.
</p>
<p>For a 1D window <code class="reqn"> {W}_{i, n} </code>, let <code class="reqn"> {Z}_{i, n - k} </code> denote a 2D window created basing on <code class="reqn"> {W}_{i, n} </code> and consisted of <code class="reqn"> n - k </code> pairs of observations and the <code class="reqn"> k </code> lagged observations <code class="reqn"> {Z}_{i, n - k} = \left\{\left( {X}_{i - n - k}, {X}_{i - n + 1} \right)\right\}, 1\le i\le n - k </code>. Robust 2D binning of the <code class="reqn"> {Z}_{i, n - p} </code> is a very useful technique in a context of robust estimation of the predictive distribution of a time series (see <cite>Kosiorowski:2013b</cite>).
</p>
<p>Assume we analyze a data stream <code class="reqn"> \{{X}_{t}\} </code> using a moving window of a fixed length <code class="reqn"> n </code>, i.e., <code class="reqn"> {W}_{i, n} </code> and the derivative window <code class="reqn"> {Z}_{i, n - 1} </code>. In a first step we calculate the weighted sample <code class="reqn"> L ^ p </code> depth for <code class="reqn"> {W}_{i, n} </code>. Next we choose equally spaced grid of points <code class="reqn"> {l}_{1}, ..., {l}_{m} </code> in this way that <code class="reqn"> [{{l}_{1}}, {{l}_{m}}] \times [{{l}_{1}}, {{l}_{m}}] </code> covers fraction of the <code class="reqn"> \beta </code> central points of <code class="reqn"> {Z}_{i, n - 1} </code> w.r.t. the calculated <code class="reqn"> L ^ p </code> depth, i.e., it covers <code class="reqn"> {R} ^ {\beta}({Z}_{i, n - 1}) </code> for certain prefixed threshold <code class="reqn"> \beta \in (0, 1) </code>. For both <code class="reqn"> {X}_{t} </code> and <code class="reqn"> {X}_{t - 1} </code> we perform a simple binning using following bins: <code class="reqn"> (-\infty, {l}_{1}) </code>, <code class="reqn"> ({l}_{1}, {l}_{2}) </code>, ..., <code class="reqn"> ({l}_{m}, \infty) </code>. For robust binning we reject "border" classes and further use only midpoints and binned frequencies for classes <code class="reqn"> ({l}_{1}, {l}_{2}) </code>, <code class="reqn"> ({l}_{2}, {l}_{3}) </code>, ..., <code class="reqn"> ({l}_{m - 1}, {l}_{m}) </code>.
</p>


<h3>Value</h3>

<p>freq: a matrix containing the binned frequencies
</p>
<p>mid_x: mid points for x
</p>
<p>mid_y: mid points for y
</p>
<p>breaks_x: breaks for x
</p>
<p>breaks_y: breaks for y
</p>
<p>input_data: max_depth_x and max_depth_y:
</p>


<h3>Author(s)</h3>

<p>Daniel Kosiorowski and Zygmunt Zawadzki from Cracow University of Economics.
</p>


<h3>References</h3>

<p>Hall, P., Wand, M. P. (1996) On the Accuracy of Binned Kernel Density Estimators, Journal of Multivariate Analysis archive, Volume 56 Issue 2, 165–184
</p>
<p>Holmstrom, L. (2000) The Accuracy and the Computational Complexity of a Multivariate Binned Kernel Density Estimator, Journal of Multivariate Analysis, Volume 72, Issue 2, 264–309, doi: <a href="https://doi.org/10.1006/jmva.1999.1863">10.1006/jmva.1999.1863</a>. (<a href="https://www.sciencedirect.com/science/article/pii/S0047259X99918638">https://www.sciencedirect.com/science/article/pii/S0047259X99918638</a>)
</p>


<h3>See Also</h3>

<p><code>depth</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">
# EXAMPLE 1
Sigma1 &lt;- matrix(c(10, 3, 3, 2), 2, 2)
X1 &lt;- mvrnorm(n = 8500, mu = c(0, 0), Sigma1)
Sigma2 &lt;- matrix(c(10, 0, 0, 2), 2, 2)
X2 &lt;- mvrnorm(n = 1500, mu = c(-10, 6), Sigma2)
BALLOT &lt;- rbind(X1, X2)
train &lt;- sample(1:10000, 500)
data &lt;- BALLOT[train, ]
plot(data)

b1 &lt;- binningDepth2D(data, remove_borders = FALSE, nbins = 12, k = 1)
b2 &lt;- binningDepth2D(data, nbins = 12, k = 1, remove_borders = TRUE)
plot(b1)
plot(b2)

# EXAMPLE 2
data(under5.mort)
data(maesles.imm)
data2011 &lt;- cbind(under5.mort[, 22], maesles.imm[, 22])
plot(binningDepth2D(data2011, nbins = 8, k = 0.5, remove_borders = TRUE))

</code></pre>


</div>