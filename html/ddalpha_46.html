<div class="container">

<table style="width: 100%;"><tr>
<td>ddalphaf.train</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
Functional DD-Classifier
</h2>

<h3>Description</h3>

<p>Trains the functional DD-classifier
</p>


<h3>Usage</h3>

<pre><code class="language-R">ddalphaf.train(dataf, labels, subset, 
                adc.args = list(instance = "avr", 
                               numFcn = -1, 
                               numDer = -1), 
                classifier.type = c("ddalpha", "maxdepth", "knnaff", "lda", "qda"), 
                cv.complete = FALSE, 
                maxNumIntervals = min(25, ceiling(length(dataf[[1]]$args)/2)),
                seed = 0,
                ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>dataf</code></td>
<td>

<p>list containing lists (functions) of two vectors of equal length, named "args" and "vals": arguments sorted in ascending order and corresponding them values respectively
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>labels</code></td>
<td>

<p>list of output labels of the functional observations
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>subset</code></td>
<td>

<p>an optional vector specifying a subset of observations to be used in training the classifier.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>adc.args</code></td>
<td>

<p>Represents a function sample as a multidimensional (dimension=<code>"numFcn"+"numDer"</code>) 
one averaging (<code>instance = "avr"</code>) or evaluating (<code>instance = "val"</code>) for that each function and it derivative on <code>"numFcn"</code> 
(resp. <code>"numDer"</code>) equal nonoverlapping covering intervals
</p>
<p>First two named <code>"args"</code> and <code>"vals"</code> are arguments sorted in 
ascending order and having same bounds for all functions and 
corresponding them values respectively
</p>

<dl>
<dt>instance</dt>
<dd>
<p>type of discretizing the functions: <br>
"avr" - by averaging over intervals of the same length <br>
"val" - by taking values on equally-spaced grid
</p>
</dd>
<dt>numFcn</dt>
<dd>
<p>number of function intervals
</p>
</dd>  
<dt>numDer</dt>
<dd>
<p>number of first-derivative intervals 
</p>
</dd>
</dl>
<p>Set <code>numFcn</code> and <code>numDer</code> to -1 to apply cross-validation.
</p>
<p>Set  <code>adc.args</code> to a list of "adc.args" objects to cross-validate only over these values.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>classifier.type</code></td>
<td>

<p>the classifier which is used on the transformed space. The default value is 'ddalpha'.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cv.complete</code></td>
<td>

<p>T: apply complete cross-validation<br>
F: restrict cross-validation by Vapnik-Chervonenkis bound
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>maxNumIntervals</code></td>
<td>

<p>maximal number of intervals for cross-validation ( max(numFcn + numDer) = maxNumIntervals )
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>seed</code></td>
<td>

<p>the random seed. The default value <code>seed=0</code> makes no changes.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>

<p>additional parameters, passed to the classifier, selected with parameter <code>classifier.type</code>.
</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The functional DD-classifier is fast nonparametric procedure for classifying functional data. It consists of
a two-step transformation of the original data plus a classifier operating on a low-dimensional
hypercube. The functional data are first mapped into a finite-dimensional location-slope space
and then transformed by a multivariate depth function into the DD-plot, which is a subset of
the unit hypercube. This transformation yields a new notion of depth for functional data. Three
alternative depth functions are employed for this, as well as two rules for the final classification. 
The resulting classifier is cross-validated over a small range of parameters only,
which is restricted by a Vapnik-Cervonenkis bound. The entire methodology does not involve
smoothing techniques, is completely nonparametric and allows to achieve Bayes optimality under
standard distributional settings. It is robust and efficiently computable.
</p>


<h3>Value</h3>

<p>Trained functional DD-classifier




</p>


<h3>References</h3>

<p>Mosler, K. and Mozharovskyi, P. (2017). Fast DD-classification of functional data. <em>Statistical Papers</em> <b>58</b> 1055â€“1089.
</p>
<p>Mozharovskyi, P. (2015). <em>Contributions to Depth-based Classification and Computation of the Tukey Depth</em>. Verlag Dr. Kovac (Hamburg).
</p>


<h3>See Also</h3>

<p><code>ddalphaf.classify</code> for classification using functional DD<code class="reqn">\alpha</code>-classifier,
<code>compclassf.train</code> to train the functional componentwise classifier,
<code>dataf.*</code> for functional data sets included in the package.
</p>


<h3>Examples</h3>

<pre><code class="language-R">
## Not run: 

## load the Growth dataset
dataf = dataf.growth()

learn = c(head(dataf$dataf, 49), tail(dataf$dataf, 34))
labels= c(head(dataf$labels, 49), tail(dataf$labels, 34)) 
test  = tail(head(dataf$dataf, 59), 10)    # elements 50:59. 5 girls, 5 boys

#cross-validate over the whole variants up to dimension 3
c1 = ddalphaf.train (learn, labels, classifier.type = "ddalpha", maxNumIntervals = 3)

classified1 = ddalphaf.classify(c1, test)

print(unlist(classified1))
print(c1$adc.args) 

# cross-validate over these two variants
c2 = ddalphaf.train (learn, labels, classifier.type = "ddalpha", 
                     adc.args = list(
                       list(instance = "avr", 
                            numFcn = 1, 
                            numDer = 2),
                       list(instance = "avr", 
                            numFcn = 0, 
                            numDer = 2)))

classified2 = ddalphaf.classify(c2, test)

print(unlist(classified2))
print(c2$adc.args) 


## End(Not run)
</code></pre>


</div>