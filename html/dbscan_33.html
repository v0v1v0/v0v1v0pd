<div class="container">

<table style="width: 100%;"><tr>
<td>extractFOSC</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Framework for the Optimal Extraction of Clusters from Hierarchies</h2>

<h3>Description</h3>

<p>Generic reimplementation of the <em>Framework for Optimal Selection of Clusters</em>
(FOSC; Campello et al, 2013) to extract clusterings from hierarchical clustering (i.e.,
hclust objects).
Can be parameterized to perform unsupervised
cluster extraction through a stability-based measure, or semisupervised
cluster extraction through either a constraint-based extraction (with a
stability-based tiebreaker) or a mixed (weighted) constraint and
stability-based objective extraction.
</p>


<h3>Usage</h3>

<pre><code class="language-R">extractFOSC(
  x,
  constraints,
  alpha = 0,
  minPts = 2L,
  prune_unstable = FALSE,
  validate_constraints = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>a valid hclust object created via <code>hclust()</code> or <code>hdbscan()</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>constraints</code></td>
<td>
<p>Either a list or matrix of pairwise constraints. If
missing, an unsupervised measure of stability is used to make local cuts and
extract the optimal clusters. See details.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>alpha</code></td>
<td>
<p>numeric; weight between <code class="reqn">[0, 1]</code> for mixed-objective
semi-supervised extraction. Defaults to 0.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>minPts</code></td>
<td>
<p>numeric; Defaults to 2. Only needed if class-less noise is a
valid label in the model.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>prune_unstable</code></td>
<td>
<p>logical; should significantly unstable subtrees be
pruned? The default is <code>FALSE</code> for the original optimal extraction
framework (see Campello et al, 2013). See details for what <code>TRUE</code>
implies.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>validate_constraints</code></td>
<td>
<p>logical; should constraints be checked for
validity? See details for what are considered valid constraints.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Campello et al (2013) suggested a <em>Framework for Optimal Selection of
Clusters</em> (FOSC) as a framework to make local (non-horizontal) cuts to any
cluster tree hierarchy. This function implements the original extraction
algorithms as described by the framework for hclust objects. Traditional
cluster extraction methods from hierarchical representations (such as
hclust objects) generally rely on global parameters or cutting values
which are used to partition a cluster hierarchy into a set of disjoint, flat
clusters. This is implemented in R in function <code>cutree()</code>.
Although such methods are widespread, using global parameter
settings are inherently limited in that they cannot capture patterns within
the cluster hierarchy at varying <em>local</em> levels of granularity.
</p>
<p>Rather than partitioning a hierarchy based on the number of the cluster one
expects to find (<code class="reqn">k</code>) or based on some linkage distance threshold
(<code class="reqn">H</code>), the FOSC proposes that the optimal clusters may exist at varying
distance thresholds in the hierarchy. To enable this idea, FOSC requires one
parameter (minPts) that represents <em>the minimum number of points that
constitute a valid cluster.</em> The first step of the FOSC algorithm is to
traverse the given cluster hierarchy divisively, recording new clusters at
each split if both branches represent more than or equal to minPts. Branches
that contain less than minPts points at one or both branches inherit the
parent clusters identity. Note that using FOSC, due to the constraint that
minPts must be greater than or equal to 2, it is possible that the optimal
cluster solution chosen makes local cuts that render parent branches of
sizes less than minPts as noise, which are denoted as 0 in the final
solution.
</p>
<p>Traversing the original cluster tree using minPts creates a new, simplified
cluster tree that is then post-processed recursively to extract clusters
that maximize for each cluster <code class="reqn">C_i</code> the cost function
</p>
<p style="text-align: center;"><code class="reqn">\max_{\delta_2, \dots, \delta_k} J = \sum\limits_{i=2}^{k} \delta_i
S(C_i)</code>
</p>
<p> where
<code class="reqn">S(C_i)</code> is the stability-based measure as </p>
<p style="text-align: center;"><code class="reqn"> S(C_i) =
\sum_{x_j \in C_i}(\frac{1}{h_{min} (x_j, C_i)} - \frac{1}{h_{max} (C_i)})
</code>
</p>

<p><code class="reqn">\delta_i</code> represents an indicator function, which constrains
the solution space such that clusters must be disjoint (cannot assign more
than 1 label to each cluster). The measure <code class="reqn">S(C_i)</code> used by FOSC
is an unsupervised validation measure based on the assumption that, if you
vary the linkage/distance threshold across all possible values, more
prominent clusters that survive over many threshold variations should be
considered as stronger candidates of the optimal solution. For this reason,
using this measure to detect clusters is referred to as an unsupervised,
<em>stability-based</em> extraction approach. In some cases it may be useful
to enact <em>instance-level</em> constraints that ensure the solution space
conforms to linkage expectations known <em>a priori</em>. This general idea of
using preliminary expectations to augment the clustering solution will be
referred to as <em>semisupervised clustering</em>. If constraints are given in
the call to <code>extractFOSC()</code>, the following alternative objective function
is maximized:
</p>
<p style="text-align: center;"><code class="reqn">J = \frac{1}{2n_c}\sum\limits_{j=1}^n \gamma (x_j)</code>
</p>

<p><code class="reqn">n_c</code> is the total number of constraints given and
<code class="reqn">\gamma(x_j)</code> represents the number of constraints involving
object <code class="reqn">x_j</code> that are satisfied. In the case of ties (such as
solutions where no constraints were given), the unsupervised solution is
used as a tiebreaker. See Campello et al (2013) for more details.
</p>
<p>As a third option, if one wishes to prioritize the degree at which the
unsupervised and semisupervised solutions contribute to the overall optimal
solution, the parameter <code class="reqn">\alpha</code> can be set to enable the extraction of
clusters that maximize the <code>mixed</code> objective function
</p>
<p style="text-align: center;"><code class="reqn">J = \alpha S(C_i) + (1 - \alpha) \gamma(C_i))</code>
</p>

<p>FOSC expects the pairwise constraints to be passed as either 1) an
<code class="reqn">n(n-1)/2</code> vector of integers representing the constraints, where 1
represents should-link, -1 represents should-not-link, and 0 represents no
preference using the unsupervised solution (see below for examples).
Alternatively, if only a few constraints are needed, a named list
representing the (symmetric) adjacency list can be used, where the names
correspond to indices of the points in the original data, and the values
correspond to integer vectors of constraints (positive indices for
should-link, negative indices for should-not-link). Again, see the examples
section for a demonstration of this.
</p>
<p>The parameters to the input function correspond to the concepts discussed
above. The <code>minPts</code> parameter to represent the minimum cluster size to
extract. The optional <code>constraints</code> parameter contains the pairwise,
instance-level constraints of the data. The optional <code>alpha</code> parameters
controls whether the mixed objective function is used (if <code>alpha</code> is
greater than 0). If the <code>validate_constraints</code> parameter is set to
true, the constraints are checked (and fixed) for symmetry (if point A has a
should-link constraint with point B, point B should also have the same
constraint). Asymmetric constraints are not supported.
</p>
<p>Unstable branch pruning was not discussed by Campello et al (2013), however
in some data sets it may be the case that specific subbranches scores are
significantly greater than sibling and parent branches, and thus sibling
branches should be considered as noise if their scores are cumulatively
lower than the parents. This can happen in extremely nonhomogeneous data
sets, where there exists locally very stable branches surrounded by unstable
branches that contain more than <code>minPts</code> points.
<code>prune_unstable = TRUE</code> will remove the unstable branches.
</p>


<h3>Value</h3>

<p>A list with the elements:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>cluster </code></td>
<td>
<p>A integer vector with cluster assignments. Zero
indicates noise points (if any).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>hc </code></td>
<td>
<p>The original hclust object with additional list elements
<code>"stability"</code>, <code>"constraint"</code>, and <code>"total"</code>
for the <code class="reqn">n - 1</code> cluster-wide objective scores from the extraction.</p>
</td>
</tr>
</table>
<h3>Author(s)</h3>

<p>Matt Piekenbrock
</p>


<h3>References</h3>

<p>Campello, Ricardo JGB, Davoud Moulavi, Arthur Zimek, and Joerg
Sander (2013). A framework for semi-supervised and unsupervised optimal
extraction of clusters from hierarchies. <em>Data Mining and Knowledge
Discovery</em> 27(3): 344-371.
<a href="https://doi.org/10.1007/s10618-013-0311-4">doi:10.1007/s10618-013-0311-4</a>
</p>


<h3>See Also</h3>

<p><code>hclust()</code>, <code>hdbscan()</code>, <code>stats::cutree()</code>
</p>
<p>Other clustering functions: 
<code>dbscan()</code>,
<code>hdbscan()</code>,
<code>jpclust()</code>,
<code>optics()</code>,
<code>sNNclust()</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">data("moons")

## Regular HDBSCAN using stability-based extraction (unsupervised)
cl &lt;- hdbscan(moons, minPts = 5)
cl$cluster

## Constraint-based extraction from the HDBSCAN hierarchy
## (w/ stability-based tiebreaker (semisupervised))
cl_con &lt;- extractFOSC(cl$hc, minPts = 5,
  constraints = list("12" = c(49, -47)))
cl_con$cluster

## Alternative formulation: Constraint-based extraction from the HDBSCAN hierarchy
## (w/ stability-based tiebreaker (semisupervised)) using distance thresholds
dist_moons &lt;- dist(moons)
cl_con2 &lt;- extractFOSC(cl$hc, minPts = 5,
  constraints = ifelse(dist_moons &lt; 0.1, 1L,
                ifelse(dist_moons &gt; 1, -1L, 0L)))

cl_con2$cluster # same as the second example
</code></pre>


</div>