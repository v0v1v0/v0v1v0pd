<div class="container">

<table style="width: 100%;"><tr>
<td>bestsetNoise</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Best Subset Selection Applied to Noise</h2>

<h3>Description</h3>

<p>Best subset selection applied to completely random noise.  This
function demonstrates how variable selection techniques in
regression can often err in including explanatory variables that
are indistinguishable from noise.
</p>


<h3>Usage</h3>

<pre><code class="language-R">bestsetNoise(m = 100, n = 40, method = "exhaustive", nvmax = 3,
              X = NULL, y=NULL, intercept=TRUE,
              print.summary = TRUE, really.big = FALSE, ...)

bestset.noise(m = 100, n = 40, method = "exhaustive", nvmax = 3,
              X = NULL, y=NULL, intercept=TRUE,
              print.summary = TRUE, really.big = FALSE, ...)

bsnCV(m = 100, n = 40, method = "exhaustive", nvmax = 3,
              X = NULL, y=NULL, intercept=TRUE, nfolds = 2,
              print.summary = TRUE, really.big = FALSE)

bsnOpt(X = matrix(rnorm(25 * 10), ncol = 10), y = NULL, method = "exhaustive",
              nvmax = NULL, nbest = 1, intercept = TRUE, criterion = "cp",
              tcrit = NULL, print.summary = TRUE, really.big = FALSE,
         ...)

bsnVaryNvar(m = 100, nvar = nvmax:50, nvmax = 3, method = "exhaustive",
              intercept=TRUE,
              plotit = TRUE, xlab = "# of variables from which to select",
              ylab = "p-values for t-statistics", main = paste("Select 'best'",
                                                  nvmax, "variables"),
              details = FALSE, really.big = TRUE, smooth = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>m</code></td>
<td>
<p>the number of observations to be simulated, ignored if X is supplied.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>n</code></td>
<td>
<p>the number of predictor variables in the simulated
model, ignored if X is supplied.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>method</code></td>
<td>
<p>Use <code>exhaustive</code> search, or <code>backward</code> selection,
or <code>forward</code> selection, or <code>sequential</code> replacement.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nvmax</code></td>
<td>
<p>Number of explanatory variables in model.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>X</code></td>
<td>
<p>Use columns from this matrix.  Alternatively, X may be a
data frame, in which case a model matrix will be formed from it.
If not <code>NULL</code>, <code>m</code> and <code>n</code> are ignored.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>
<p>If not supplied, random normal noise will be generated.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nbest</code></td>
<td>
<p>Number of models, for each choice of number of columns
of explanatory variables, to return (<code>bsnOpt</code>). If <code>tcrit</code>
is non-NULL, it may be important to set this greater than one, in
order to have a good chance of finding models with minimum absolute
<em>t</em>-statistic greater than <code>tcrit</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>intercept</code></td>
<td>
<p>Should an intercept be added?</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nvar</code></td>
<td>
<p>range of number of candidate variables (<code>bsnVaryVvar</code>).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nfolds</code></td>
<td>
<p>For splitting the data into training and text sets,
the number of folds.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>criterion</code></td>
<td>
<p>Criterion to use in choosing between models with
different numbers of explanatory variables (<code>bsnOpt</code>).
Alternatives are “bic”, or “cip” or “adjr2”.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tcrit</code></td>
<td>
<p>Consider only those models for which the minimum absolute
<em>t</em>-statistic is greater than <code>tcrit</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>print.summary</code></td>
<td>
<p>Should summary information be printed.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>plotit</code></td>
<td>

<p>Plot a graph? (<code>bsnVaryVvar</code>)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>xlab</code></td>
<td>

<p><em>x</em>-label for graph (<code>bsnVaryVvar</code>)
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ylab</code></td>
<td>

<p><em>y</em>-label for graph (<code>bsnVaryVvar</code>.)
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>main</code></td>
<td>

<p>main title for graph (<code>bsnVaryVvar</code>.)
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>details</code></td>
<td>
<p>Return detailed output list (<code>bsnVaryVvar</code>)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>really.big</code></td>
<td>
<p>Set to <code>TRUE</code> to allow (currently) for more than
50 explanatory variables.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>smooth</code></td>
<td>
<p>Fit smooth to graph? (<code>bsnVaryVvar</code>).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>Additional arguments, to be passed through to
<code>regsubsets()</code>.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>If <code>X</code> is not supplied, and in any case for <code>bsnVaryNvar</code>, a
set of <code>n</code> predictor variables are simulated as independent
standard normal, i.e. N(0,1), variates.  Additionally a N(0,1) response
variable is simulated.  The function <code>bsnOpt</code> selects the
‘best’ model with <code>nvmax</code> or fewer explanatory variables,
where the argument <code>criterion</code> specifies the criterion that will
be used to choose between models with different numbers of explanatory
columns.  Other functions select the ‘best’ model with
<code>nvmax</code> explanatory columns.  In any case, the selection is made
using the <code>regsubsets()</code> function from the leaps package.
(The leaps package must be installed for this function to work.)
</p>
<p>The function <code>bsnCV</code> splits the data (randomly) into <code>nfolds</code>
(2 or more) parts.  It puts each part aside in turn for use to fit
the model (effectively, test data), with the remaining data used
for selecting the variables that will be used for fitting. One model
fit is returned for each of the <code>nfolds</code> parts.
</p>
<p>The function <code>bsnVaryVvar</code> makes repeated calls to
<code>bestsetNoise</code>
</p>


<h3>Value</h3>

<p><code>bestsetNoise</code> returns the <code>lm</code> model object for the "best"
model with <code>nvmax</code> explanatory columns.
</p>
<p><code>bsnCV</code> returns as many models as there are folds.
</p>
<p><code>bsnVaryVvar</code> silently returns either (<code>details=FALSE</code>) a
matrix that has <em>p</em>-values of the coefficients for the ‘best’
choice of model for
each different number of candidate variables, or
(<code>details=TRUE</code>) a list with elements:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>coef</code></td>
<td>
<p>A matrix of sets of regression coefficients</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>SE</code></td>
<td>
<p>A matrix of standard errors</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pval</code></td>
<td>
<p>A matrix of <em>p</em>-values</p>
</td>
</tr>
</table>
<p>Matrices have one row for each choice of <code>nvar</code>.  The statistics
returned are for the ‘best’ model with nvmax explanatory
variables.
</p>
<p><code>bsnOpt</code> silently returns a list with elements:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>u1</code></td>
<td>
<p>‘best’ model (<code>lm</code> object) with <code>nvmax</code> or
fewer columns of predictors. If <code>tcrit</code> is non-NULL, and there
is no model for which all coefficients have <em>t</em>-statistics
less than <code>tcrit</code> in absolute value, <code>u1</code> will be NULL.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tcrit</code></td>
<td>
<p>For each model, the minimum of the absolute values of
the <em>t</em>-statistics.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>regsubsets_obj</code></td>
<td>
<p>The object returned by the call to <code>regsubsets</code>.</p>
</td>
</tr>
</table>
<h3>Note</h3>

<p>These functions are primarily designed to demonstrate the biases
that can be expected, relative to theoretical estimates of standard
errors of parameters and other fitted model statistics, when there
is prior selection of the columns that are to be included in the
model. With the exception of <code>bsnVaryNvar</code>, they can also be
used with an <code>X</code> and <code>y</code> for actual data.  In that case,
the <em>p</em>-values should be compared with those
obtained from repeated use of the function where <code>y</code> is random
noise, as a check on the extent of selection effects.
</p>


<h3>Author(s)</h3>

<p>J.H. Maindonald</p>


<h3>See Also</h3>

 <p><code>lm</code></p>


<h3>Examples</h3>

<pre><code class="language-R">leaps.out &lt;- try(require(leaps, quietly=TRUE))
leaps.out.log &lt;- is.logical(leaps.out)
if ((leaps.out.log==TRUE)&amp;(leaps.out==TRUE)){
bestsetNoise(20,6) # `best' 3-variable regression for 20 simulated observations
                   # on 7 unrelated variables (including the response)
bsnCV(20,6) # `best' 3-variable regressions (one for each fold) for 20
                   # simulated observations on 7 unrelated variables
                   # (including the response)
bsnVaryNvar(m = 50, nvar = 3:6, nvmax = 3, method = "exhaustive",
            plotit=FALSE, details=TRUE)
bsnOpt()
}
</code></pre>


</div>