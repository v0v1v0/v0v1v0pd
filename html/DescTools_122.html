<div class="container">

<table style="width: 100%;"><tr>
<td>Conf</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Confusion Matrix And Associated Statistics

</h2>

<h3>Description</h3>

<p>Calculates a cross-tabulation of observed and predicted classes with associated statistics.

</p>


<h3>Usage</h3>

<pre><code class="language-R">Conf(x, ...)

## S3 method for class 'table'
Conf(x, pos = NULL, ...)
## S3 method for class 'matrix'
Conf(x, pos = NULL, ...)
## Default S3 method:
Conf(x, ref, pos = NULL, na.rm = TRUE, ...)

## S3 method for class 'rpart'
Conf(x, ...)
## S3 method for class 'multinom'
Conf(x, ...)
## S3 method for class 'glm'
Conf(x, cutoff = 0.5, pos = NULL, ...)
## S3 method for class 'randomForest'
Conf(x, ...)
## S3 method for class 'svm'
Conf(x, ...)
## S3 method for class 'regr'
Conf(x, ...)

## S3 method for class 'Conf'
plot(x, main = "Confusion Matrix", ...)

## S3 method for class 'Conf'
print(x, digits = max(3, getOption("digits") - 3), ...)

Sens(x, ...)
Spec(x, ...)

</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>a vector, normally a factor, of predicted classes or an object of following classes <code>rpart</code>, <code>randomForest</code>, <code>svm</code>, <code>C50</code>, <code>glm</code>, <code>multinom</code>, <code>reg</code>r, <code>ld</code>a, <code>qda</code> or <code>table</code>, resp. <code>matrix</code>. When a model is given, the predicted classes will be determined. A table or a matrix will be interpreted as a confusion matrix.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ref</code></td>
<td>
<p>a vector, normally a factor, of classes to be used as the reference. This is ignored if <code>x</code> is a <code>table</code> or <code>matrix</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pos</code></td>
<td>
<p>a character string that defines the factor level corresponding to the "positive" results. Will be ignored for a <code class="reqn">n \times n</code> table n &gt; 2.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cutoff</code></td>
<td>
<p>used in logit models. The cutoff for changing classes.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>main</code></td>
<td>
<p>overall title for the plot. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>digits</code></td>
<td>
<p>controls the number of digits to print.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>na.rm</code></td>
<td>
<p>a logical value indicating whether or not missing values should be removed. Defaults to <code>FALSE</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>further arguments to be passed to or from methods.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The functions require the factors to have the same levels.
</p>
<p>For two class problems, the sensitivity, specificity, positive
predictive value and negative predictive value is calculated using the
<code>positive</code> argument. Also, the prevalence of the "event" is computed from the
data (unless passed in as an argument), the detection rate (the rate of true events also
predicted to be events) and the detection prevalence (the prevalence of predicted events).
</p>
<p>Suppose a <code class="reqn">2 \times 2</code> table with notation
</p>

<table>
<tr>
<td style="text-align: right;">
                    </td>
<td style="text-align: center;"> Reference </td>
<td style="text-align: center;">          </td>
</tr>
<tr>
<td style="text-align: right;">
         Predicted  </td>
<td style="text-align: center;"> Event     </td>
<td style="text-align: center;"> No Event </td>
</tr>
<tr>
<td style="text-align: right;">
         Event      </td>
<td style="text-align: center;"> A         </td>
<td style="text-align: center;"> B        </td>
</tr>
<tr>
<td style="text-align: right;">
         No Event   </td>
<td style="text-align: center;"> C         </td>
<td style="text-align: center;"> D        </td>
</tr>
<tr>
<td style="text-align: right;">
       </td>
</tr>
</table>
<p>The formulas used here are:
</p>
<p style="text-align: center;"><code class="reqn">Sensitivity = A/(A+C)</code>
</p>

<p style="text-align: center;"><code class="reqn">Specificity = D/(B+D)</code>
</p>

<p style="text-align: center;"><code class="reqn">Prevalence = (A+C)/(A+B+C+D)</code>
</p>

<p style="text-align: center;"><code class="reqn">PPV = (sensitivity * Prevalence)/((sensitivity*Prevalence) + ((1-specificity)*(1-Prevalence)))</code>
</p>

<p style="text-align: center;"><code class="reqn">NPV = (specificity * (1-Prevalence))/(((1-sensitivity)*Prevalence) + ((specificity)*(1-Prevalence)))</code>
</p>

<p style="text-align: center;"><code class="reqn">Detection Rate =  A/(A+B+C+D)</code>
</p>

<p style="text-align: center;"><code class="reqn">Detection Prevalence =  (A+B)/(A+B+C+D)</code>
</p>

<p style="text-align: center;"><code class="reqn">F-val Accuracy =  2 / (1/PPV + 1/Sensitivity)</code>
</p>

<p style="text-align: center;"><code class="reqn">Matthews Cor.-Coef = (A*D-B*C)/sqrt((A+B)*(A+C)*(D+B)*(D+C)) </code>
</p>

<p>See the references for discusions of the first five formulas.
</p>
<p>For more than two classes, these results are
calculated comparing each factor level to the remaining levels
(i.e. a "one versus all" approach).
</p>
<p>The overall accuracy and unweighted Kappa statistic are calculated. A p-value from McNemar's test is also computed using <code>mcnemar.test</code> (which can produce <code>NA</code> values with sparse tables).
</p>
<p>The overall accuracy rate is computed along with a 95 percent confidence interval for this rate (using <code>BinomCI</code>) and a one-sided test to see if the accuracy is better than the "no information rate," which is taken to be the largest class percentage in the data.
</p>
<p>The sensitivity is defined as the proportion of positive results out of the number of
samples which were actually positive. When there are no positive results, sensitivity is
not defined and a value of <code>NA</code> is returned. Similarly, when there are no negative
results, specificity is not defined and a value of <code>NA</code> is returned. Similar
statements are true for predictive values.
</p>
<p>Confidence intervals for sensitivity, specificity etc. could be calculated as binomial confidence intervals (see <code>BinomCI</code>). <code>BinomCI(A, A+C)</code> yields the ci for sensitivity.
</p>


<h3>Value</h3>

<p>a list with elements
</p>
<table>
<tr style="vertical-align: top;">
<td><code>table</code></td>
<td>
<p>the results of <code>table</code> on <code>data</code> and  <code>reference</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>positive</code></td>
<td>
<p>the positive result level</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>overall</code></td>
<td>
<p>a numeric vector with overall accuracy and Kappa statistic values</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>byClass</code></td>
<td>
<p>the sensitivity, specificity, positive predictive value, negative predictive value, prevalence, dection rate and detection prevalence for each class. For two class systems, this is calculated once using the <code>positive</code> argument</p>
</td>
</tr>
</table>
<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt; <br>
rewritten based on the ideas of <code>confusionMatrix</code> by Max Kuhn &lt;Max.Kuhn@pfizer.com&gt;
</p>


<h3>References</h3>

<p>Kuhn, M. (2008) Building predictive models in R using the caret package <em>Journal of Statistical Software</em>, (<a href="https://www.jstatsoft.org/v28/i05/">https://www.jstatsoft.org/v28/i05/</a>).
</p>
<p>Powers, David M W (2011) Evaluation: From Precision, Recall and F-Measure to ROC, Informedness, Markedness &amp; Correlation (PDF). <em>Journal of Machine Learning Technologies</em> 2 (1): 37-63.
</p>
<p>Collett D (1999) Modelling Binary Data. <em>Chapman &amp; Hall/CRC</em>, Boca Raton Florida, pp. 24.
</p>
<p>Matthews, B. W. (1975) Comparison of the predicted and observed secondary structure of T4 phage lysozyme. <em>Biochimica et Biophysica Acta (BBA) - Protein Structure</em> 405 (2): 442-451. doi:10.1016/0005-2795(75)90109-9. PMID 1180967.
</p>


<h3>See Also</h3>

<p><code>OddsRatio</code>, <code>RelRisk</code>

</p>


<h3>Examples</h3>

<pre><code class="language-R"># let tab be a confusion table
tab &lt;- TextToTable("
   lo hi
lo 23 13
hi 10 18 ", dimnames=c("pred", "obs"))

Conf(tab, pos="hi")


pred &lt;- Untable(tab)[,"pred"]
obs &lt;- Untable(tab)[,"obs"]

Conf(x = pred, ref = obs)
Conf(x = pred, ref = obs, pos="hi")

Sens(tab)   # Sensitivity
Spec(tab)   # Specificity


tab &lt;- TextToTable("
      terrible poor marginal clear
terrible       10    4        1     0
poor            5   10       12     2
marginal        2    4       12     5
clear           0    2        6    13
", dimnames=c("pred", "obs"))

Conf(tab)
</code></pre>


</div>