<div class="container">

<table style="width: 100%;"><tr>
<td>LFDA</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2> Local Fisher Discriminant Analysis (LFDA)

</h2>

<h3>Description</h3>

<p> This function implements local Fisher discriminant analysis. It gives the discriminant function with the posterior possibility of each class.

</p>


<h3>Usage</h3>

<pre><code class="language-R">LFDA(x, y, r, prior = proportions,
CV = FALSE, usekernel = TRUE, fL = 0, 
tol, kernel = "gaussian", 
metric = c("orthonormalized", "plain", "weighted"), 
knn = 5, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p> Input training data

</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>
<p> Training labels

</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>r</code></td>
<td>
<p> Number of reduced features that will be kept

</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>prior</code></td>
<td>
<p> Prior possibility of each class

</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>CV</code></td>
<td>
<p> Whether to do cross validation

</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>usekernel</code></td>
<td>
<p> Whether to use the kernel discrimination in native bayes classifier

</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>fL</code></td>
<td>
<p> Feed to native bayes classifier. Factor for Laplace correction, default factor is 0, i.e. no correction.

</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tol</code></td>
<td>
<p> The tolerance used in Mabayes discrimination, see Mabayes

</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>kernel</code></td>
<td>
<p> If usekernel is TRUE, specifying the kernel names, see NaiveBaye.

</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>metric</code></td>
<td>
<p> The type of metric in the embedding space (no default), e.g., 'weighted',  weighted eigenvectors; 'orthonormalized' , orthonormalized; 'plain',  raw eigenvectors.

</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>knn</code></td>
<td>
<p> Number of nearest neighbors

</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p> additional arguments for the classifier

</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The results give the classified classes and the posterior possibility of each class using different classifier.

</p>


<h3>Value</h3>



<table>
<tr style="vertical-align: top;">
<td><code>class</code></td>
<td>
<p>The class labels</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>posterior</code></td>
<td>
<p>The posterior possibility of each class</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>bayes_judgement</code></td>
<td>
<p>Discrimintion results using the Mabayes classifier</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>bayes_assigment</code></td>
<td>
<p>Discrimintion results using the Naive bayes classifier</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Z </code></td>
<td>
<p>The reduced features</p>
</td>
</tr>
</table>
<h3>Author(s)</h3>

<p>qinxinghu@gmail.com

</p>


<h3>References</h3>

<p>Sugiyama, M (2007). Dimensionality reduction of multimodal labeled data by local Fisher discriminant analysis. Journal of Machine Learning Research, vol.8, 1027-1061.
</p>
<p>Sugiyama, M (2006). Local Fisher discriminant analysis for supervised dimensionality reduction. In W. W. Cohen and A. Moore (Eds.), Proceedings of 23rd International Conference on Machine Learning (ICML2006), 905-912.
</p>
<p>Tang, Y., &amp; Li, W. (2019). lfda: Local Fisher Discriminant Analysis inR. Journal of Open Source Software, 4(39), 1572.
</p>
<p>Moore, A. W. (2004). Naive Bayes Classifiers. In School of Computer Science. Carnegie Mellon University.
</p>
<p>Pierre Enel (2020). Kernel Fisher Discriminant Analysis (https://www.github.com/p-enel/MatlabKFDA), GitHub. Retrieved March 30, 2020.

</p>


<h3>Examples</h3>

<pre><code class="language-R">LFDAtest=LFDA(iris[,1:4],y=iris[,5],r=3, 
CV=FALSE,usekernel = TRUE, fL = 0,
kernel="gaussian",metric = "plain",knn = 6,tol = 1)
LFDApred=predict.LFDA(LFDAtest,iris[1:10,1:4],prior=NULL)
</code></pre>


</div>