<div class="container">

<table style="width: 100%;"><tr>
<td>dfba_binomial</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Bayesian Binomial Rate Parameter Inference</h2>

<h3>Description</h3>

<p>Given binomial frequency data, provides a Bayesian analysis for the
population binomial rate parameter.
</p>


<h3>Usage</h3>

<pre><code class="language-R">dfba_binomial(n1, n2, a0 = 1, b0 = 1, prob_interval = 0.95)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>n1</code></td>
<td>
<p>Integer number of binomial observations for a category 1 response (<em>e.g.</em>, the number of successes)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>n2</code></td>
<td>
<p>Integer number of binomial observations for a category 2 response (<em>e.g.</em>, the number of failures)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>a0</code></td>
<td>
<p>The first shape parameter for the prior beta distribution that corresponds to the population binomial parameter (default is 1). Must be positive and finite.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>b0</code></td>
<td>
<p>The second shape parameter for the prior beta distribution for the population binomial rate parameter (default is 1). Must be positive and finite.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>prob_interval</code></td>
<td>
<p>Probability within interval estimates for the population binomial rate parameter (default is .95)</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The binomial distribution with size = <code class="reqn">n</code> and probability = <code class="reqn">\phi</code> has
discrete probabilities
</p>
<p style="text-align: center;"><code class="reqn">p(x) = \frac{n!}{z!(n - x!)}\phi^{x}(1-\phi)^{n-x}</code>
</p>

<p>where x is an integer from 0 to <code class="reqn">n</code> in steps of 1. The binomial model
assumes a Bernoulli process of independent trials where there are binary
outcomes that have the same probability (say, <code class="reqn">\phi</code>) for a response in
one of the two categories and a probability of <code class="reqn">1-\phi</code> for the other
category. Before any data are collected, there are <code class="reqn">n + 1</code> possible
values for <code class="reqn">x</code> number of outcomes in category 1 and <code class="reqn">n - x</code> number of
outcomes in category 2. The binomial distribution is a likelihood
distribution. A likelihood is the probability of an outcome given a specific
value for the population rate parameter. Yet for real applications, the
population parameter is not known. All that is known are the outcomes
observed from a set of binomial trials. The binomial inference problem is to
estimate the population <code class="reqn">\phi</code> parameter based on the sample data.
</p>
<p>The frequentist approach to statistics is based on the relative frequency
method of assigning probability values (Ellis, 1842). From this framework,
there are no probabilities for anything that does not have a relative
frequency (von Mises, 1957). In frequency theory, the <code class="reqn">\phi</code> parameter
does not have a relative frequency, so it cannot have a probability
distribution. From a frequentist framework, a value for the binomial rate
parameter is <em>assumed</em>, and there is a discrete distribution for the <code class="reqn">n + 1</code>
outcomes for <code class="reqn">x</code> from 0 to <code class="reqn">n</code>. The discrete likelihood distribution
has relative frequency over repeated experiments. Thus, for the frequentist
approach, <code class="reqn">x</code> is a random variable, and <code class="reqn">\phi</code> is an unknown fixed
constant. Frequency theory thus delibrately eschews the idea of the binomial
rate parameter having a probability distribution. Laplace (1774) had
previously employed a Bayesian approach of treating the <code class="reqn">\phi</code> parameter
as a random variable. Yet Ellis and other researchers within the frequentist
tradition delibrately rejected the Bayes/Laplace approach. For tests of a
null hypothesis of an assumed <code class="reqn">\phi</code> value, the frequentist approach either
continues to assume the null hypothesis or it rejects the null hypothesis
depending on the likelihood of the observed data plus the likelihood of more
extreme unobserved outcomes. The confidence interval is the range of <code class="reqn">\phi</code>
values where the null hypothesis of specific <code class="reqn">\phi</code> values would be
retained given the observed data (Clopper &amp; Pearson, 1934). However, the
frequentist confidence interval is not a probability interval since
population parameters cannot have a probability distribution with frequentist
methods. Frequentist statisticians were well aware (<em>e.g.</em>, Pearson, 1920)
that if the <code class="reqn">\phi</code> parameter had a distribution, then the Bayes/Laplace
approach would be correct.
</p>
<p>Bayesian statistics rejects the frequentist theoretical decisions as to what
are the fixed constants and what is the random variable that can take on a
range of values. From a Bayesian framework, probability is anything that
satisfies the Kolmogorov (1933) axioms, so probabilities need not be limited
to processes that have a relative frequency. Importantly, probability can be
a measure of information or knowledge provided that the probability
representation meets the Kolmogorov axioms (De Finetti, 1974). Given binomial
data, the population binomial rate parameter <code class="reqn">\phi</code> is unknown, so it is
represented with a probability distribution for its possible values. This
assumed distribution is the prior distribution. Furthermore, the quantity <code class="reqn">x</code>
for the likelihood distribution above is not a random variable once the
experiment has been conducted. If there are <code class="reqn">n_1</code> outcomes for category 1
and <code class="reqn">n_2 = n-n_1</code> outcomes in category 2, then these are fixed values.
While frequentist methods compute both the likelihood of the observed
outcome <em>and</em> the likelihood for unobserved outcomes that are more
extreme, in Bayesian inference it is <em>only</em> the likelihood of the observed
outcome that is computed. From the Bayesian perspective, the inclusion of
unobserved outcomes in the analysis violates the likelihood principle (Berger
&amp; Wolpert, 1988). A number of investigators have found paradoxes with
frequentist procedures when the likelihood principle is not used (<em>e.g.</em>,
Lindley &amp; Phillips, 1976; Chechile, 2020). The Bayesian practice of strictly
computing only the likelihood of the observed data produces the result that
the likelihood for the binomial is proportional to <code class="reqn">\phi^{n_1}(1 - \phi)^{n_2}</code>.
In Bayesian statistics, the proportionality constant is not needed because it
appears in both the numerator and the denominator of Bayes theorem and thus
cancels. See Chechile (2020) for more extensive comparisons between
frequentist and Bayesian approaches with a particular focus on the binomial
model.
</p>
<p>Given a beta distribution prior for the binomial <code class="reqn">\phi</code> parameter, it has
been shown that the resulting posterior distribution from Bayes theorem is
another member of the beta family of distributions (Lindley &amp; Phillips, 1976).
This property of the prior and posterior being in the same distributional
family is called <em>conjugacy</em>. The beta distribution is a natural Bayesian
conjugate function for all Bernoulli processes where the likelihood is
proportional to <code class="reqn">\phi^{n_1}(1 - \phi)^{n_2}</code> (Chechile, 2020).
The density function for a beta variate is
</p>
<p style="text-align: center;"><code class="reqn">f(x) = \begin{cases} Kx^{a-1}(1-x)^{b-1} &amp; \quad \textrm{if } 0 \le x \le 1, \\0 &amp; \quad \textrm{otherwise} \end{cases}</code>
</p>

<p>where </p>
<p style="text-align: center;"><code class="reqn">K = \frac{\Gamma(a + b)}{\Gamma(a)\Gamma(b)}</code>
</p>

<p>(Johnson, Kotz, &amp; Balakrishnan, 1995). The two shape parameters <code class="reqn">a</code> and <code class="reqn">b</code>
must be positive values. If the beta prior shape parameters are a0 and b0,
then the posterior beta shape parameters are <code class="reqn">a_{post} = a_0 + n_1</code> and
<code class="reqn">b_{post} = b_0 + n_2</code>. The default prior for the <code>dfba_binomial()</code>
function is <code>a0 = b0 = 1</code>, which corresponds to the uniform prior.
</p>
<p>Thus, the Bayesian inference for the unknown binomial rate parameter <code class="reqn">phi</code>
is the posterior beta distribution with shape parameters of <code>a_post</code> and
<code>b_post</code>. The <code>dfba_binomial()</code> function calls the
<code>dfba_beta_descriptive()</code> function to find the centrality point estimates
(<em>i.e.</em>, the mean, median, and mode) and to find two interval estimates
that contain the probability specified in the <code>prob_interval</code> argument.
One interval has equal-tail probabilities and the other interval is the
highest-density interval. Users can use the <code>dfba_beta_bayes_factor()</code>
function to test hypotheses about the <code class="reqn">\phi</code> parameter.
</p>


<h3>Value</h3>

<p>A list containing the following components:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>n1</code></td>
<td>
<p>Observed number of category 1 responses</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>n2</code></td>
<td>
<p>Observed number of category 2 responses</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>a0</code></td>
<td>
<p>First shape parameter for the prior beta distribution of the binomial rate parameter</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>b0</code></td>
<td>
<p>Second shape parameter for the prior beta distribution of the binomial rate parameter</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>prob_interval</code></td>
<td>
<p>Probability within interval estimates for the population binomial rate parameter</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>a_post</code></td>
<td>
<p>First shape parameter for the posterior beta distribution for the binomial rate parameter</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>b_post</code></td>
<td>
<p>Second shape parameter for the posterior beta distribution for the binomial rate parameter</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>phimean</code></td>
<td>
<p>Mean of the posterior beta distribution for the binomial rate parameter</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>phimedian</code></td>
<td>
<p>Median of the posterior beta distribution for the binomial rate parameter</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>phimode</code></td>
<td>
<p>Mode of the posterior beta distribution for the binomial rate parameter</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>eti_lower</code></td>
<td>
<p>Lower limit for the posterior equal-tail interval that has the probability stipulated in the <code>prob_interval</code> argument</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>eti_upper</code></td>
<td>
<p>Upper limit for the posterior equal-tail interval that has the probability stipulated in the <code>prob_interval</code> argument</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>hdi_lower</code></td>
<td>
<p>Lower limit for the posterior highest-density interval that has the probability stipulated in the <code>prob_interval</code> argument</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>hdi_upper</code></td>
<td>
<p>Upper limit for the posterior highest-density interval that has the probability stipulated in the <code>prob_interval</code> argument</p>
</td>
</tr>
</table>
<h3>References</h3>

<p>Berger, J. O., &amp; Wolpert, R. L. (1988). The Likelihood Principle (2nd ed.)
Hayward, CA: Institute of Mathematical Statistics.
</p>
<p>Chechile, R. A. (2020). Bayesian Statistics for Experimental Scientists: A
General Introduction Using Distribution-Free Statistics. Cambridge: MIT Press.
</p>
<p>Clopper, C. J., &amp; Pearson, E. S. (1934). The use of confidence or fiducial
limits illustrated in the case of the binomial. Biometrika, 26, 404-413.
</p>
<p>De Finetti, B. (1974). Bayesianism: Its unifying role for both the
foundations and applications of statistics. International Statistical Review/
Revue Internationale de Statistique, 117-130.
</p>
<p>Ellis, R. L. (1842). On the foundations of the theory of probability.
Transactions of the Cambridge Philosophical Society, 8, 1-6.
</p>
<p>Johnson, N. L., Kotz S., and Balakrishnan, N. (1995). Continuous Univariate
Distributions, Vol. 1, New York: Wiley.
</p>
<p>Kolmogorov, A. N. (1933/1959). Grundbegriffe der Wahrcheinlichkeitsrechnung.
Berlin: Springer. English translation in 1959 as Foundations of the Theory of
Probability. New York: Chelsea.
</p>
<p>Laplace, P. S. (1774). Memoire sr la probabilite des causes par les
evenements. Oeuvres complete, 8,5-24.
</p>
<p>Lindley, D. V., &amp; Phillips, L. D. (1976). Inference for a Bernoulli process
(a Bayesian view). The American Statistician, 30, 112-119.
</p>
<p>Pearson, K. (1920). The fundamental problem of practical statistics.
Biometrika, 13(1), 1-16.
</p>
<p>von Mises, R. (1957). Probability, Statistics, and Truth. New York: Dover.
</p>


<h3>See Also</h3>

<p><code>Distributions</code> for details on the
functions included in the <strong>stats</strong> regarding the beta and the binomial
distributions.
</p>
<p><code>dfba_beta_bayes_factor</code> for further documentation about the
Bayes factor and its interpretation.
</p>
<p><code>dfba_beta_descriptive</code> for advanced Bayesian descriptive methods
for beta distributions
</p>


<h3>Examples</h3>

<pre><code class="language-R"># Example using defaults of a uniform prior and 95% interval estimates
dfba_binomial(n1 = 16,
              n2 = 2)

 # Example with the Jeffreys prior and 99% interval estimates
dfba_binomial(n1 = 16,
              n2 = 2,
              a0 = .5,
              b0 = .5,
              prob_interval = .99)

</code></pre>


</div>