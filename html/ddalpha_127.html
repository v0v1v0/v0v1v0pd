<div class="container">

<table style="width: 100%;"><tr>
<td>ddalpha.classify</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
Classify using DD-Classifier
</h2>

<h3>Description</h3>

<p>Classifies data using the DD-classifier and a specified outsider treatment.
</p>


<h3>Usage</h3>

<pre><code class="language-R">ddalpha.classify(ddalpha, objects, subset, outsider.method = NULL, use.convex = NULL)

## S3 method for class 'ddalpha'
predict(object, objects, subset, outsider.method = NULL, use.convex = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>ddalpha, object</code></td>
<td>

<p>DD<code class="reqn">\alpha</code>-classifier (obtained by <code>ddalpha.train</code>).
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>objects</code></td>
<td>

<p>Matrix containing objects to be classified; each row is one <code class="reqn">d</code>-dimensional object.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>subset</code></td>
<td>

<p>an optional vector specifying a subset of observations to be classified.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>outsider.method</code></td>
<td>

<p>Character string, name of a treatment to be used for outsiders; one of those trained by <code>ddalpha.train</code>. If the treatment was specified using the argument <code>outsider.methods</code> then use the name of the method.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>use.convex</code></td>
<td>

<p>Logical variable indicating whether outsiders should be determined as the points not contained in any of the convex hulls of the classes from the training sample (<code>TRUE</code>) or those having zero depth w.r.t. each class from the training sample (<code>FALSE</code>). For <code>depth =</code> <code>"zonoid"</code> both values give the same result. If <code>NULL</code> the value specified in DD<code class="reqn">\alpha</code>-classifier (in <code>ddalpha.train</code>) is used.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>

<p>additional parameters are ignored
</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Only one outsider treatment can be specified.
</p>
<p>See Lange, Mosler and Mozharovskyi (2014) for details and additional information.
</p>


<h3>Value</h3>

<p>List containing class labels, or character string "Ignored" for the outsiders if "Ignore" was specified as the outsider treating method.
</p>


<h3>References</h3>

<p>Dyckerhoff, R., Koshevoy, G., and Mosler, K. (1996). Zonoid data depth: theory and computation. In: Prat A. (ed), <em>COMPSTAT 1996. Proceedings in computational statistics</em>, Physica-Verlag (Heidelberg), 235–240.
</p>
<p>Lange, T., Mosler, K., and Mozharovskyi, P. (2014). Fast nonparametric classification based on data depth. <em>Statistical Papers</em> <b>55</b> 49–69.
</p>
<p>Li, J., Cuesta-Albertos, J.A., and Liu, R.Y. (2012). DD-classifier: Nonparametric classification procedure based on DD-plot. <em>Journal of the American Statistical Association</em> <b>107</b> 737–753.
</p>
<p>Mozharovskyi, P. (2015). <em>Contributions to Depth-based Classification and Computation of the Tukey Depth</em>. Verlag Dr. Kovac (Hamburg).
</p>
<p>Mozharovskyi, P., Mosler, K., and Lange, T. (2015). Classifying real-world data with the DD<code class="reqn">\alpha</code>-procedure. <em>Advances in Data Analysis and Classification</em> <b>9</b> 287–314.
</p>
<p>Vasil'ev, V.I. (2003). The reduction principle in problems of revealing regularities I. <em>Cybernetics and Systems Analysis</em> <b>39</b> 686–694.
</p>


<h3>See Also</h3>

<p><code>ddalpha.train</code> to train the DD-classifier.
</p>


<h3>Examples</h3>

<pre><code class="language-R"># Generate a bivariate normal location-shift classification task
# containing 200 training objects and 200 to test with
class1 &lt;- mvrnorm(200, c(0,0), 
                  matrix(c(1,1,1,4), nrow = 2, ncol = 2, byrow = TRUE))
class2 &lt;- mvrnorm(200, c(2,2), 
                  matrix(c(1,1,1,4), nrow = 2, ncol = 2, byrow = TRUE))
trainIndices &lt;- c(1:100)
testIndices &lt;- c(101:200)
propertyVars &lt;- c(1:2)
classVar &lt;- 3
trainData &lt;- rbind(cbind(class1[trainIndices,], rep(1, 100)), 
                   cbind(class2[trainIndices,], rep(2, 100)))
testData &lt;- rbind(cbind(class1[testIndices,], rep(1, 100)), 
                  cbind(class2[testIndices,], rep(2, 100)))
data &lt;- list(train = trainData, test = testData)

# Train the DDalpha-Classifier (zonoid depth, maximum Mahalanobis depth 
# classifier with defaults as outsider treatment)
ddalpha &lt;- ddalpha.train(data$train, 
                         depth = "zonoid", 
                         outsider.methods = "depth.Mahalanobis")
# Get the classification error rate
classes &lt;- ddalpha.classify(data$test[,propertyVars], ddalpha, 
                            outsider.method = "depth.Mahalanobis")
cat("Classification error rate: ", 
    sum(unlist(classes) != data$test[,classVar])/200, ".\n", sep="")
</code></pre>


</div>