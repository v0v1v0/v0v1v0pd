<div class="container">

<table style="width: 100%;"><tr>
<td>predict.multifor</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Multi forest prediction</h2>

<h3>Description</h3>

<p>Prediction with new data and a saved forest from <code>multifor</code>.
</p>


<h3>Usage</h3>

<pre><code class="language-R">## S3 method for class 'multifor'
predict(
  object,
  data = NULL,
  predict.all = FALSE,
  num.trees = object$num.trees,
  type = "response",
  seed = NULL,
  num.threads = NULL,
  verbose = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>object</code></td>
<td>
<p><code>multifor</code> object.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>data</code></td>
<td>
<p>New test data of class <code>data.frame</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>predict.all</code></td>
<td>
<p>Return individual predictions for each tree instead of aggregated predictions for all trees. Return a matrix (sample x tree) for classification, a 3d array for probability estimation (sample x class x tree).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>num.trees</code></td>
<td>
<p>Number of trees used for prediction. The first <code>num.trees</code> in the forest are used.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>type</code></td>
<td>
<p>Type of prediction. If "response" (default), the predicted classes (classification) or 
predicted probabilities (probability estimation) are returned. If "terminalNodes", the IDs of the terminal 
node in each tree for each observation in the given dataset are returned.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>seed</code></td>
<td>
<p>Random seed. Default is <code>NULL</code>, which generates the seed from <code>R</code>. Set to <code>0</code> to ignore the <code>R</code> seed. The seed is used in case of ties in classification mode.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>num.threads</code></td>
<td>
<p>Number of threads. Default is number of CPUs available.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>verbose</code></td>
<td>
<p>Verbose output on or off.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>further arguments passed to or from other methods.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>This package is a fork of the R package 'ranger' that implements random forests using an
efficient C++ implementation. More precisely, 'diversityForest' was written by modifying
the code of 'ranger', version 0.11.0.
</p>


<h3>Value</h3>

<p>Object of class <code>multifor.prediction</code> with elements
</p>

<table>
<tr>
<td style="text-align: left;">
      <code>predictions</code>    </td>
<td style="text-align: left;"> Predicted classes/values (only for classification and regression)  </td>
</tr>
<tr>
<td style="text-align: left;">
      <code>num.trees</code>   </td>
<td style="text-align: left;"> Number of trees. </td>
</tr>
<tr>
<td style="text-align: left;">
      <code>num.independent.variables</code> </td>
<td style="text-align: left;"> Number of independent variables. </td>
</tr>
<tr>
<td style="text-align: left;">
      <code>num.samples</code>     </td>
<td style="text-align: left;"> Number of samples. </td>
</tr>
<tr>
<td style="text-align: left;">
      <code>treetype</code>    </td>
<td style="text-align: left;"> Type of forest/tree. Classification or probability.
  </td>
</tr>
</table>
<h3>Author(s)</h3>

<p>Marvin N. Wright
</p>


<h3>References</h3>


<ul>
<li>
<p> Hornung, R. (2022). Diversity forests: Using split sampling to enable innovative complex split procedures in random forests. SN Computer Science 3(2):1, &lt;<a href="https://doi.org/10.1007/s42979-021-00920-1">doi:10.1007/s42979-021-00920-1</a>&gt;.
</p>
</li>
<li>
<p> Wright, M. N., Ziegler, A. (2017). ranger: A fast Implementation of Random Forests for High Dimensional Data in C++ and R. Journal of Statistical Software 77:1-17, &lt;<a href="https://doi.org/10.18637/jss.v077.i01">doi:10.18637/jss.v077.i01</a>&gt;.
</p>
</li>
<li>
<p> Wager, S., Hastie T., &amp; Efron, B. (2014). Confidence Intervals for Random Forests: The Jackknife and the Infinitesimal Jackknife. Journal of Machine Learning Research 15:1625-1651.
</p>
</li>
<li>
<p> Meinshausen (2006). Quantile Regression Forests. Journal of Machine Learning Research 7:983-999.
</p>
</li>
</ul>
<h3>See Also</h3>

<p><code>multifor</code>
</p>


</div>