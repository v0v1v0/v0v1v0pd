<div class="container">

<table style="width: 100%;"><tr>
<td>empirical_EVPI</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Expected value of perfect information (EVPI) for a simple
model with the predictor variable sampled from a normal
distribution with.</h2>

<h3>Description</h3>

<p>The Expected Value of Perfect Information is a concept in
decision analysis. It measures the expected loss of gain
(expected opportunity loss, EOL) that is incurred because
the decision-maker does not have perfect information
about a paricular variable. It is determined by examining
the influence of that variable on the output value of a
decision model. Its value is best illustrated by a plot
of weighed decision outcomes as a function of the
variable in question. If this curve intersects zero and
the recommendation without perfect information is to go
ahead with the project, the EVPI is the negative area
under the curve, or the positive area if the
recommendation is not to go ahead. If there is no
intersection point, the EVPI is zero.
</p>


<h3>Usage</h3>

<pre><code class="language-R">empirical_EVPI(mc, test_var_name, out_var_name)

## S3 method for class 'EVPI_res'
summary(object, ...)

## S3 method for class 'EVPI_res'
plot(x, res = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>mc</code></td>
<td>
<p>output table from a Monte Carlo simulation,
e.g. as realized with the decisionSupport package</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>test_var_name</code></td>
<td>
<p>character; name of an independent
variable in mc, sampled from a normal distribution</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>out_var_name</code></td>
<td>
<p>character; name of a dependent
variable in mc</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>object</code></td>
<td>
<p>EVPI_res object (produced with
empirical_EVPI) as input to the summary function.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>Arguments to be passed to methods, such as
graphical parameters (see par).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>EVPI_res object (produced with empirical_EVPI)
as input to the plotting function.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>res</code></td>
<td>
<p>boolean parameter indicating whether the plot
function should output a plot of opportunity losses and
gains  (res = TRUE) or a plot of the original data with
the loess prediction (res = FALSE).</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The EVPI is often calculated by assuming that all
variables except the one being tested take their best
estimate. This makes it possible to calculate the EVPI
very quickly, but at a high price: the assumption that
many variables simply take their best value ignores
uncertainties about all these variables. In the present
implementation, this problem is addressed by using the
outputs of a Monte Carlo simulation and assessing the
EVPI empirically. In the first step, the output variable
is smoothed using a loess regression with an automated
optimization of the bandwidth parameter, based on a
generalized cross validation procedure. Then the values
are weighted according to the probability density
function that has been used for Monte Carlo sampling
(i.e. a normal distribution, with mean and standard
deviation being estimated automatically) and the
resulting positive and negative areas under the curve are
calculated. After this, the expected gain (exptected mean
value - EMV) without perfect information (PI) is
calculated, the recommendation whether to go ahead with
the project without PI determine and the EVPI returned by
the function.
</p>


<h3>Value</h3>

<p>list of 11 elements: 
(1) expected_gain: expected gain when project is
implemented, without knowing the value of the test
variable, equals NA when there is no variation in the
output variable (2) recommendation: should project be
implemented? Decision without knowing the value of the
test variable (3) EVPI_do: the Expected Value of
Perfect Information (EVPI) for this variable, if the
recommended decision is to implement the project. (4)
EVPI_dont: the Expected Value of Perfect Information
(EVPI) for this variable, if the recommended decision
is not to implement the project. (5) tests_var_data:
values of the test variable (6) out_var_data: values of
the outcome variable (7) out_var_sm: results of loess
regression = smoothed outcome variable (8) weight:
values by which smoothed outcome variable is weighted
(9) out_var_weight: smoothed and weighted outcome
variable (10) test_var_name: variable name of test data
(11) out_var_name: variable name of outcome data
</p>


<h3>Author(s)</h3>

<p>Eike Luedeling, Katja Schiffers
</p>


<h3>Examples</h3>

<pre><code class="language-R">

### In the following example, the sign of the calculation
### is entirely determined by the predictor variable
### 'indep1', so this should be expected to have a high
### EVPI.

montecarlo &lt;- data.frame(indep1 = rnorm(1000), indep2 = rlnorm(1000))
montecarlo[, 'output1'] &lt;- montecarlo[, 'indep1'] * montecarlo[, 'indep2']

evpi1 &lt;- empirical_EVPI(mc = montecarlo, test_var_name = 'indep1', out_var_name = 'output1')
summary(evpi1)
plot(evpi1, res = FALSE)
plot(evpi1, res = TRUE)


### In this example, the sign of the output variable does not change depending on the
### predictor variable 'indep1' so the EVPI should be zero.
montecarlo[, 'output2'] &lt;- (montecarlo[, 'indep1'] * (montecarlo[, 'indep2']) + 10)
evpi2 &lt;- empirical_EVPI(mc = montecarlo, test_var_name = 'indep1', out_var_name = 'output2')
summary(evpi2)
plot(evpi2, res = FALSE)
plot(evpi2, res = TRUE)
</code></pre>


</div>