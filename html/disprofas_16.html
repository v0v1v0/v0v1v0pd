<div class="container">

<table style="width: 100%;"><tr>
<td>get_T2_one</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Hotelling's statistics (for one (small) sample)</h2>

<h3>Description</h3>

<p>The function <code>get_T2_one()</code> estimates the parameters for Hotelling's
one-sample <code class="reqn">T^2</code> statistic for small samples.
</p>


<h3>Usage</h3>

<pre><code class="language-R">get_T2_one(m, mu, signif, na_rm = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>m</code></td>
<td>
<p>A matrix with the data of the reference group, e.g. a matrix
for the different model parameters (columns) of different dosage unit
(rows).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>mu</code></td>
<td>
<p>A numeric vector of, e.g. the hypothetical model parameter
mean values.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>signif</code></td>
<td>
<p>A positive numeric value between <code>0</code> and <code>1</code>
that specifies the significance level. The default value is <code>0.05</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>na_rm</code></td>
<td>
<p>A logical value that indicates whether observations containing
<code>NA</code> (or <code>NaN</code>) values should be removed (<code>na_rm = TRUE</code>)
or not (<code>na_rm = FALSE</code>). The default is <code>na_rm = FALSE</code>.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The one-sample Hotelling's <code class="reqn">T^2</code> test statistic is given by
</p>
<p style="text-align: center;"><code class="reqn">T^2 = n \left( \bar{\bm{x}} - \bm{\mu}_0 \right)^{\top}
      \bm{S}^{-1} \left( \bar{\bm{x}} - \bm{\mu}_0 \right) .</code>
</p>

<p>where <code class="reqn">\bar{\bm{x}}</code> is the vector of the sample means of the
sample group, e.g. the vector of the average dissolution per time point or
of the average model parameters, <code class="reqn">n</code> is the numbers of observations of
the sample group (i.e. the number of rows in matrix <code>m</code> handed over
to the <code>get_T2_one()</code> function, and <code class="reqn">\bm{S}</code> is variance-covariance
matrix. The matrix <code class="reqn">\bm{S}^{-1}</code> is the inverted
variance-covariance matrix. The term
</p>
<p style="text-align: center;"><code class="reqn">D_M = \sqrt{ \left( \bar{\bm{x}} - \bm{\mu}_0 \right)^{\top}
      \bm{S}^{-1} \left( \bar{\bm{x}} - \bm{\mu}_0 \right) }</code>
</p>

<p>is the Mahalanobis distance measuring the difference between the sample mean
vector and the vector of the hypothetical values <code class="reqn">\bm{\mu}_0</code>.
For large samples, <code class="reqn">T^2</code> is approximately chi-square distributed with
<code class="reqn">p</code> degrees of freedom, where <code class="reqn">p</code> is the number of variables, i.e.
the number of dissolution profile time points or the number of model
parameters. In terms of the Mahalanobis distance, the one-sample Hotelling's
<code class="reqn">T^2</code> statistic can be expressed has
</p>
<p style="text-align: center;"><code class="reqn">n \; D_M^2 = k \; D_M^2 .</code>
</p>

<p>To transform the one-sample Hotelling's <code class="reqn">T^2</code> statistic into an
<code class="reqn">F</code>-statistic, a conversion factor is necessary, i.e.
</p>
<p style="text-align: center;"><code class="reqn">K = k \; \frac{n - p}{(n - 1) p} .</code>
</p>

<p>With this transformation, the following test statistic can be applied:
</p>
<p style="text-align: center;"><code class="reqn">K \; D_M^2 \leq F_{p, n - p, \alpha} .</code>
</p>

<p>Under the null hypothesis, <code class="reqn">H_0: \bm{\mu} = \bm{\mu}_0</code>, this <code class="reqn">F</code>-statistic is <code class="reqn">F</code>-distributed with
<code class="reqn">p</code> and <code class="reqn">n - p</code> degrees of freedom. <code class="reqn">H_0</code> is rejected at a
significance level of <code class="reqn">\alpha</code> if the test statistic <code class="reqn">F</code> exceeds
the critical value from the <code class="reqn">F</code>-table evaluated at <code class="reqn">\alpha</code>, i.e.
<code class="reqn">F &gt; F_{p, n - p, \alpha}</code>. <br></p>
<p>The following assumptions concerning the data are made:
</p>

<ul>
<li>
<p> The data of population <code class="reqn">x</code> has no sub-populations, i.e. there are
no sub-populations of <code class="reqn">x</code> with different means.
</p>
</li>
<li>
<p> The observations are based on a common variance-covariance matrix
<code class="reqn">\Sigma</code>.
</p>
</li>
<li>
<p> The observations have been independently sampled.
</p>
</li>
<li>
<p> The observations have been sampled from a multivariate normal
distribution.
</p>
</li>
</ul>
<p><strong>Confidence intervals</strong>: <br>
Simultaneous <code class="reqn">(1 - \alpha)100\%</code> confidence intervals for all linear
combinations of the sample means are given by the expression
</p>
<p style="text-align: center;"><code class="reqn">\left( \bar{\bm{x}} - \bm{\mu}_0 \right) \pm
\sqrt{\frac{1}{K} \; F_{p, n - p, \alpha} \; \bm{s}} ,</code>
</p>

<p>where <code class="reqn">\bm{s}</code> is the vector of the diagonal elements of the
variance-covariance matrix <code class="reqn">\bm{S}</code>. With <code class="reqn">(1 - \alpha)100\%</code>
confidence, this interval covers the respective linear combination of the
differences between the sample means and the hypothetical means. If not
the linear combination of the variables is of interest but rather the
individual variables, then the Bonferroni corrected confidence intervals
should be used instead which are given by the expression
</p>
<p style="text-align: center;"><code class="reqn">\left( \bar{\bm{x}} - \bm{\mu}_0 \right) \pm
  t_{n - 1, \frac{\alpha}{2 p}} \;
  \sqrt{\frac{1}{k} \; \bm{s}} .</code>
</p>



<h3>Value</h3>

<p>A list with the following elements is returned:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>Parameters</code></td>
<td>
<p>Parameters determined for the estimation of Hotelling's
<code class="reqn">T^2</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cov</code></td>
<td>
<p>The variance-covariance matrix of the reference group.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>means</code></td>
<td>
<p>A list with the elements <code>mean.r</code>, <code>mean.t</code> and
<code>mean.diff</code>, i.e. the average model parameters of the reference
group, the hypothetical average model parameters (handed over via the
<code>mu</code> parameter) and the corresponding differences, respectively.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>CI</code></td>
<td>
<p>A list with the elements <code>Hotelling</code> and <code>Bonferroni</code>,
i.e. data frames with columns <code>LCL</code> and <code>UCL</code> for the lower
and upper <code class="reqn">(1 - \alpha)100\%</code> confidence limits, respectively, and
rows for each time point or model parameter.</p>
</td>
</tr>
</table>
<p>The <code>Parameters</code> element contains the following information:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>dm</code></td>
<td>
<p>Mahalanobis distance of the samples.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>df1</code></td>
<td>
<p>Degrees of freedom (number of variables or time points).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>df2</code></td>
<td>
<p>Degrees of freedom (number of rows - number of variables - 1).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>alpha</code></td>
<td>
<p>Provided significance level.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>K</code></td>
<td>
<p>Scaling factor for <code class="reqn">F</code> to account for the distribution of the
<code class="reqn">T^2</code> statistic.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>k</code></td>
<td>
<p>Scaling factor for the squared Mahalanobis distance to obtain
the <code class="reqn">T^2</code> statistic.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>T2</code></td>
<td>
<p>Hotelling's <code class="reqn">T^2</code> statistic (<code class="reqn">F</code>-distributed).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>F</code></td>
<td>
<p>Observed <code class="reqn">F</code> value.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>F.crit</code></td>
<td>
<p>Critical <code class="reqn">F</code> value.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>t.crit</code></td>
<td>
<p>Critical <code class="reqn">t</code> value.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>p.F</code></td>
<td>
<p><code class="reqn">p</code> value for Hotelling's <code class="reqn">T^2</code> test statistic.</p>
</td>
</tr>
</table>
<h3>References</h3>

<p>Hotelling, H. The generalisation of Student's ratio. <em>Ann Math Stat</em>.
1931; <strong>2</strong>(3): 360-378.
</p>
<p>Hotelling, H. (1947) <em>Multivariate quality control illustrated by air
testing of sample bombsights</em>. In: Eisenhart, C., Hastay, M.W., and Wallis,
W.A., Eds., Techniques of Statistical Analysis, McGraw Hill, New York,
111-184.
</p>


<h3>See Also</h3>

<p><code>get_T2_two</code>, <code>get_sim_lim</code>.
</p>


<h3>Examples</h3>

<pre><code class="language-R"># Estimation of the parameters for Hotelling's one-sample T2 statistic
# (for small samples)
# Check if there is a significant difference of the test batch results
# from the average reference batch results.
# Since p.F in res1$Parameters is smaller than 0.1, it is concluded that the
# new batch differs from the reference batch.
res1 &lt;-
  get_T2_one(m = as.matrix(dip1[dip1$type == "T", c("t.15", "t.90")]),
             mu = colMeans(dip1[dip1$type == "R", c("t.15", "t.90")]),
             signif = 0.1, na_rm = FALSE)
res1$Parameters

# Expected results in res1$Parameters
#           dm          df1          df2       signif            K
# 1.314197e+01 2.000000e+00 4.000000e+00 1.000000e-01 2.400000e+00
#            k           T2            F       F.crit       t.crit
# 6.000000e+00 1.036268e+03 4.145072e+02 4.324555e+00 2.570582e+00
#          p.F
# 2.305765e-05

# In Tsong (1997) (see reference of dip7), the model-dependent approach is
# illustrated with an example data set of alpha and beta parameters obtained
# by fitting the Weibull curve function to a data set of dissolution profiles
# of three reference batches and one new batch (12 profiles per batch).
# Check if there is a significant difference of the test batch results
# from the average reference batch results.
# Since p.F in res2$Parameters is smaller than 0.05, it is concluded that the
# test batch differs from the reference batches.
res2 &lt;-
  get_T2_one(m = as.matrix(dip7[dip7$type == "test", c("alpha", "beta")]),
             mu = colMeans(dip7[dip7$type == "ref", c("alpha", "beta")]),
             signif = 0.05, na_rm = FALSE)
res2$Parameters

# Expected results in res2$Parameters
#           dm          df1          df2       signif            K
# 5.984856e+00 2.000000e+00 1.000000e+01 5.000000e-02 5.454545e+00
#            k           T2            F       F.crit       t.crit
# 1.200000e+01 4.298220e+02 1.953736e+02 4.102821e+00 2.593093e+00
#          p.F
# 9.674913e-09

# In Sathe (1996) (see reference of dip8), the model-dependent approach is
# illustrated with an example data set of alpha and beta parameters obtained
# by fitting the Weibull curve function to a data set of dissolution profiles
# of one reference batch and one new batch with minor modifications and another
# new batch with major modifications (12 profiles per batch).
# Check if there is a significant difference of the results of the minor or
# major modificated batches from the average reference batch results.
# Since p.F in res3.minor$Parameters or in res3.major$Parameters are smaller
# than 0.1, it is concluded that the minor and the major modification batch
# differs from the reference batch.
res3.minor &lt;-
  get_T2_one(m = log(as.matrix(dip8[dip8$type == "minor",
                                    c("alpha", "beta")])),
             mu = log(colMeans(dip8[dip8$type == "ref",
                                     c("alpha", "beta")])),
             signif = 0.1, na_rm = FALSE)
res3.major &lt;-
  get_T2_one(m = log(as.matrix(dip8[dip8$type == "major",
                                    c("alpha", "beta")])),
             mu = log(colMeans(dip8[dip8$type == "ref",
                                     c("alpha", "beta")])),
             signif = 0.1, na_rm = FALSE)
res3.minor$Parameters
res3.major$Parameters

# Expected results in res3.minor$Parameters
#           dm          df1          df2       signif            K
# 2.718715e+00 2.000000e+00 1.000000e+01 1.000000e-01 5.454545e+00
#            k           T2            F       F.crit       t.crit
# 1.200000e+01 8.869691e+01 4.031678e+01 2.924466e+00 2.200985e+00
#          p.F
# 1.635140e-05

# Expected results in res3.major$Parameters
#           dm          df1          df2       signif            K
# 5.297092e+00 2.000000e+00 1.000000e+01 1.000000e-01 5.454545e+00
#            k           T2            F       F.crit       t.crit
# 1.200000e+01 3.367102e+02 1.530501e+02 2.924466e+00 2.200985e+00
#          p.F
# 3.168664e-08
</code></pre>


</div>