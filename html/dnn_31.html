<div class="container">

<table style="width: 100%;"><tr>
<td>fwdNN</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
Feed forward and back propagation for dnn Models
</h2>

<h3>Description</h3>

<p>{fwdNN} is an R function for feed forward network.
</p>


<h3>Usage</h3>

<pre><code class="language-R">   fwdNN(X, model)             
#
# to calculate a feed feedward model 
#
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>X</code></td>
<td>
<p>For "dNNmodel", X is a design matrix of dimension n * p.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>model</code></td>
<td>
<p>a model return from dNNmodel function.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>'cache' is the cache of each input layer, will be used in the bwdNN function.
</p>


<h3>Value</h3>


<p>The function fwdNN return a list containing at least the following components:
</p>
<table><tr style="vertical-align: top;">
<td><code>cache</code></td>
<td>
<p>a list contains the values of each output layer after activation function transformation and adding the 
intercept term (i.e. the bias term). The intercept does not add to the output layer in the cache.</p>
</td>
</tr></table>
<h3>Author(s)</h3>

<p>Bingshu E. Chen (bingshu.chen@queensu.ca)
</p>


<h3>See Also</h3>


<p><code>bwdNN</code>,
<code>plot.dNNmodel</code>,
<code>print.dNNmodel</code>,
<code>summary.dNNmodel</code>,
</p>


<h3>Examples</h3>

<pre><code class="language-R">### define a dnn model, calculate the feed forward network
   model = dNNmodel(units = c(8, 6, 1), activation = c("elu", "sigmoid", "sigmoid"), 
                   input_shape = 3)
  
### feed forward with a dummy x matrix
   x = matrix(runif(15), nrow = 5, ncol = 3)
   cache = fwdNN(x, model)
</code></pre>


</div>