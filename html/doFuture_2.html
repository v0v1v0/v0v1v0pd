<div class="container">

<table style="width: 100%;"><tr>
<td>%dofuture%</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Loop over a Foreach Expression using Futures</h2>

<h3>Description</h3>

<p>Loop over a Foreach Expression using Futures
</p>


<h3>Usage</h3>

<pre><code class="language-R">foreach %dofuture% expr
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>foreach</code></td>
<td>
<p>A <code>foreach</code> object created by <code>foreach::foreach()</code>
and <code>foreach::times()</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>expr</code></td>
<td>
<p>An R expression.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>This is a replacement for <code>%dopar%</code> of the <span class="pkg">foreach</span> package
that leverages the <span class="pkg">future</span> framework.
</p>
<p>When using <code style="white-space: pre;">⁠%dofuture%⁠</code>:
</p>

<ul>
<li>
<p> there is no need to use <code>registerDoFuture()</code>
</p>
</li>
<li>
<p> there is no need to use <code style="white-space: pre;">⁠%dorng%⁠</code> of the <strong>doRNG</strong> package
(but you need to specify <code>.options.future = list(seed = TRUE)</code>
whenever using random numbers in the <code>expr</code> expression)
</p>
</li>
<li>
<p> global variables and packages are identified automatically by
the <span class="pkg">future</span> framework
</p>
</li>
<li>
<p> errors are relayed as-is (with <code style="white-space: pre;">⁠%dopar%⁠</code> they captured and modified)
</p>
</li>
</ul>
<h3>Value</h3>

<p>The value of the foreach call.
</p>


<h3>Global variables and packages</h3>

<p>When using <code style="white-space: pre;">⁠%dofuture%⁠</code>, the future framework identifies globals and
packages automatically (via static code inspection).  However, there
are cases where it fails to find some of the globals or packages. When
this happens, one can specify the <code>future::future()</code> arguments <code>globals</code>
and <code>packages</code> via foreach argument <code>.options.future</code>.  For example,
if you specify argument
<code>.options.future = list(globals = structure(TRUE, ignore = "b", add = "a"))</code>
then globals are automatically identified (<code>TRUE</code>), but it ignores <code>b</code> and
always adds <code>a</code>.
</p>
<p>An alternative to specifying the <code>globals</code> and the <code>packages</code> options via
<code>.options.future</code>, is to use the <code>%globals%</code>
and the <code>%packages%</code> operators.
See the examples for an illustration.
</p>
<p>For further details and instructions, see <code>future::future()</code>.
</p>


<h3>Random Number Generation (RNG)</h3>

<p>The <code style="white-space: pre;">⁠%dofuture%⁠</code> uses the future ecosystem to generate proper random
numbers in parallel in the same way they are generated in, for instance,
<span class="pkg">future.apply</span>. For this to work, you need to specify
<code>.options.future = list(seed = TRUE)</code>.  For example,
</p>
<div class="sourceCode r"><pre>y &lt;- foreach(i = 1:3, .options.future = list(seed = TRUE)) %dofuture% {
  rnorm(1)
}
</pre></div>
<p>Unless <code>seed</code> is <code>FALSE</code> or <code>NULL</code>, this guarantees that the exact same
sequence of random numbers are generated <em>given the same initial
seed / RNG state</em> - this regardless of type of future backend, number of
workers, and scheduling ("chunking") strategy.
</p>
<p>RNG reproducibility is achieved by pregenerating the random seeds for all
iterations by using L'Ecuyer-CMRG RNG streams.  In each
iteration, these seeds are set before evaluating the foreach expression.
<em>Note, for large number of iterations this may introduce a large overhead.</em>
</p>
<p>If <code>seed = TRUE</code>, then <code>.Random.seed</code>
is used if it holds a L'Ecuyer-CMRG RNG seed, otherwise one is created
randomly.
</p>
<p>If <code>seed = FALSE</code>, it is expected that none of the foreach iterations
use random number generation.
If they do, then an informative warning or error is produces depending
on settings. See future::future for more details.
Using <code>seed = NULL</code>, is like <code>seed = FALSE</code> but without the check
whether random numbers were generated or not.
</p>
<p>As input, <code>seed</code> may also take a fixed initial seed (integer),
either as a full L'Ecuyer-CMRG RNG seed (vector of 1+6 integers), or
as a seed generating such a full L'Ecuyer-CMRG seed. This seed will
be used to generated one L'Ecuyer-CMRG RNG stream for each iteration.
</p>
<p>An alternative to specifying the <code>seed</code> option via <code>.options.future</code>,
is to use the <code>%seed%</code> operator.  See
the examples for an illustration.
</p>
<p>For further details and instructions, see
<code>future.apply::future_lapply()</code>.
</p>


<h3>Load balancing ("chunking")</h3>

<p>Whether load balancing ("chunking") should take place or not can be
controlled by specifying either argument
<code style="white-space: pre;">⁠.options.future = list(scheduling = &lt;ratio&gt;)⁠</code> or
<code style="white-space: pre;">⁠.options.future = list(chunk.size = &lt;count&gt;)⁠</code> to <code>foreach()</code>.
</p>
<p>The value <code>chunk.size</code> specifies the average number of elements
processed per future ("chunks").
If <code>+Inf</code>, then all elements are processed in a single future (one worker).
If <code>NULL</code>, then argument <code>future.scheduling</code> is used.
</p>
<p>The value <code>scheduling</code> specifies the average number of futures
("chunks") that each worker processes.
If <code>0.0</code>, then a single future is used to process all iterations;
none of the other workers are not used.
If <code>1.0</code> or <code>TRUE</code>, then one future per worker is used.
If <code>2.0</code>, then each worker will process two futures (if there are
enough iterations).
If <code>+Inf</code> or <code>FALSE</code>, then one future per iteration is used.
The default value is <code>scheduling = 1.0</code>.
</p>
<p>For further details and instructions, see
<code>future.apply::future_lapply()</code>.
</p>


<h3>Control processing order of iterations</h3>

<p>Attribute <code>ordering</code> of <code>chunk.size</code> or <code>scheduling</code> can be used to
control the ordering the elements are iterated over, which only affects
the processing order and <em>not</em> the order values are returned.
This attribute can take the following values:
</p>

<ul>
<li>
<p> index vector - an numeric vector of length <code>nX</code>.
</p>
</li>
<li>
<p> function     - an function taking one argument which is called as
<code>ordering(nX)</code> and which must return an
index vector of length <code>nX</code>, e.g.
<code>function(n) rev(seq_len(n))</code> for reverse ordering.
</p>
</li>
<li> <p><code>"random"</code>   - this will randomize the ordering via random index
vector <code>sample.int(nX)</code>.
</p>
</li>
</ul>
<p>where <code>nX</code> is the number of foreach iterations to be done.
</p>
<p>For example,
<code>.options.future = list(scheduling = structure(2.0, ordering = "random"))</code>.
</p>
<p><em>Note</em>, when elements are processed out of order, then captured standard
output and conditions are also relayed in that order, that is, out of order.
</p>
<p>For further details and instructions, see
<code>future.apply::future_lapply()</code>.
</p>


<h3>Reporting on progress</h3>

<p>How to report on progress is a frequently asked question, especially
in long-running tasks and parallel processing.  The <strong>foreach</strong>
framework does <em>not</em> have a built-in mechanism for progress
reporting(*).
</p>
<p>When using <strong>doFuture</strong>, and the Futureverse in general, for
processing, the <strong>progressr</strong> package can be used to signal progress
updates in a near-live fashion.  There is special argument related to
<code>foreach()</code> or <strong>doFuture</strong> to achieve this. Instead, one calls a
a, so called, "progressor" function within each iteration.  See
the <a href="https://cran.r-project.org/package=progressr"><strong>progressr</strong></a>
package and its <code>vignette(package = "progressr")</code> for examples.
</p>
<p>(*) The legacy <strong>doSNOW</strong> package uses a special <code>foreach()</code> argument
<code>.options.doSNOW$progress</code> that can be used to make a progress update
each time results from a parallel workers is returned. This approach
is limited by how chunking works, requires the developer to set that
argument, and the code becomes incompatible with foreach adaptors
registered by other <strong>doNnn</strong> packages.
</p>


<h3>Examples</h3>

<pre><code class="language-R">
plan(multisession)  # parallelize futures on the local machine

y &lt;- foreach(x = 1:10, .combine = rbind) %dofuture% {
  y &lt;- sqrt(x)
  data.frame(x = x, y = y, pid = Sys.getpid())
}
print(y)


## Random number generation
y &lt;- foreach(i = 1:3, .combine = rbind, .options.future = list(seed = TRUE)) %dofuture% {
  data.frame(i = i, random = runif(n = 1L)) 
}
print(y)

## Random number generation (alternative specification)
y &lt;- foreach(i = 1:3, .combine = rbind) %dofuture% {
  data.frame(i = i, random = runif(n = 1L)) 
} %seed% TRUE
print(y)

## Random number generation with the foreach() %:% nested operator
y &lt;- foreach(i = 1:3, .combine = rbind) %:%
       foreach(j = 3:5, .combine = rbind, .options.future = list(seed = TRUE)) %dofuture% {
  data.frame(i = i, j = j, random = runif(n = 1L)) 
}
print(y)

## Random number generation with the nested foreach() calls
y &lt;- foreach(i = 1:3, .combine = rbind, .options.future = list(seed = TRUE)) %dofuture% {
  foreach(j = 3:5, .combine = rbind, .options.future = list(seed = TRUE)) %dofuture% {
    data.frame(i = i, j = j, random = runif(n = 1L)) 
  }
}
print(y)




</code></pre>


</div>