<div class="container">

<table style="width: 100%;"><tr>
<td>random.Normal</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Draw a random sample from a Normal distribution</h2>

<h3>Description</h3>

<p>Please see the documentation of <code>Normal()</code> for some properties
of the Normal distribution, as well as extensive examples
showing to how calculate p-values and confidence intervals.
</p>


<h3>Usage</h3>

<pre><code class="language-R">## S3 method for class 'Normal'
random(x, n = 1L, drop = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>A <code>Normal</code> object created by a call to <code>Normal()</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>n</code></td>
<td>
<p>The number of samples to draw. Defaults to <code>1L</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>drop</code></td>
<td>
<p>logical. Should the result be simplified to a vector if possible?</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>Unused. Unevaluated arguments will generate a warning to
catch mispellings or other possible errors.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>In case of a single distribution object or <code>n = 1</code>, either a numeric
vector of length <code>n</code> (if <code>drop = TRUE</code>, default) or a <code>matrix</code> with <code>n</code> columns
(if <code>drop = FALSE</code>).
</p>


<h3>Examples</h3>

<pre><code class="language-R">
set.seed(27)

X &lt;- Normal(5, 2)
X

mean(X)
variance(X)
skewness(X)
kurtosis(X)

random(X, 10)

pdf(X, 2)
log_pdf(X, 2)

cdf(X, 4)
quantile(X, 0.7)

### example: calculating p-values for two-sided Z-test

# here the null hypothesis is H_0: mu = 3
# and we assume sigma = 2

# exactly the same as: Z &lt;- Normal(0, 1)
Z &lt;- Normal()

# data to test
x &lt;- c(3, 7, 11, 0, 7, 0, 4, 5, 6, 2)
nx &lt;- length(x)

# calculate the z-statistic
z_stat &lt;- (mean(x) - 3) / (2 / sqrt(nx))
z_stat

# calculate the two-sided p-value
1 - cdf(Z, abs(z_stat)) + cdf(Z, -abs(z_stat))

# exactly equivalent to the above
2 * cdf(Z, -abs(z_stat))

# p-value for one-sided test
# H_0: mu &lt;= 3   vs   H_A: mu &gt; 3
1 - cdf(Z, z_stat)

# p-value for one-sided test
# H_0: mu &gt;= 3   vs   H_A: mu &lt; 3
cdf(Z, z_stat)

### example: calculating a 88 percent Z CI for a mean

# same `x` as before, still assume `sigma = 2`

# lower-bound
mean(x) - quantile(Z, 1 - 0.12 / 2) * 2 / sqrt(nx)

# upper-bound
mean(x) + quantile(Z, 1 - 0.12 / 2) * 2 / sqrt(nx)

# equivalent to
mean(x) + c(-1, 1) * quantile(Z, 1 - 0.12 / 2) * 2 / sqrt(nx)

# also equivalent to
mean(x) + quantile(Z, 0.12 / 2) * 2 / sqrt(nx)
mean(x) + quantile(Z, 1 - 0.12 / 2) * 2 / sqrt(nx)

### generating random samples and plugging in ks.test()

set.seed(27)

# generate a random sample
ns &lt;- random(Normal(3, 7), 26)

# test if sample is Normal(3, 7)
ks.test(ns, pnorm, mean = 3, sd = 7)

# test if sample is gamma(8, 3) using base R pgamma()
ks.test(ns, pgamma, shape = 8, rate = 3)

### MISC

# note that the cdf() and quantile() functions are inverses
cdf(X, quantile(X, 0.7))
quantile(X, cdf(X, 7))
</code></pre>


</div>