<div class="container">

<table style="width: 100%;"><tr>
<td>dropout</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Neural network parameters</h2>

<h3>Description</h3>

<p>These functions generate parameters that are useful for neural network models.
</p>


<h3>Usage</h3>

<pre><code class="language-R">dropout(range = c(0, 1), trans = NULL)

epochs(range = c(10L, 1000L), trans = NULL)

hidden_units(range = c(1L, 10L), trans = NULL)

hidden_units_2(range = c(1L, 10L), trans = NULL)

batch_size(range = c(unknown(), unknown()), trans = transform_log2())
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>range</code></td>
<td>
<p>A two-element vector holding the <em>defaults</em> for the smallest and
largest possible values, respectively. If a transformation is specified,
these values should be in the <em>transformed units</em>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>trans</code></td>
<td>
<p>A <code>trans</code> object from the <code>scales</code> package, such as
<code>scales::transform_log10()</code> or <code>scales::transform_reciprocal()</code>. If not provided,
the default is used which matches the units used in <code>range</code>. If no
transformation, <code>NULL</code>.</p>
</td>
</tr>
</table>
<h3>Details</h3>


<ul>
<li> <p><code>dropout()</code>: The parameter dropout rate. (See <code>parsnip:::mlp()</code>).
</p>
</li>
<li> <p><code>epochs()</code>: The number of iterations of training. (See <code>parsnip:::mlp()</code>).
</p>
</li>
<li> <p><code>hidden_units()</code>: The number of hidden units in a network layer.
(See <code>parsnip:::mlp()</code>).
</p>
</li>
<li> <p><code>batch_size()</code>: The mini-batch size for neural networks.
</p>
</li>
</ul>
<h3>Examples</h3>

<pre><code class="language-R">dropout()
</code></pre>


</div>