<div class="container">

<table style="width: 100%;"><tr>
<td>deepregression</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Fitting Semi-Structured Deep Distributional Regression</h2>

<h3>Description</h3>

<p>Fitting Semi-Structured Deep Distributional Regression
</p>


<h3>Usage</h3>

<pre><code class="language-R">deepregression(
  y,
  list_of_formulas,
  list_of_deep_models = NULL,
  family = "normal",
  data,
  tf_seed = as.integer(1991 - 5 - 4),
  return_prepoc = FALSE,
  subnetwork_builder = subnetwork_init,
  model_builder = keras_dr,
  fitting_function = utils::getFromNamespace("fit.keras.engine.training.Model",
    "keras"),
  additional_processors = list(),
  penalty_options = penalty_control(),
  orthog_options = orthog_control(),
  weight_options = weight_control(),
  formula_options = form_control(),
  output_dim = 1L,
  verbose = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>
<p>response variable</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>list_of_formulas</code></td>
<td>
<p>a named list of right hand side formulas,
one for each parameter of the distribution specified in <code>family</code>;
set to <code>~ 1</code> if the parameter should be treated as constant.
Use the <code>s()</code>-notation from <code>mgcv</code> for specification of
non-linear structured effects and <code>d(...)</code> for
deep learning predictors (predictors in brackets are separated by commas),
where <code>d</code> can be replaced by an name name of the names in
<code>list_of_deep_models</code>, e.g., <code>~ 1 + s(x) + my_deep_mod(a,b,c)</code>,
where my_deep_mod is the name of the neural net specified in
<code>list_of_deep_models</code> and <code>a,b,c</code> are features modeled via
this network.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>list_of_deep_models</code></td>
<td>
<p>a named list of functions specifying a keras model.
See the examples for more details.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>family</code></td>
<td>
<p>a character specifying the distribution. For information on
possible distribution and parameters, see <code>make_tfd_dist</code>. Can also
be a custom distribution.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>data</code></td>
<td>
<p>data.frame or named list with input features</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tf_seed</code></td>
<td>
<p>a seed for TensorFlow (only works with R version &gt;= 2.2.0)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>return_prepoc</code></td>
<td>
<p>logical; if TRUE only the pre-processed data and layers are returned 
(default FALSE).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>subnetwork_builder</code></td>
<td>
<p>function to build each subnetwork (network for each distribution parameter;
per default <code>subnetwork_init</code>). Can also be a list of the same size as
<code>list_of_formulas</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>model_builder</code></td>
<td>
<p>function to build the model based on additive predictors 
(per default <code>keras_dr</code>). In order to work with the methods defined for the class 
<code>deepregression</code>, the model should behave like a keras model</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>fitting_function</code></td>
<td>
<p>function to fit the instantiated model when calling <code>fit</code>. Per default
the keras <code>fit</code> function.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>additional_processors</code></td>
<td>
<p>a named list with additional processors to convert the formula(s).
Can have an attribute <code>"controls"</code> to pass additional controls</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>penalty_options</code></td>
<td>
<p>options for smoothing and penalty terms defined by <code>penalty_control</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>orthog_options</code></td>
<td>
<p>options for the orthgonalization defined by <code>orthog_control</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>weight_options</code></td>
<td>
<p>options for layer weights defined by <code>weight_control</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>formula_options</code></td>
<td>
<p>options for formula parsing (mainly used to make calculation more efficiently)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>output_dim</code></td>
<td>
<p>dimension of the output, per default 1L</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>verbose</code></td>
<td>
<p>logical; whether to print progress of model initialization to console</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>further arguments passed to the <code>model_builder</code> function</p>
</td>
</tr>
</table>
<h3>References</h3>

<p>Ruegamer, D. et al. (2023):
deepregression: a Flexible Neural Network Framework for Semi-Structured Deep Distributional Regression.
<a href="https://doi.org/10.18637/jss.v105.i02">doi:10.18637/jss.v105.i02</a>.
</p>


<h3>Examples</h3>

<pre><code class="language-R">library(deepregression)

n &lt;- 1000
data = data.frame(matrix(rnorm(4*n), c(n,4)))
colnames(data) &lt;- c("x1","x2","x3","xa")
formula &lt;- ~ 1 + deep_model(x1,x2,x3) + s(xa) + x1

deep_model &lt;- function(x) x %&gt;%
layer_dense(units = 32, activation = "relu", use_bias = FALSE) %&gt;%
layer_dropout(rate = 0.2) %&gt;%
layer_dense(units = 8, activation = "relu") %&gt;%
layer_dense(units = 1, activation = "linear")

y &lt;- rnorm(n) + data$xa^2 + data$x1

mod &lt;- deepregression(
  list_of_formulas = list(loc = formula, scale = ~ 1),
  data = data, y = y,
  list_of_deep_models = list(deep_model = deep_model)
)

if(!is.null(mod)){

# train for more than 10 epochs to get a better model
mod %&gt;% fit(epochs = 10, early_stopping = TRUE)
mod %&gt;% fitted() %&gt;% head()
cvres &lt;- mod %&gt;% cv()
mod %&gt;% get_partial_effect(name = "s(xa)")
mod %&gt;% coef()
mod %&gt;% plot()

}

mod &lt;- deepregression(
  list_of_formulas = list(loc = ~ 1 + s(xa) + x1, scale = ~ 1,
                          dummy = ~ -1 + deep_model(x1,x2,x3) %OZ% 1),
  data = data, y = y,
  list_of_deep_models = list(deep_model = deep_model),
  mapping = list(1,2,1:2)
)

</code></pre>


</div>