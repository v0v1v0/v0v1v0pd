<div class="container">

<table style="width: 100%;"><tr>
<td>ClassificationError</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Classification Error (rate)</h2>

<h3>Description</h3>

<p>Compares projected points to a given prior classification using knn classifier.
</p>


<h3>Usage</h3>

<pre><code class="language-R">ClassificationError(OutputDistances,Cls,k=5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>OutputDistances</code></td>
<td>
<p>[1:n,1:n] numeric matrix with distance matrix of
projected data.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Cls</code></td>
<td>
<p>[1:n] Numeric vector containing class information.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>k</code></td>
<td>
<p>number of k nearest neighbors, in Venna 2010 set to 5 (here default)</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Projected points are evaluated by k-nearest neighbor classification accuracy (with k = 5), that is, each sample in the
visualization is classified by majority vote of its k nearest neighbors in the visualization, and the
classification is compared to the ground truth label. [Venna 2010].
</p>


<h3>Value</h3>

<p>List with three entries:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>Error</code></td>
<td>
<p>Classification Error: 1-Accuracy[1]</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Accuracy</code></td>
<td>
<p>Accuracy </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>KNNCls</code></td>
<td>
<p>[1:n]] cls of knn classifier</p>
</td>
</tr>
</table>
<h3>Note</h3>

<p>Here, the Outputdistances of the Projected points are used.
</p>


<h3>Author(s)</h3>

<p>Michael Thrun
</p>


<h3>References</h3>

<p>Venna, J., Peltonen, J., Nybo, K., Aidos, H., and Kaski, S. Information retrieval perspective to nonlinear dimensionality reduction for data visualization. The Journal of Machine Learning Research, 11, 451-490.  (2010)
</p>
<p>Gracia, A., Gonzalez, S., Robles, V., and Menasalvas, E. A methodology to compare Dimensionality Reduction algorithms in terms of loss of quality. Information Sciences, 270, 1-27.  (2014)
</p>


<h3>Examples</h3>

<pre><code class="language-R">
if(requireNamespace("FCPS")){
data(Hepta,package="FCPS")
projection=cmdscale(dist(Hepta$Data), k=2)
ClassificationError(as.matrix(dist(projection)),Hepta$Cls)
}


</code></pre>


</div>