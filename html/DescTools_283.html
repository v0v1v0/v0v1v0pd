<div class="container">

<table style="width: 100%;"><tr>
<td>HoeffD</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
Matrix of Hoeffding's D Statistics
</h2>

<h3>Description</h3>

<p>Computes a matrix of Hoeffding's (1948) <code>D</code> statistics for all possible
pairs of columns of a matrix.  <code>D</code>
is a measure of the distance
between <code>F(x,y)</code> and <code>G(x)H(y)</code>, where <code>F(x,y)</code> is the joint CDF of <code>X</code> and <code>Y</code>,
and <code>G</code> and <code>H</code> are marginal CDFs. Missing values are deleted in pairs rather than deleting all rows
of <code>x</code> having any missing variables.
The <code>D</code> statistic is robust against a wide
variety of alternatives to independence, such as non-monotonic relationships.
The larger the value of <code>D</code>, the more dependent are <code>X</code> and <code>Y</code> (for many types
of dependencies).  <code>D</code> used here is 30 times Hoeffding's original <code>D</code>, and
ranges from -0.5 to 1.0 if there are no ties in the data.
<code>print.HoeffD</code> prints the information derived by <code>HoeffD</code>.  The higher
the value of <code>D</code>, the more dependent are <code>x</code> and <code>y</code>.
</p>


<h3>Usage</h3>

<pre><code class="language-R">HoeffD(x, y)
## S3 method for class 'HoeffD'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>

<p>a numeric matrix with at least 5 rows and at least 2 columns (if
<code>y</code> is absent), or an object created by <code>HoeffD</code>
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>

<p>a numeric vector or matrix which will be concatenated to <code>x</code>
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>ignored</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Uses midranks in case of ties, as described by Hollander and Wolfe.
P-values are approximated by linear interpolation on the table
in Hollander and Wolfe, which uses the asymptotically equivalent
Blum-Kiefer-Rosenblatt statistic.  For <code>P&lt;.0001</code> or <code>&gt;0.5</code>, <code>P</code> values are
computed using a well-fitting linear regression function in <code>log P</code> vs.
the test statistic.
Ranks (but not bivariate ranks) are computed using efficient
algorithms (see reference 3).
</p>


<h3>Value</h3>

<p>a list with elements <code>D</code>, the
matrix of D statistics, <code>n</code> the
matrix of number of observations used in analyzing each pair of variables,
and <code>P</code>, the asymptotic P-values.
Pairs with fewer than 5 non-missing values have the D statistic set to NA.
The diagonals of <code>n</code> are the number of non-NAs for the single variable
corresponding to that row and column.
</p>


<h3>Author(s)</h3>

<p>Frank Harrell &lt;f.harrell@vanderbilt.edu&gt;
<br>
Department of Biostatistics
<br>
Vanderbilt University
<br></p>


<h3>References</h3>

<p>Hoeffding W. (1948) A non-parametric test of independence.  <em>Ann Math Stat</em> 19:546–57.
</p>
<p>Hollander M., Wolfe D.A. (1973)   <em>Nonparametric Statistical Methods</em>,
pp. 228–235, 423. New York: Wiley.
</p>
<p>Press W.H., Flannery B.P., Teukolsky S.A., Vetterling, W.T. (1988) <em>Numerical
Recipes in C</em> Cambridge: Cambridge University Press.
</p>


<h3>See Also</h3>

<p><code>rcorr</code>, <code>varclus</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">x &lt;- c(-2, -1, 0, 1, 2)
y &lt;- c(4,   1, 0, 1, 4)
z &lt;- c(1,   2, 3, 4, NA)
q &lt;- c(1,   2, 3, 4, 5)

HoeffD(cbind(x, y, z, q))


# Hoeffding's test can detect even one-to-many dependency
set.seed(1)
x &lt;- seq(-10, 10, length=200)
y &lt;- x * sign(runif(200, -1, 1))
plot(x, y)

HoeffD(x, y)
</code></pre>


</div>