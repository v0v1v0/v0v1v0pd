<div class="container">

<table style="width: 100%;"><tr>
<td>SVM_predict</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Predictive Modeling using Support Vector Machine</h2>

<h3>Description</h3>

<p>This function trains a Support Vector Machine regressor using the training
data provided and predict response for the test features. This implementation
depends on the <code>kernlab</code> package.
</p>


<h3>Usage</h3>

<pre><code class="language-R">SVM_predict(
  x_train,
  y_train,
  x_test,
  lims,
  kernel = "rbf",
  optimize = FALSE,
  C = 2,
  kpar = list(sigma = 0.1),
  eps = 0.01,
  seed = NULL,
  verbose = FALSE,
  parallel = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x_train</code></td>
<td>
<p>Training features for designing the SVM regressor.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>y_train</code></td>
<td>
<p>Training response for designing the SVM regressor.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>x_test</code></td>
<td>
<p>Test features for which response values are to be predicted.
If <code>x_test</code> is not given, the function will return the trained model.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lims</code></td>
<td>
<p>Vector providing the range of the response values for modeling.
If missing, these values are estimated from the training response.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>kernel</code></td>
<td>
<p>Kernel function for SVM implementation. The available options
are <code>linear</code>, <code>poly</code>, <code>rbf</code>, and <code>tanh</code>. Defaults to <code>rbf</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>optimize</code></td>
<td>
<p>Flag for model tuning. If <code>TRUE</code>, performs a grid search for
parameters. If <code>FALSE</code>, uses the parameters provided. Defaults to <code>FALSE</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>C</code></td>
<td>
<p>Cost of constraints violation. This is the constant "C" of the
regularization term in the Lagrange formulation. Defaults to <code>2</code>. Valid only
when <code>optimize = FALSE</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>kpar</code></td>
<td>
<p>List of kernel parameters. This is a named list that contains
the parameters to be used with the specified kernel. The valid parameters
for the existing kernels are -
</p>

<ul>
<li> <p><code>sigma</code> for the radial basis (rbf) kernel. Note that this is the
<strong>inverse</strong> kernel width.
</p>
</li>
<li> <p><code>degree</code>, <code>scale</code>, <code>offset</code> for the polynomial kernel.
</p>
</li>
<li> <p><code>scale</code>, <code>offset</code> for the hyperbolic tangent kernel.
</p>
</li>
</ul>
<p>Valid only when <code>optimize = FALSE</code>. Defaults to <code>list(sigma = 0.1)</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>eps</code></td>
<td>
<p>The insensitive-loss function used for epsilon-SVR. Defaults to
<code>0.01</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>seed</code></td>
<td>
<p>Seed for random number generator (for reproducible outcomes).
Defaults to <code>NULL</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>verbose</code></td>
<td>
<p>Flag for printing the tuning progress when <code>optimize = TRUE</code>.
Defaults to <code>FALSE</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>parallel</code></td>
<td>
<p>Flag for allowing parallel processing when performing grid
search <em>i.e.</em>, <code>optimimze = TRUE</code>. Defaults to <code>FALSE</code>.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>If <code>x_test</code> is missing, the trained SVM regressor.
</p>
<p>If <code>x_test</code> is provided, the predicted values using the model.
</p>


<h3>Note</h3>

<p>The response values are filtered to be bound by range in <code>lims</code>.
</p>


<h3>Examples</h3>

<pre><code class="language-R">set.seed(86420)
x &lt;- matrix(rnorm(3000, 0.2, 1.2), ncol = 3);    colnames(x) &lt;- paste0("x", 1:3)
y &lt;- 0.3*x[, 1] + 0.1*x[, 2] - x[, 3] + rnorm(1000, 0, 0.05)

## Get the model only...
model &lt;- SVM_predict(x_train = x[1:800, ], y_train = y[1:800], kernel = "rbf")

## Get predictive performance...
y_pred &lt;- SVM_predict(x_train = x[1:800, ], y_train = y[1:800], x_test = x[801:1000, ])
y_test &lt;- y[801:1000]
print(performance(y_test, y_pred, measures = "RSQ"))

</code></pre>


</div>