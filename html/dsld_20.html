<div class="container">

<table style="width: 100%;"><tr>
<td>dsldEDFFair Wrappers</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>dsldEDFFair Wrappers</h2>

<h3>Description</h3>

 
<p>Explicitly Deweighted Features: control the effect of proxies 
related to sensitive variables for prediction. 
</p>


<h3>Usage</h3>

<pre><code class="language-R">dsldQeFairKNN(data, yName, sNames, deweightPars=NULL, yesYVal=NULL,k=25,
  scaleX=TRUE, holdout=floor(min(1000,0.1*nrow(data))))
dsldQeFairRF(data,yName,sNames,deweightPars=NULL, nTree=500, minNodeSize=10,
  mtry = floor(sqrt(ncol(data))),yesYVal=NULL,
  holdout=floor(min(1000,0.1*nrow(data))))
dsldQeFairRidgeLin(data, yName, sNames, deweightPars = NULL, 
  holdout=floor(min(1000,0.1*nrow(data))))
dsldQeFairRidgeLog(data, yName, sNames, deweightPars = NULL, holdout =
  floor(min(1000, 0.1 * nrow(data))), yesYVal = levels(data[, yName])[2])
## S3 method for class 'dsldQeFair'
predict(object,newx,...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>data</code></td>
<td>

<p>Dataframe, training set.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>yName</code></td>
<td>

<p>Name of the response variable column. 
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>sNames</code></td>
<td>

<p>Name(s) of the sensitive attribute column(s). 
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>deweightPars</code></td>
<td>

<p>Values for de-emphasizing variables in a split, e.g. 
'list(age=0.2,gender=0.5)'. In the linear case,
larger values means more deweighting, i.e. less influence of the given 
variable on predictions. For KNN and random forests, smaller
values mean more deweighting.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>scaleX</code></td>
<td>

<p>Scale the features. Defaults to TRUE.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>yesYVal</code></td>
<td>

<p>Y value to be considered "yes," to be coded 1 rather than 0.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>k</code></td>
<td>

<p>Number of nearest neighbors. In functions other than 
<code>dsldQeFairKNN</code> for which this is an argument, 
it is the number of neighbors to use in finding 
conditional probabilities via knnCalib.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>holdout</code></td>
<td>

<p>How many rows to use as the holdout/testing set. Can be NULL.
The testing set is used to calculate s correlation and test accuracy.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nTree</code></td>
<td>

<p>Number of trees.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>minNodeSize</code></td>
<td>

<p>Minimum number of data points in a tree node.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>mtry</code></td>
<td>

<p>Number of variables randomly tried at each split.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>object</code></td>
<td>

<p>An object returned by the dsld-EDFFAIR wrapper.  
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>newx</code></td>
<td>

<p>New data to be predicted. Must be in the same format as original data.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>

<p>Further arguments.
</p>
</td>
</tr>
</table>
<h3>Details</h3>

 
<p>The sensitive variables S are removed entirely, but there is concern
that they still affect prediction indirectly, via a set C of proxy
variables. 
</p>
<p>Linear EDF reduces the impact of the proxies through a shinkage
process similar to that of ridge regression. Specifically, instead
of minimizing the sum of squared errors SSE with respect to a
coefficient vector b, we minimize SSE + the squared norm of Db,
where D is a diagonal matrix with nonzero elements corresponding to
C. Large values penalizing variables in C, thus shrinking them.
</p>
<p>KNN EDF reduces the weights in Euclidean distance for variables in
C.  The random forests version reduces the probabilities that a
proxy will be used in splitting a node.
</p>
<p>By using various values of the deweighting parameters, the user can
choose a desired position in the Fairness-Utility Tradeoff.
</p>
<p>More details can be found in the references. 
</p>


<h3>Value</h3>

<p>The EDF functions return objects of class 'dsldQeFair', which include
components for test and base accuracy, summaries of inputs and so on.
</p>


<h3>Author(s)</h3>

<p>N. Matloff, A. Mittal, J. Tran
</p>


<h3>References</h3>

<p>https://github.com/matloff/EDFfair 
</p>


<h3>See Also</h3>

<p>Matloff, Norman, and Wenxi Zhang. "A novel regularization approach to fair ML." <br><code>arXiv preprint arXiv:2208.06557</code> (2022).
</p>


<h3>Examples</h3>

<pre><code class="language-R">  

data(compas1) 
data(svcensus) 

# dsldQeFairKNN: deweight "decile score" column with "race" as 
# the sensitive variable
knnOut &lt;- dsldQeFairKNN(compas1, "two_year_recid", "race", 
   list(decile_score=0.1), yesYVal = "Yes")
knnOut$testAcc 
knnOut$corrs 
predict(knnOut, compas1[1,-8]) 

# dsldFairRF: deweight "decile score" column with "race" as sensitive variable
rfOut &lt;- dsldQeFairRF(compas1, "two_year_recid", "race", 
   list(decile_score=0.3), yesYVal = "Yes")
rfOut$testAcc
rfOut$corrs 
predict(rfOut, compas1[1,-8]) 

# dsldQeFairRidgeLin: deweight "occupation" and "age" columns
lin &lt;- dsldQeFairRidgeLin(svcensus, "wageinc", "gender", deweightPars = 
  list(occ=.4, age=.2))
lin$testAcc 
lin$corrs 
predict(lin, svcensus[1,-4])

# dsldQeFairRidgeLin: deweight "decile score" column
log &lt;- dsldQeFairRidgeLog(compas1, "two_year_recid", "race", 
  list(decile_score=0.1), yesYVal = "Yes")
log$testAcc 
log$corrs 
predict(log, compas1[1,-8])
</code></pre>


</div>