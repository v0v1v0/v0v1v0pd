<div class="container">

<table style="width: 100%;"><tr>
<td>posterior</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Posterior state/class probabilities and classification</h2>

<h3>Description</h3>

<p>Return posterior state classifications and/or
probabilities for a fitted <code>(dep-)mix</code> object. In
the case of a latent class or mixture model, states refer to the 
classes/mixture components.
</p>
<p>There are different ways to define posterior state probabilities and the 
resulting classifications. The 'type' argument can be used to specify the
desired definition. The default is currently set to 'viterbi'.
Other options are 'global' and 'local' for state classification, and 
'filtering' and 'smoothing' for state probabilities. See Details for more 
information.
</p>


<h3>Usage</h3>

<pre><code class="language-R">	## S4 method for signature 'depmix'
posterior(object, type = c("viterbi", "global", "local", "filtering", "smoothing"))
	## S4 method for signature 'depmix.fitted'
posterior(object, type = c("viterbi", "global", "local", "filtering", "smoothing"))
	## S4 method for signature 'mix'
posterior(object, type = c("viterbi", "global", "local", "filtering", "smoothing"))
	## S4 method for signature 'mix.fitted'
posterior(object, type = c("viterbi", "global", "local", "filtering", "smoothing"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>object</code></td>
<td>
<p>A (fitted)(dep-)mix object.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>type</code></td>
<td>
<p>character, partial matching allowed. The type of classification or posterior probability desired. </p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>After fitting a <code>mix</code> or <code>depmix</code> model, one is often interested 
in determining the most probable mixture components or hidden states at each 
time-point <var>t</var>. This is also called decoding the hidden states from the observed 
data. There are at least two general ways to consider state classification:
'global' decoding means determining the most likely state sequence, whilst 
'local' decoding means determining the most likely state at each time point 
whilst not explicitly considering the identity of the hidden states at other
time points. For mixture models, both forms of decoding are identical.
</p>
<p>Global decoding is based on the conditional probability
<code class="reqn">p(S_1, \ldots, S_T \mid Y_1, \ldots, Y_T)</code>, and consists of determining, 
at each time point <code class="reqn">t = 1, \ldots, T</code>:
</p>
<p style="text-align: center;"><code class="reqn">s*_t = \arg \max_{i=1}^N p(S_1 = s*_1, \ldots, S_{t-1} = s*_{t-1}, S_t = i, S_{t+1} = s*_{t+1}, \ldots, S_T = s*_{T} \mid Y_1, \ldots, Y_T)</code>
</p>

<p>where <var>N</var> is the total number of states. These probabilities and the 
resulting classifications, are computed through the <code>viterbi</code> algorithm.
Setting <code>type = 'viterbi'</code> returns a <code>data.frame</code> with the Viterbi-decoded 
global state sequence in the first column, and the normalized "delta" probabilities
in the remainining columns. These "delta" probabilities are defined as the joint 
probability of the most likely state sequence ending in state <var>i</var> at time <var>t</var>,
and all the observations up to time <var>t</var>. The normalization of these joint
probabilities is done on a time-point basis (i.e., dividing the delta probability
by the sum of the delta probabilities for that time point for all possible states 
<var>j</var> (including state <var>i</var>)). These probabilities are not straightforward 
to interpret. Setting <code>type = "global"</code> returns just a vector with the 
Viterbi-decoded global state sequence.
</p>
<p>Local decoding is based on the smoothing probabilities 
<code class="reqn">p(S_t \mid Y_1, \ldots, Y_T)</code>, which are the "gamma" probabilities 
computed with the <code>forwardbackward</code> algorithm. Local decoding then
consists of determining, at each time point <code class="reqn">t = 1, \ldots, T</code> 
</p>
<p style="text-align: center;"><code class="reqn">s*_t = \arg \max_{i=1}^N p(S_t = i \mid Y_1, \ldots, Y_T)</code>
</p>
 
<p>where <var>N</var> is the total number of states. Setting <code>type = "local"</code> returns
a vector with the local decoded states. Setting <code>type = "smoothing"</code> returns
the smoothing probabilities which underlie this classification. When considering
the posterior probability of each state, the values returned by <code>type = "smoothing"</code>
are most likely what is wanted by the user.
</p>
<p>The option <code>type = "filtering"</code> returns a matrix with the so-called filtering probabilities, 
defined as <code class="reqn">p(S_t \mid Y_1, \ldots, Y_t)</code>, i.e. the probability of a hidden 
state at time <var>t</var> considering the observations up to and including time <var>t</var>.
</p>
<p>See the <code>fit</code> help page for an example. 
</p>


<h3>Value</h3>

<p>The return value of <code>posterior</code> depends on the value of the <code>type</code>
argument:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>type = 'viterbi'</code></td>
<td>
<p>Returns a data.frame with <code>nstates(object) + 1</code>
columns; the first column contains the states decoded through the Viterbi 
algorithm, the remaining columns contain the (normalized) delta probabilities.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>type = 'global'</code></td>
<td>
<p>Returns a vector which contains the states decoded 
through the Viterbi algorithm.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>type = 'local'</code></td>
<td>
<p>Returns a vector which contains the states decoded 
as the maximum of the smoothing probabilities.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>type = 'filtering'</code></td>
<td>
<p>Returns a matrix which contains the posterior 
probabilities of each state, conditional upon the responses observed thus 
far.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>type = 'smoothing'</code></td>
<td>
<p>Returns a matrix which contains the posterior 
probabilities of each state, conditional upon all the responses observed.</p>
</td>
</tr>
</table>
<p>See Details for more information.
</p>


<h3>Note</h3>

<p>The initial version of this function was a simple wrapper to return the value of the <code>posterior</code> slot in a <code>mix-fitted</code> or <code>depmix-fitted</code> object. The value of this slot is set by a call of the <code>viterbi</code> method. For backwards compatibility, the default value of the <code>type</code> argument is set to <code>"viterbi"</code>, which returns the same. As the "delta" probabilities returned as part of this may be misinterpreted, and may not be the desired posterior probabilities, the updated version of this method now allows for other return values, and the <code>type = "viterbi"</code> option should be considered depreciated.</p>


<h3>Author(s)</h3>

<p>Maarten Speekenbrink &amp; Ingmar Visser</p>


<h3>References</h3>

 	
<p>Lawrence R. Rabiner (1989). A tutorial on hidden Markov models and
selected applications in speech recognition. <em>Proceedings of
IEEE</em>, 77-2, p.  267-295. 
</p>


<h3>Examples</h3>

<pre><code class="language-R">
data(speed)

# 2-state model on rt and corr from speed data set 
# with Pacc as covariate on the transition matrix
# ntimes is used to specify the lengths of 3 separate series
mod &lt;- depmix(list(rt~1,corr~1),data=speed,transition=~Pacc,nstates=2,
	family=list(gaussian(),multinomial("identity")),ntimes=c(168,134,137))
fmod &lt;- fit(mod)

# Global decoding:
pst_global &lt;- posterior(fmod, type = "global")

# Local decoding:
pst_local &lt;- posterior(fmod,type="local")

# Global and local decoding provide different results:
identical(pst_global, pst_local)

# smoothing probabilities are used for local decoding, and may be used as 
# easily interpretable posterior state probabilities
pst_prob &lt;- posterior(fmod, type = "smoothing")

# "delta" probabilities from the Viterbi algorithm
pst_delta &lt;- posterior(fmod, type="viterbi")[,-1]

# The smoothing and "delta" probabilities are different:
identical(pst_prob, pst_delta)

# Filtering probabilities are an alternative to smoothing probabilities:
pst_filt &lt;- posterior(fmod, type = "filtering")

# The smoothing and filtering probabilities are different:
identical(pst_prob, pst_filt)
</code></pre>


</div>