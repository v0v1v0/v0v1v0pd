<div class="container">

<table style="width: 100%;"><tr>
<td>DoubleMLPLIV</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Double machine learning for partially linear IV regression models</h2>

<h3>Description</h3>

<p>Double machine learning for partially linear IV regression models.
</p>


<h3>Format</h3>

<p>R6::R6Class object inheriting from DoubleML.
</p>


<h3>Details</h3>

<p>Partially linear IV regression (PLIV) models take the form
</p>
<p><code class="reqn">Y - D\theta_0 = g_0(X) + \zeta</code>,
</p>
<p><code class="reqn">Z = m_0(X) + V</code>,
</p>
<p>with <code class="reqn">E[\zeta|Z,X]=0</code> and <code class="reqn">E[V|X] = 0</code>. <code class="reqn">Y</code> is the outcome variable variable, <code class="reqn">D</code> is the policy variable of interest and <code class="reqn">Z</code> denotes one or multiple instrumental variables. The high-dimensional vector <code class="reqn">X = (X_1, \ldots, X_p)</code> consists of other confounding covariates, and <code class="reqn">\zeta</code> and <code class="reqn">V</code> are stochastic errors.
</p>


<h3>Super class</h3>

<p><code>DoubleML::DoubleML</code> -&gt; <code>DoubleMLPLIV</code>
</p>


<h3>Active bindings</h3>

<div class="r6-active-bindings">

<dl>
<dt><code>partialX</code></dt>
<dd>
<p>(<code>logical(1)</code>)  <br>
Indicates whether covariates <code class="reqn">X</code> should be partialled out.</p>
</dd>
<dt><code>partialZ</code></dt>
<dd>
<p>(<code>logical(1)</code>) <br>
Indicates whether instruments <code class="reqn">Z</code> should be partialled out.</p>
</dd>
</dl>
</div>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-DoubleMLPLIV-new"><code>DoubleMLPLIV$new()</code></a>
</p>
</li>
<li> <p><a href="#method-DoubleMLPLIV-set_ml_nuisance_params"><code>DoubleMLPLIV$set_ml_nuisance_params()</code></a>
</p>
</li>
<li> <p><a href="#method-DoubleMLPLIV-tune"><code>DoubleMLPLIV$tune()</code></a>
</p>
</li>
<li> <p><a href="#method-DoubleMLPLIV-clone"><code>DoubleMLPLIV$clone()</code></a>
</p>
</li>
</ul>
<details><summary>Inherited methods</summary><ul>
<li><span class="pkg-link" data-pkg="DoubleML" data-topic="DoubleML" data-id="bootstrap"><a href="../../DoubleML/html/DoubleML.html#method-DoubleML-bootstrap"><code>DoubleML::DoubleML$bootstrap()</code></a></span></li>
<li><span class="pkg-link" data-pkg="DoubleML" data-topic="DoubleML" data-id="confint"><a href="../../DoubleML/html/DoubleML.html#method-DoubleML-confint"><code>DoubleML::DoubleML$confint()</code></a></span></li>
<li><span class="pkg-link" data-pkg="DoubleML" data-topic="DoubleML" data-id="fit"><a href="../../DoubleML/html/DoubleML.html#method-DoubleML-fit"><code>DoubleML::DoubleML$fit()</code></a></span></li>
<li><span class="pkg-link" data-pkg="DoubleML" data-topic="DoubleML" data-id="get_params"><a href="../../DoubleML/html/DoubleML.html#method-DoubleML-get_params"><code>DoubleML::DoubleML$get_params()</code></a></span></li>
<li><span class="pkg-link" data-pkg="DoubleML" data-topic="DoubleML" data-id="learner_names"><a href="../../DoubleML/html/DoubleML.html#method-DoubleML-learner_names"><code>DoubleML::DoubleML$learner_names()</code></a></span></li>
<li><span class="pkg-link" data-pkg="DoubleML" data-topic="DoubleML" data-id="p_adjust"><a href="../../DoubleML/html/DoubleML.html#method-DoubleML-p_adjust"><code>DoubleML::DoubleML$p_adjust()</code></a></span></li>
<li><span class="pkg-link" data-pkg="DoubleML" data-topic="DoubleML" data-id="params_names"><a href="../../DoubleML/html/DoubleML.html#method-DoubleML-params_names"><code>DoubleML::DoubleML$params_names()</code></a></span></li>
<li><span class="pkg-link" data-pkg="DoubleML" data-topic="DoubleML" data-id="print"><a href="../../DoubleML/html/DoubleML.html#method-DoubleML-print"><code>DoubleML::DoubleML$print()</code></a></span></li>
<li><span class="pkg-link" data-pkg="DoubleML" data-topic="DoubleML" data-id="set_sample_splitting"><a href="../../DoubleML/html/DoubleML.html#method-DoubleML-set_sample_splitting"><code>DoubleML::DoubleML$set_sample_splitting()</code></a></span></li>
<li><span class="pkg-link" data-pkg="DoubleML" data-topic="DoubleML" data-id="split_samples"><a href="../../DoubleML/html/DoubleML.html#method-DoubleML-split_samples"><code>DoubleML::DoubleML$split_samples()</code></a></span></li>
<li><span class="pkg-link" data-pkg="DoubleML" data-topic="DoubleML" data-id="summary"><a href="../../DoubleML/html/DoubleML.html#method-DoubleML-summary"><code>DoubleML::DoubleML$summary()</code></a></span></li>
</ul></details><hr>
<a id="method-DoubleMLPLIV-new"></a>



<h4>Method <code>new()</code>
</h4>

<p>Creates a new instance of this R6 class.
</p>


<h5>Usage</h5>

<div class="r"><pre>DoubleMLPLIV$new(
  data,
  ml_l,
  ml_m,
  ml_r,
  ml_g = NULL,
  partialX = TRUE,
  partialZ = FALSE,
  n_folds = 5,
  n_rep = 1,
  score = "partialling out",
  dml_procedure = "dml2",
  draw_sample_splitting = TRUE,
  apply_cross_fitting = TRUE
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>data</code></dt>
<dd>
<p>(<code>DoubleMLData</code>) <br>
The <code>DoubleMLData</code> object providing the data and specifying the variables
of the causal model.</p>
</dd>
<dt><code>ml_l</code></dt>
<dd>
<p>(<code>LearnerRegr</code>,
<code>Learner</code>, <code>character(1)</code>) <br>
A learner of the class <code>LearnerRegr</code>, which is
available from <a href="https://mlr3.mlr-org.com/index.html">mlr3</a> or its
extension packages <a href="https://mlr3learners.mlr-org.com/">mlr3learners</a> or
<a href="https://mlr3extralearners.mlr-org.com/">mlr3extralearners</a>.
Alternatively, a <code>Learner</code> object with public field
<code>task_type = "regr"</code> can be passed, for example of class
<code>GraphLearner</code>. The learner can possibly
be passed with specified parameters, for example
<code>lrn("regr.cv_glmnet", s = "lambda.min")</code>.  <br><code>ml_l</code> refers to the nuisance function <code class="reqn">l_0(X) = E[Y|X]</code>.</p>
</dd>
<dt><code>ml_m</code></dt>
<dd>
<p>(<code>LearnerRegr</code>,
<code>Learner</code>, <code>character(1)</code>) <br>
A learner of the class <code>LearnerRegr</code>, which is
available from <a href="https://mlr3.mlr-org.com/index.html">mlr3</a> or its
extension packages <a href="https://mlr3learners.mlr-org.com/">mlr3learners</a> or
<a href="https://mlr3extralearners.mlr-org.com/">mlr3extralearners</a>.
Alternatively, a <code>Learner</code> object with public field
<code>task_type = "regr"</code> can be passed, for example of class
<code>GraphLearner</code>. The learner can possibly
be passed with specified parameters, for example
<code>lrn("regr.cv_glmnet", s = "lambda.min")</code>. <br><code>ml_m</code> refers to the nuisance function <code class="reqn">m_0(X) = E[Z|X]</code>.</p>
</dd>
<dt><code>ml_r</code></dt>
<dd>
<p>(<code>LearnerRegr</code>,
<code>Learner</code>, <code>character(1)</code>) <br>
A learner of the class <code>LearnerRegr</code>, which is
available from <a href="https://mlr3.mlr-org.com/index.html">mlr3</a> or its
extension packages <a href="https://mlr3learners.mlr-org.com/">mlr3learners</a> or
<a href="https://mlr3extralearners.mlr-org.com/">mlr3extralearners</a>.
Alternatively, a <code>Learner</code> object with public field
<code>task_type = "regr"</code> can be passed, for example of class
<code>GraphLearner</code>. The learner can possibly
be passed with specified parameters, for example
<code>lrn("regr.cv_glmnet", s = "lambda.min")</code>. <br><code>ml_r</code> refers to the nuisance function <code class="reqn">r_0(X) = E[D|X]</code>.</p>
</dd>
<dt><code>ml_g</code></dt>
<dd>
<p>(<code>LearnerRegr</code>,
<code>Learner</code>, <code>character(1)</code>) <br>
A learner of the class <code>LearnerRegr</code>, which is
available from <a href="https://mlr3.mlr-org.com/index.html">mlr3</a> or its
extension packages <a href="https://mlr3learners.mlr-org.com/">mlr3learners</a> or
<a href="https://mlr3extralearners.mlr-org.com/">mlr3extralearners</a>.
Alternatively, a <code>Learner</code> object with public field
<code>task_type = "regr"</code> can be passed, for example of class
<code>GraphLearner</code>. The learner can possibly
be passed with specified parameters, for example
<code>lrn("regr.cv_glmnet", s = "lambda.min")</code>. <br><code>ml_g</code> refers to the nuisance function <code class="reqn">g_0(X) = E[Y - D\theta_0|X]</code>.
Note: The learner <code>ml_g</code> is only required for the score <code>'IV-type'</code>.
Optionally, it can be specified and estimated for callable scores.</p>
</dd>
<dt><code>partialX</code></dt>
<dd>
<p>(<code>logical(1)</code>)  <br>
Indicates whether covariates <code class="reqn">X</code> should be partialled out.
Default is <code>TRUE</code>.</p>
</dd>
<dt><code>partialZ</code></dt>
<dd>
<p>(<code>logical(1)</code>) <br>
Indicates whether instruments <code class="reqn">Z</code> should be partialled out.
Default is <code>FALSE</code>.</p>
</dd>
<dt><code>n_folds</code></dt>
<dd>
<p>(<code>integer(1)</code>)<br>
Number of folds. Default is <code>5</code>.</p>
</dd>
<dt><code>n_rep</code></dt>
<dd>
<p>(<code>integer(1)</code>) <br>
Number of repetitions for the sample splitting. Default is <code>1</code>.</p>
</dd>
<dt><code>score</code></dt>
<dd>
<p>(<code>character(1)</code>, <code style="white-space: pre;">⁠function()⁠</code>) <br>
A <code>character(1)</code> (<code>"partialling out"</code> or <code>"IV-type"</code>) or a <code style="white-space: pre;">⁠function()⁠</code>
specifying the score function.
If a <code style="white-space: pre;">⁠function()⁠</code> is provided, it must be of the form
<code style="white-space: pre;">⁠function(y, z, d, l_hat, m_hat, r_hat, g_hat, smpls)⁠</code> and
the returned output must be a named <code>list()</code> with elements
<code>psi_a</code> and <code>psi_b</code>. Default is <code>"partialling out"</code>.</p>
</dd>
<dt><code>dml_procedure</code></dt>
<dd>
<p>(<code>character(1)</code>) <br>
A <code>character(1)</code> (<code>"dml1"</code> or <code>"dml2"</code>) specifying the double machine
learning algorithm. Default is <code>"dml2"</code>.</p>
</dd>
<dt><code>draw_sample_splitting</code></dt>
<dd>
<p>(<code>logical(1)</code>) <br>
Indicates whether the sample splitting should be drawn during
initialization of the object. Default is <code>TRUE</code>.</p>
</dd>
<dt><code>apply_cross_fitting</code></dt>
<dd>
<p>(<code>logical(1)</code>) <br>
Indicates whether cross-fitting should be applied. Default is <code>TRUE</code>.</p>
</dd>
</dl>
</div>


<hr>
<a id="method-DoubleMLPLIV-set_ml_nuisance_params"></a>



<h4>Method <code>set_ml_nuisance_params()</code>
</h4>

<p>Set hyperparameters for the nuisance models of DoubleML models.
</p>
<p>Note that in the current implementation, either all parameters have to
be set globally or all parameters have to be provided fold-specific.
</p>


<h5>Usage</h5>

<div class="r"><pre>DoubleMLPLIV$set_ml_nuisance_params(
  learner = NULL,
  treat_var = NULL,
  params,
  set_fold_specific = FALSE
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>learner</code></dt>
<dd>
<p>(<code>character(1)</code>) <br>
The nuisance model/learner (see method <code>params_names</code>).</p>
</dd>
<dt><code>treat_var</code></dt>
<dd>
<p>(<code>character(1)</code>) <br>
The treatment varaible (hyperparameters can be set treatment-variable
specific).</p>
</dd>
<dt><code>params</code></dt>
<dd>
<p>(named <code>list()</code>) <br>
A named <code>list()</code> with estimator parameters. Parameters are used for all
folds by default. Alternatively, parameters can be passed in a
fold-specific way if option  <code>fold_specific</code>is <code>TRUE</code>. In this case, the
outer list needs to be of length <code>n_rep</code> and the inner list of length
<code>n_folds</code>.</p>
</dd>
<dt><code>set_fold_specific</code></dt>
<dd>
<p>(<code>logical(1)</code>) <br>
Indicates if the parameters passed in <code>params</code> should be passed in
fold-specific way. Default is <code>FALSE</code>. If <code>TRUE</code>, the outer list needs
to be of length <code>n_rep</code> and the inner list of length <code>n_folds</code>.
Note that in the current implementation, either all parameters have to
be set globally or all parameters have to be provided fold-specific.</p>
</dd>
</dl>
</div>



<h5>Returns</h5>

<p>self
</p>


<hr>
<a id="method-DoubleMLPLIV-tune"></a>



<h4>Method <code>tune()</code>
</h4>

<p>Hyperparameter-tuning for DoubleML models.
</p>
<p>The hyperparameter-tuning is performed using the tuning methods provided
in the <a href="https://mlr3tuning.mlr-org.com/">mlr3tuning</a> package. For more
information on tuning in <a href="https://mlr3.mlr-org.com/">mlr3</a>, we refer to
the section on parameter tuning in the
<a href="https://mlr3book.mlr-org.com/chapters/chapter4/hyperparameter_optimization.html">mlr3 book</a>.
</p>


<h5>Usage</h5>

<div class="r"><pre>DoubleMLPLIV$tune(
  param_set,
  tune_settings = list(n_folds_tune = 5, rsmp_tune = mlr3::rsmp("cv", folds = 5), measure
    = NULL, terminator = mlr3tuning::trm("evals", n_evals = 20), algorithm =
    mlr3tuning::tnr("grid_search"), resolution = 5),
  tune_on_folds = FALSE
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>param_set</code></dt>
<dd>
<p>(named <code>list()</code>) <br>
A named <code>list</code> with a parameter grid for each nuisance model/learner
(see method <code>learner_names()</code>). The parameter grid must be an object of
class ParamSet.</p>
</dd>
<dt><code>tune_settings</code></dt>
<dd>
<p>(named <code>list()</code>) <br>
A named <code>list()</code> with arguments passed to the hyperparameter-tuning with
<a href="https://mlr3tuning.mlr-org.com/">mlr3tuning</a> to set up
TuningInstance objects.
<code>tune_settings</code> has entries
</p>

<ul>
<li> <p><code>terminator</code> (Terminator) <br>
A Terminator object. Specification of <code>terminator</code>
is required to perform tuning.
</p>
</li>
<li> <p><code>algorithm</code> (Tuner or <code>character(1)</code>) <br>
A Tuner object (recommended) or key passed to the
respective dictionary to specify the tuning algorithm used in
tnr(). <code>algorithm</code> is passed as an argument to
tnr(). If <code>algorithm</code> is not specified by the users,
default is set to <code>"grid_search"</code>. If set to <code>"grid_search"</code>, then
additional argument <code>"resolution"</code> is required.
</p>
</li>
<li> <p><code>rsmp_tune</code> (Resampling or <code>character(1)</code>)<br>
A Resampling object (recommended) or option passed
to rsmp() to initialize a
Resampling for parameter tuning in <code>mlr3</code>.
If not specified by the user, default is set to <code>"cv"</code>
(cross-validation).
</p>
</li>
<li> <p><code>n_folds_tune</code> (<code>integer(1)</code>, optional) <br>
If <code>rsmp_tune = "cv"</code>, number of folds used for cross-validation.
If not specified by the user, default is set to <code>5</code>.
</p>
</li>
<li> <p><code>measure</code> (<code>NULL</code>, named <code>list()</code>, optional) <br>
Named list containing the measures used for parameter tuning. Entries in
list must either be Measure objects or keys to be
passed to passed to msr(). The names of the entries must
match the learner names (see method <code>learner_names()</code>). If set to <code>NULL</code>,
default measures are used, i.e., <code>"regr.mse"</code> for continuous outcome
variables and <code>"classif.ce"</code> for binary outcomes.
</p>
</li>
<li> <p><code>resolution</code> (<code>character(1)</code>) <br> The key passed to the respective
dictionary to specify  the tuning algorithm used in
tnr(). <code>resolution</code> is passed as an argument to
tnr().
</p>
</li>
</ul>
</dd>
<dt><code>tune_on_folds</code></dt>
<dd>
<p>(<code>logical(1)</code>) <br>
Indicates whether the tuning should be done fold-specific or globally.
Default is <code>FALSE</code>.</p>
</dd>
</dl>
</div>



<h5>Returns</h5>

<p>self
</p>


<hr>
<a id="method-DoubleMLPLIV-clone"></a>



<h4>Method <code>clone()</code>
</h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>DoubleMLPLIV$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt>
<dd>
<p>Whether to make a deep clone.</p>
</dd>
</dl>
</div>




<h3>See Also</h3>

<p>Other DoubleML: 
<code>DoubleML</code>,
<code>DoubleMLIIVM</code>,
<code>DoubleMLIRM</code>,
<code>DoubleMLPLR</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">
library(DoubleML)
library(mlr3)
library(mlr3learners)
library(data.table)
set.seed(2)
ml_l = lrn("regr.ranger", num.trees = 100, mtry = 20, min.node.size = 2, max.depth = 5)
ml_m = ml_l$clone()
ml_r = ml_l$clone()
obj_dml_data = make_pliv_CHS2015(alpha = 1, n_obs = 500, dim_x = 20, dim_z = 1)
dml_pliv_obj = DoubleMLPLIV$new(obj_dml_data, ml_l, ml_m, ml_r)
dml_pliv_obj$fit()
dml_pliv_obj$summary()


## Not run: 
library(DoubleML)
library(mlr3)
library(mlr3learners)
library(mlr3tuning)
library(data.table)
set.seed(2)
ml_l = lrn("regr.rpart")
ml_m = ml_l$clone()
ml_r = ml_l$clone()
obj_dml_data = make_pliv_CHS2015(
  alpha = 1, n_obs = 500, dim_x = 20,
  dim_z = 1)
dml_pliv_obj = DoubleMLPLIV$new(obj_dml_data, ml_l, ml_m, ml_r)
param_grid = list(
  "ml_l" = paradox::ps(
    cp = paradox::p_dbl(lower = 0.01, upper = 0.02),
    minsplit = paradox::p_int(lower = 1, upper = 2)),
  "ml_m" = paradox::ps(
    cp = paradox::p_dbl(lower = 0.01, upper = 0.02),
    minsplit = paradox::p_int(lower = 1, upper = 2)),
  "ml_r" = paradox::ps(
    cp = paradox::p_dbl(lower = 0.01, upper = 0.02),
    minsplit = paradox::p_int(lower = 1, upper = 2)))

# minimum requirements for tune_settings
tune_settings = list(
  terminator = mlr3tuning::trm("evals", n_evals = 5),
  algorithm = mlr3tuning::tnr("grid_search", resolution = 5))
dml_pliv_obj$tune(param_set = param_grid, tune_settings = tune_settings)
dml_pliv_obj$fit()
dml_pliv_obj$summary()

## End(Not run)
</code></pre>


</div>