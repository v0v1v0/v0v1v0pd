<div class="container">

<table style="width: 100%;"><tr>
<td>ddml_fpliv</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Estimator for the Flexible Partially Linear IV Model.</h2>

<h3>Description</h3>

<p>Estimator for the flexible partially linear IV model.
</p>


<h3>Usage</h3>

<pre><code class="language-R">ddml_fpliv(
  y,
  D,
  Z,
  X,
  learners,
  learners_DXZ = learners,
  learners_DX = learners,
  sample_folds = 10,
  ensemble_type = "nnls",
  shortstack = FALSE,
  cv_folds = 10,
  enforce_LIE = TRUE,
  custom_ensemble_weights = NULL,
  custom_ensemble_weights_DXZ = custom_ensemble_weights,
  custom_ensemble_weights_DX = custom_ensemble_weights,
  cluster_variable = seq_along(y),
  subsamples = NULL,
  cv_subsamples_list = NULL,
  silent = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>
<p>The outcome variable.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>D</code></td>
<td>
<p>A matrix of endogenous variables.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Z</code></td>
<td>
<p>A (sparse) matrix of instruments.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>X</code></td>
<td>
<p>A (sparse) matrix of control variables.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>learners</code></td>
<td>
<p>May take one of two forms, depending on whether a single
learner or stacking with multiple learners is used for estimation of the
conditional expectation functions.
If a single learner is used, <code>learners</code> is a list with two named
elements:
</p>

<ul>
<li>
<p><code>what</code> The base learner function. The function must be
such that it predicts a named input <code>y</code> using a named input
<code>X</code>.
</p>
</li>
<li>
<p><code>args</code> Optional arguments to be passed to <code>what</code>.
</p>
</li>
</ul>
<p>If stacking with multiple learners is used, <code>learners</code> is a list of
lists, each containing four named elements:
</p>

<ul>
<li>
<p><code>fun</code> The base learner function. The function must be
such that it predicts a named input <code>y</code> using a named input
<code>X</code>.
</p>
</li>
<li>
<p><code>args</code> Optional arguments to be passed to <code>fun</code>.
</p>
</li>
<li>
<p><code>assign_X</code> An optional vector of column indices
corresponding to control variables in <code>X</code> that are passed to
the base learner.
</p>
</li>
<li>
<p><code>assign_Z</code> An optional vector of column indices
corresponding to instruments in <code>Z</code> that are passed to the
base learner.
</p>
</li>
</ul>
<p>Omission of the <code>args</code> element results in default arguments being
used in <code>fun</code>. Omission of <code>assign_X</code> (and/or <code>assign_Z</code>)
results in inclusion of all variables in <code>X</code> (and/or <code>Z</code>).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>learners_DXZ, learners_DX</code></td>
<td>
<p>Optional arguments to allow for different
estimators of <code class="reqn">E[D \vert X, Z]</code>, <code class="reqn">E[D \vert X]</code>. Setup is
identical to <code>learners</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>sample_folds</code></td>
<td>
<p>Number of cross-fitting folds.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ensemble_type</code></td>
<td>
<p>Ensemble method to combine base learners into final
estimate of the conditional expectation functions. Possible values are:
</p>

<ul>
<li>
<p><code>"nnls"</code> Non-negative least squares.
</p>
</li>
<li>
<p><code>"nnls1"</code> Non-negative least squares with the constraint
that all weights sum to one.
</p>
</li>
<li>
<p><code>"singlebest"</code> Select base learner with minimum MSPE.
</p>
</li>
<li>
<p><code>"ols"</code> Ordinary least squares.
</p>
</li>
<li>
<p><code>"average"</code> Simple average over base learners.
</p>
</li>
</ul>
<p>Multiple ensemble types may be passed as a vector of strings.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>shortstack</code></td>
<td>
<p>Boolean to use short-stacking.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cv_folds</code></td>
<td>
<p>Number of folds used for cross-validation in ensemble
construction.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>enforce_LIE</code></td>
<td>
<p>Indicator equal to 1 if the law of iterated expectations
is enforced in the first stage.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>custom_ensemble_weights</code></td>
<td>
<p>A numerical matrix with user-specified
ensemble weights. Each column corresponds to a custom ensemble
specification, each row corresponds to a base learner in <code>learners</code>
(in chronological order). Optional column names are used to name the
estimation results corresponding the custom ensemble specification.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>custom_ensemble_weights_DXZ, custom_ensemble_weights_DX</code></td>
<td>
<p>Optional
arguments to allow for different
custom ensemble weights for <code>learners_DXZ</code>,<code>learners_DX</code>. Setup
is identical to <code>custom_ensemble_weights</code>. Note:
<code>custom_ensemble_weights</code> and
<code>custom_ensemble_weights_DXZ</code>,<code>custom_ensemble_weights_DX</code> must
have the same number of columns.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cluster_variable</code></td>
<td>
<p>A vector of cluster indices.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>subsamples</code></td>
<td>
<p>List of vectors with sample indices for cross-fitting.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cv_subsamples_list</code></td>
<td>
<p>List of lists, each corresponding to a subsample
containing vectors with subsample indices for cross-validation.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>silent</code></td>
<td>
<p>Boolean to silence estimation updates.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p><code>ddml_fpliv</code> provides a double/debiased machine learning
estimator for the parameter of interest <code class="reqn">\theta_0</code> in the partially
linear IV model given by
</p>
<p><code class="reqn">Y = \theta_0D + g_0(X) + U,</code>
</p>
<p>where <code class="reqn">(Y, D, X, Z, U)</code> is a random vector such that
<code class="reqn">E[U\vert X, Z] = 0</code> and <code class="reqn">E[Var(E[D\vert X, Z]\vert X)] \neq 0</code>,
and <code class="reqn">g_0</code> is an unknown nuisance function.
</p>


<h3>Value</h3>

<p><code>ddml_fpliv</code> returns an object of S3 class
<code>ddml_fpliv</code>. An object of class <code>ddml_fpliv</code> is a list
containing the following components:
</p>

<dl>
<dt><code>coef</code></dt>
<dd>
<p>A vector with the <code class="reqn">\theta_0</code> estimates.</p>
</dd>
<dt><code>weights</code></dt>
<dd>
<p>A list of matrices, providing the weight
assigned to each base learner (in chronological order) by the
ensemble procedure.</p>
</dd>
<dt><code>mspe</code></dt>
<dd>
<p>A list of matrices, providing the MSPE of each
base learner (in chronological order) computed by the
cross-validation step in the ensemble construction.</p>
</dd>
<dt><code>iv_fit</code></dt>
<dd>
<p>Object of class <code>ivreg</code> from the IV
regression of <code class="reqn">Y - \hat{E}[Y\vert X]</code> on
<code class="reqn">D - \hat{E}[D\vert X]</code> using
<code class="reqn">\hat{E}[D\vert X,Z] - \hat{E}[D\vert X]</code> as the instrument.</p>
</dd>
<dt>
<code>learners</code>,<code>learners_DX</code>,<code>learners_DXZ</code>,
<code>cluster_variable</code>,<code>subsamples</code>,
<code>cv_subsamples_list</code>,<code>ensemble_type</code>
</dt>
<dd>
<p>Pass-through of
selected user-provided arguments. See above.</p>
</dd>
</dl>
<h3>References</h3>

<p>Ahrens A, Hansen C B, Schaffer M E, Wiemann T (2023). "ddml: Double/debiased
machine learning in Stata." <a href="https://arxiv.org/abs/2301.09397">https://arxiv.org/abs/2301.09397</a>
</p>
<p>Chernozhukov V, Chetverikov D, Demirer M, Duflo E, Hansen C B, Newey W,
Robins J (2018). "Double/debiased machine learning for treatment and
structural parameters." The Econometrics Journal, 21(1), C1-C68.
</p>
<p>Wolpert D H (1992). "Stacked generalization." Neural Networks, 5(2), 241-259.
</p>


<h3>See Also</h3>

<p><code>summary.ddml_fpliv()</code>, <code>AER::ivreg()</code>
</p>
<p>Other ddml: 
<code>ddml_ate()</code>,
<code>ddml_late()</code>,
<code>ddml_pliv()</code>,
<code>ddml_plm()</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R"># Construct variables from the included Angrist &amp; Evans (1998) data
y = AE98[, "worked"]
D = AE98[, "morekids"]
Z = AE98[, "samesex", drop = FALSE]
X = AE98[, c("age","agefst","black","hisp","othrace","educ")]

# Estimate the partially linear IV model using a single base learner: Ridge.
fpliv_fit &lt;- ddml_fpliv(y, D, Z, X,
                        learners = list(what = mdl_glmnet,
                                        args = list(alpha = 0)),
                        sample_folds = 2,
                        silent = TRUE)
summary(fpliv_fit)
</code></pre>


</div>