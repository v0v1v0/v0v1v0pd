<div class="container">

<table style="width: 100%;"><tr>
<td>qEI.grad</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Gradient of the multipoint expected improvement (qEI) criterion</h2>

<h3>Description</h3>

<p>Computes an exact or approximate gradient of the multipoint expected
improvement criterion
</p>


<h3>Usage</h3>

<pre><code class="language-R">qEI.grad(
  x,
  model,
  plugin = NULL,
  type = "UK",
  minimization = TRUE,
  fastCompute = TRUE,
  eps = 10^(-6),
  envir = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>a matrix representing the set of input points (one row corresponds
to one point) where to evaluate the gradient,</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>model</code></td>
<td>
<p>an object of class <code>km</code>,</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>plugin</code></td>
<td>
<p>optional scalar: if provided, it replaces the minimum of the
current observations,</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>type</code></td>
<td>
<p>"SK" or "UK" (by default), depending whether uncertainty
related to trend estimation has to be taken into account,</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>minimization</code></td>
<td>
<p>logical specifying if EI is used in minimiziation or in
maximization,</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>fastCompute</code></td>
<td>
<p>if TRUE, a fast approximation method based on a
semi-analytic formula is used (see [Marmin 2014] for details),</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>eps</code></td>
<td>
<p>the value of <em>epsilon</em> of the fast computation trick.
Relevant only if <code>fastComputation</code> is TRUE,</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>envir</code></td>
<td>
<p>an optional environment specifying where to get intermediate
values calculated in <code>qEI</code>.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>The gradient of the multipoint expected improvement criterion with
respect to x. A 0-matrix is returned if the batch of input points contains
twice the same point or a point from the design experiment of the km object
(the gradient does not exist in these cases).
</p>


<h3>Author(s)</h3>

<p>Sebastien Marmin 
</p>
<p>Clement Chevalier 
</p>
<p>David Ginsbourger
</p>


<h3>References</h3>

<p>C. Chevalier and D. Ginsbourger (2014) Learning and Intelligent
Optimization - 7th International Conference, Lion 7, Catania, Italy,
January 7-11, 2013, Revised Selected Papers, chapter Fast computation of
the multipoint Expected Improvement with applications in batch selection,
pages 59-69, Springer.
</p>
<p>D. Ginsbourger, R. Le Riche, L. Carraro (2007), A Multipoint Criterion for
Deterministic Parallel Global Optimization based on Kriging. The
International Conference on Non Convex Programming, 2007.
</p>
<p>D. Ginsbourger, R. Le Riche, and L. Carraro. Kriging is well-suited to
parallelize optimization (2010), In Lim Meng Hiot, Yew Soon Ong, Yoel
Tenne, and Chi-Keong Goh, editors, <em>Computational Intelligence in
Expensive Optimization Problems</em>, Adaptation Learning and Optimization,
pages 131-162. Springer Berlin Heidelberg.
</p>
<p>S. Marmin. Developpements pour l'evaluation et la maximisation du critere
d'amelioration esperee multipoint en optimisation globale (2014). Master's
thesis, Mines Saint-Etienne (France) and University of Bern (Switzerland).
</p>
<p>J. Mockus (1988), <em>Bayesian Approach to Global Optimization</em>. Kluwer
academic publishers.
</p>
<p>M. Schonlau (1997), <em>Computer experiments and global optimization</em>,
Ph.D. thesis, University of Waterloo.
</p>


<h3>See Also</h3>

<p><code>qEI</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">
set.seed(15)
# Example 1 - validation by comparison to finite difference approximations

# a 9-points factorial design, and the corresponding response
d &lt;- 2
n &lt;- 9
design &lt;- expand.grid(seq(0,1,length=3), seq(0,1,length=3)) 
names(design)&lt;-c("x1", "x2")
design &lt;- data.frame(design) 
names(design)&lt;-c("x1", "x2")
y &lt;- apply(design, 1, branin)
y &lt;- data.frame(y) 
names(y) &lt;- "y" 

# learning
model &lt;- km(~1, design=design, response=y)

# pick up 2 points sampled from the simple expected improvement
q &lt;- 2  # increase to 4 for a more meaningful test
X &lt;- sampleFromEI(model,n=q)

# compute the gradient at the 4-point batch
grad.analytic &lt;- qEI.grad(X,model)
# numerically compute the gradient
grad.numeric &lt;- matrix(NaN,q,d)
eps &lt;- 10^(-6)
EPS &lt;- matrix(0,q,d)
for (i in 1:q) {
  for (j in 1:d) {
    EPS[i,j] &lt;- eps
    grad.numeric[i,j] &lt;- 1/eps*(qEI(X+EPS,model,fastCompute=FALSE)-qEI(X,model,fastCompute=FALSE))
    EPS[i,j] &lt;- 0
  }  
}
print(grad.numeric)
print(grad.analytic)

## Not run: 
# graphics: displays the EI criterion, the design points in black, 
# the batch points in red and the gradient in blue.
nGrid &lt;- 15
gridAxe1 &lt;- seq(lower[1],upper[1],length=nGrid)
gridAxe2 &lt;- seq(lower[2],upper[2],length=nGrid)
grid &lt;- expand.grid(gridAxe1,gridAxe2)
aa &lt;- apply(grid,1,EI,model=model)
myMat &lt;- matrix(aa,nrow=nGrid)
image(x = gridAxe1, y = gridAxe2, z = myMat, 
      col = colorRampPalette(c("darkgray","white"))(5*10), 
      ylab = names(design)[1], xlab=names(design)[2], 
      main = "qEI-gradient of a batch of 4 points", axes = TRUE, 
      zlim = c(min(myMat), max(myMat)))
contour(x = gridAxe1, y = gridAxe2, z = myMat, 
        add = TRUE, nlevels = 10)
points(X[,1],X[,2],pch=19,col='red')
points(model@X[,1],model@X[,2],pch=19)
arrows(X[,1],X[,2],X[,1]+0.012*grad.analytic[,1],X[,2]+0.012*grad.analytic[,2],col='blue')

## End(Not run)

</code></pre>


</div>