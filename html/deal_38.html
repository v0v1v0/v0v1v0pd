<div class="container">

<table style="width: 100%;"><tr>
<td>learn</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Estimation of parameters in the local probability
distributions</h2>

<h3>Description</h3>

<p>Updates the distributions of the parameters in the network,
based on a prior network and data. Also, the network score is calculated.
</p>


<h3>Usage</h3>

<pre><code class="language-R">learn (nw, df, prior=jointprior(nw),
               nodelist=1:size(nw),
               trylist=vector("list",size(nw)),
               timetrace=FALSE) 

</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>nw</code></td>
<td>
<p>an object of class <code>network</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>df</code></td>
<td>
<p>a data frame used for learning the network, see
<code>network</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>prior</code></td>
<td>
<p>a list containing parameter priors, generated by
<code>jointprior</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nodelist</code></td>
<td>
<p>a numeric vector of indices of nodes to be learned.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>trylist</code></td>
<td>
<p>a list used internally for reusing learning of nodes,
see <code>maketrylist</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>timetrace</code></td>
<td>
<p>a logical. If <code>TRUE</code>, prints some timing
information on the screen.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The procedure <code>learn</code> determines the master prior, local parameter
priors and local parameter posteriors, see Bottcher (2001). It may be called on all nodes
(default) or just a single node. 
</p>
<p>From the joint prior distribution, the marginal distribution of
all parameters in the family consisting of the node and its parents
can be determined. This is the master prior, see
<code>localmaster</code>.
</p>
<p>The local parameter priors are now determined by conditioning in
the master prior distribution, see
<code>conditional</code>. The hyperparameters associated with the
local parameter prior distribution is attached to each node in the
property <code>condprior</code>.
</p>
<p>Finally, the local parameter posterior distributions are calculated (see
<code>post</code>) and attached to each node in the property
<code>condposterior</code>. 
</p>
<p>A so-called trylist is maintained to speedup the learning process. The
trylist consists of a list of
matrices for each node. The matrix for a given node holds previously
evaluated parent configurations and the corresponding log-likelihood
contribution. If a node with a certain parent
configuration needs to be learned, it is checked, whether the node has
already been learned. The previously learned nodes are given as input
in the trylist parameter and is updated in the learning procedure. 
</p>
<p>When one or more nodes in a network have been learned, the network
score is updated and attached to the network in the property
<code>score</code>.  
</p>
<p>The learning procedure is called from various functions using the
principle, that networks should always be updated with their
score. Thus, e.g.\ <code>drawnetwork</code> keeps the network updated
when the graph is altered.
</p>


<h3>Value</h3>

<p>A list with two elements that may be accessed using
<code>getnetwork</code> and <code>gettrylist</code>. The elements are
</p>
<table>
<tr style="vertical-align: top;">
<td><code>nw</code></td>
<td>
<p>an object of class <code>network</code>, with the
<code>condposterior</code> properties updated for 
the nodes. Also, the property <code>score</code> is updated and contains
the network score. The contribution to the network score for each
node is contained in the property <code>loglik</code> for each node.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>trylist</code></td>
<td>
<p>an updated list used internally for reusing learning
of nodes, see <code>maketrylist</code>.</p>
</td>
</tr>
</table>
<h3>Author(s)</h3>

<p>Susanne Gammelgaard Bottcher, <br>
Claus Dethlefsen <a href="mailto:rpackage.deal@gmail.com">rpackage.deal@gmail.com</a>.
</p>


<h3>References</h3>

<p>Bottcher, S.G. (2001). Learning Bayesian Networks with Mixed Variables, Artificial Intelligence and Statistics 2001, Morgan Kaufmann, San Francisco, CA, USA, 149-156.
</p>


<h3>See Also</h3>

<p><code>networkfamily</code>,
<code>jointprior</code>,
<code>maketrylist</code>,
<code>network</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">data(rats)
fit       &lt;- network(rats)
fit.prior &lt;- jointprior(fit,12)
fit.learn &lt;- learn(fit,rats,fit.prior,timetrace=TRUE)
fit.nw    &lt;- getnetwork(fit.learn)
fit.learn2&lt;- learn(fit,rats,fit.prior,trylist=gettrylist(fit.learn),timetrace=TRUE)
</code></pre>


</div>