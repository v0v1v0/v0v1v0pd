<div class="container">

<table style="width: 100%;"><tr>
<td>sae.dnn.train</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Training a Deep neural network with weights initialized by Stacked AutoEncoder</h2>

<h3>Description</h3>

<p>Training a Deep neural network with weights initialized by
Stacked AutoEncoder
</p>


<h3>Usage</h3>

<pre><code class="language-R">sae.dnn.train(x, y, hidden = c(1), activationfun = "sigm", learningrate = 0.8, 
    momentum = 0.5, learningrate_scale = 1, output = "sigm", sae_output = "linear", 
    numepochs = 3, batchsize = 100, hidden_dropout = 0, visible_dropout = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>matrix of x values for examples</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>
<p>vector or matrix of target values for examples</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>hidden</code></td>
<td>
<p>vector for number of units of hidden
layers.Default is c(10).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>activationfun</code></td>
<td>
<p>activation function of hidden
unit.Can be "sigm","linear" or "tanh".Default is "sigm"
for logistic function</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>learningrate</code></td>
<td>
<p>learning rate for gradient descent.
Default is 0.8.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>momentum</code></td>
<td>
<p>momentum for gradient descent. Default is
0.5 .</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>learningrate_scale</code></td>
<td>
<p>learning rate will be mutiplied
by this scale after every iteration. Default is 1 .</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>numepochs</code></td>
<td>
<p>number of iteration for samples Default
is 3.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>batchsize</code></td>
<td>
<p>size of mini-batch. Default is 100.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>output</code></td>
<td>
<p>function of output unit, can be
"sigm","linear" or "softmax". Default is "sigm".</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>sae_output</code></td>
<td>
<p>function of autoencoder output unit,
can be "sigm","linear" or "softmax". Default is
"linear".</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>hidden_dropout</code></td>
<td>
<p>drop out fraction for hidden layer.
Default is 0.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>visible_dropout</code></td>
<td>
<p>drop out fraction for input layer
Default is 0.</p>
</td>
</tr>
</table>
<h3>Author(s)</h3>

<p>Xiao Rong
</p>


<h3>Examples</h3>

<pre><code class="language-R">Var1 &lt;- c(rnorm(50, 1, 0.5), rnorm(50, -0.6, 0.2))
Var2 &lt;- c(rnorm(50, -0.8, 0.2), rnorm(50, 2, 1))
x &lt;- matrix(c(Var1, Var2), nrow = 100, ncol = 2)
y &lt;- c(rep(1, 50), rep(0, 50))
dnn &lt;- sae.dnn.train(x, y, hidden = c(5, 5))
## predict by dnn
test_Var1 &lt;- c(rnorm(50, 1, 0.5), rnorm(50, -0.6, 0.2))
test_Var2 &lt;- c(rnorm(50, -0.8, 0.2), rnorm(50, 2, 1))
test_x &lt;- matrix(c(test_Var1, test_Var2), nrow = 100, ncol = 2)
nn.test(dnn, test_x, y)
</code></pre>


</div>