<div class="container">

<table style="width: 100%;"><tr>
<td>wmultinomial</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>wmultinomial function</h2>

<h3>Description</h3>

<p>A function to evaluate the weighted multinomial loss function and the derivative of this function
to be used when training a neural network. This is eqivalent to a multinomial cost function
employing a Dirichlet prior on the probabilities. Its effect is to regularise the estimation so
that in the case where we apriori expect more of one particular category compared to another
then this can be included in the objective.
</p>


<h3>Usage</h3>

<pre><code class="language-R">wmultinomial(w, batchsize)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>w</code></td>
<td>
<p>a vector of weights, adding up whose length is equal to the output length of the net</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>batchsize</code></td>
<td>
<p>of batch used in inference WARNING: ensure this matches with actual batchsize used!</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>a list object with elements that are functions, evaluating the loss and the derivative
</p>


<h3>References</h3>


<ol>
<li>
<p> Ian Goodfellow, Yoshua Bengio, Aaron Courville, Francis Bach. Deep Learning. (2016)
</p>
</li>
<li>
<p> Terrence J. Sejnowski. The Deep Learning Revolution (The MIT Press). (2018)
</p>
</li>
<li>
<p> Neural Networks YouTube playlist by 3brown1blue: <a href="https://www.youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi">https://www.youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi</a>
</p>
</li>
<li>
<p>http://neuralnetworksanddeeplearning.com/
</p>
</li>
</ol>
<h3>See Also</h3>

<p>network, train, backprop_evaluate, MLP_net, backpropagation_MLP,
Qloss, no_regularisation, L1_regularisation, L2_regularisation
</p>


</div>